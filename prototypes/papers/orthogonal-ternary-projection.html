<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Orthogonal Ternary Projection | Rohan Vinaik</title>

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">

  <!-- Theme -->
  <link rel="stylesheet" href="../lab-theme.css">

  <style>
    /* Paper-specific styles */
    body {
      display: flex;
      min-height: 100vh;
    }

    /* Paper Navigation Sidebar */
    .paper-nav {
      position: fixed;
      left: 0;
      top: 0;
      bottom: 0;
      width: 240px;
      background: var(--bg-secondary);
      border-right: 1px solid var(--border);
      display: flex;
      flex-direction: column;
      font-family: var(--font-mono);
      z-index: 100;
      overflow-y: auto;
    }

    .paper-nav__header {
      padding: var(--space-lg) var(--space-md);
      border-bottom: 1px solid var(--border);
    }

    .paper-nav__back {
      font-size: 0.75rem;
      color: var(--text-muted);
      text-decoration: none;
      display: flex;
      align-items: center;
      gap: 6px;
      margin-bottom: var(--space-sm);
    }

    .paper-nav__back:hover {
      color: var(--text-primary);
    }

    .paper-nav__title {
      font-size: 0.85rem;
      font-weight: 600;
      color: var(--text-primary);
      line-height: 1.3;
    }

    .paper-nav__meta {
      font-size: 0.7rem;
      color: var(--text-muted);
      margin-top: var(--space-xs);
    }

    .paper-nav__toc {
      padding: var(--space-md);
      flex: 1;
    }

    .toc-title {
      font-size: 0.65rem;
      color: var(--text-muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: var(--space-sm);
    }

    .toc-item {
      display: block;
      font-size: 0.75rem;
      color: var(--text-secondary);
      text-decoration: none;
      padding: 6px 0;
      border-left: 2px solid transparent;
      padding-left: var(--space-sm);
      transition: all 0.15s ease;
    }

    .toc-item:hover {
      color: var(--text-primary);
      border-left-color: var(--text-muted);
    }

    .toc-item.active {
      color: var(--text-primary);
      border-left-color: var(--text-primary);
    }

    .paper-nav__footer {
      padding: var(--space-md);
      border-top: 1px solid var(--border);
      font-size: 0.7rem;
    }

    .paper-nav__links {
      display: flex;
      flex-wrap: wrap;
      gap: var(--space-sm);
    }

    .paper-nav__links a {
      color: var(--text-muted);
      text-decoration: none;
    }

    .paper-nav__links a:hover {
      color: var(--text-primary);
    }

    /* Main Paper Content */
    .paper-main {
      margin-left: 240px;
      flex: 1;
      max-width: 800px;
      padding: var(--space-xl);
    }

    /* Paper Header */
    .paper-header {
      margin-bottom: var(--space-xl);
      padding-bottom: var(--space-lg);
      border-bottom: 1px solid var(--border);
    }

    .paper-header__status {
      display: inline-block;
      font-family: var(--font-mono);
      font-size: 0.6rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      padding: 3px 8px;
      border: 1px solid var(--border);
      color: var(--text-muted);
      margin-bottom: var(--space-md);
    }

    .paper-header__status--theory {
      border-color: var(--accent-theory);
      color: var(--accent-theory);
    }

    .paper-header__title {
      font-size: 1.8rem;
      font-weight: 600;
      line-height: 1.3;
      margin-bottom: var(--space-md);
    }

    .paper-header__authors {
      font-size: 1rem;
      color: var(--text-secondary);
      margin-bottom: var(--space-sm);
    }

    .paper-header__affiliations {
      font-size: 0.85rem;
      color: var(--text-muted);
      margin-bottom: var(--space-md);
    }

    .paper-header__tags {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
    }

    .paper-tag {
      font-family: var(--font-mono);
      font-size: 0.6rem;
      padding: 3px 8px;
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      color: var(--text-muted);
    }

    /* Abstract */
    .paper-abstract {
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      padding: var(--space-lg);
      margin-bottom: var(--space-xl);
    }

    .paper-abstract__title {
      font-family: var(--font-mono);
      font-size: 0.7rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      color: var(--text-muted);
      margin-bottom: var(--space-sm);
    }

    .paper-abstract__text {
      font-size: 0.95rem;
      line-height: 1.7;
      color: var(--text-secondary);
    }

    /* Paper Sections */
    .paper-section {
      margin-bottom: var(--space-xl);
    }

    .paper-section__title {
      font-size: 1.3rem;
      font-weight: 600;
      margin-bottom: var(--space-md);
      padding-top: var(--space-md);
    }

    .paper-section__subtitle {
      font-size: 1.1rem;
      font-weight: 500;
      margin-top: var(--space-lg);
      margin-bottom: var(--space-sm);
    }

    .paper-section p {
      font-size: 0.95rem;
      line-height: 1.8;
      margin-bottom: var(--space-md);
    }

    /* Key Insight Box */
    .key-insight {
      background: var(--bg-secondary);
      border-left: 3px solid var(--accent-theory);
      padding: var(--space-md);
      margin: var(--space-lg) 0;
      font-size: 0.95rem;
      line-height: 1.6;
    }

    .key-insight strong {
      display: block;
      margin-bottom: var(--space-xs);
      font-family: var(--font-mono);
      font-size: 0.7rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      color: var(--text-muted);
    }

    /* Code blocks */
    .paper-code {
      background: var(--bg-secondary);
      border: 1px solid var(--border);
      padding: var(--space-md);
      font-family: var(--font-mono);
      font-size: 0.8rem;
      line-height: 1.5;
      overflow-x: auto;
      margin-bottom: var(--space-md);
    }

    /* Inline code */
    code {
      font-family: var(--font-mono);
      font-size: 0.85em;
      background: var(--bg-secondary);
      padding: 2px 6px;
      border-radius: 2px;
    }

    /* Tables */
    .paper-table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: var(--space-md);
      font-size: 0.85rem;
    }

    .paper-table th,
    .paper-table td {
      padding: var(--space-sm);
      border: 1px solid var(--border);
      text-align: left;
    }

    .paper-table th {
      background: var(--bg-secondary);
      font-family: var(--font-mono);
      font-size: 0.75rem;
      text-transform: uppercase;
      letter-spacing: 0.03em;
    }

    /* Lists */
    .paper-section ul,
    .paper-section ol {
      margin-bottom: var(--space-md);
      padding-left: var(--space-lg);
    }

    .paper-section li {
      font-size: 0.95rem;
      line-height: 1.7;
      margin-bottom: var(--space-xs);
    }

    /* Responsive */
    @media (max-width: 900px) {
      .paper-nav {
        width: 200px;
      }
      .paper-main {
        margin-left: 200px;
        padding: var(--space-lg);
      }
    }

    @media (max-width: 700px) {
      .paper-nav {
        position: relative;
        width: 100%;
        max-height: none;
        border-right: none;
        border-bottom: 1px solid var(--border);
      }
      .paper-nav__toc {
        display: none;
      }
      .paper-main {
        margin-left: 0;
        padding: var(--space-md);
      }
      .paper-header__title {
        font-size: 1.4rem;
      }
    }
  </style>
</head>
<body>
  <!-- Paper Navigation -->
  <nav class="paper-nav">
    <div class="paper-nav__header">
      <a href="../narrative-prototype.html#papers" class="paper-nav__back">&larr; Back to Papers</a>
      <div class="paper-nav__title">Orthogonal Ternary Projection</div>
      <div class="paper-nav__meta">2025 | Information Theory</div>
    </div>

    <div class="paper-nav__toc">
      <div class="toc-title">Contents</div>
      <a href="#abstract" class="toc-item">Abstract</a>
      <a href="#introduction" class="toc-item">1. Introduction</a>
      <a href="#informational-zeros" class="toc-item">2. Informational Zeros</a>
      <a href="#foundations" class="toc-item">3. Theoretical Foundations</a>
      <a href="#progressive-revelation" class="toc-item">4. Progressive Revelation</a>
      <a href="#genomics" class="toc-item">5. Application: Genomics</a>
      <a href="#implications" class="toc-item">6. Implications</a>
    </div>

    <div class="paper-nav__footer">
      <div class="paper-nav__links">
        <a href="#">PDF</a>
        <a href="#">Code</a>
      </div>
    </div>
  </nav>

  <!-- Paper Content -->
  <main class="paper-main">
    <header class="paper-header">
      <span class="paper-header__status paper-header__status--theory">Theory</span>
      <h1 class="paper-header__title">Orthogonal Ternary Projection: A Theory of Geometric Information and Informational Zeros</h1>
      <div class="paper-header__authors">Rohan Vinaik</div>
      <div class="paper-header__affiliations">Independent Researcher</div>
      <div class="paper-header__tags">
        <span class="paper-tag">INFORMATION-THEORY</span>
        <span class="paper-tag">HDC</span>
        <span class="paper-tag">ENCODING</span>
      </div>
    </header>

    <section class="paper-abstract" id="abstract">
      <div class="paper-abstract__title">Abstract</div>
      <p class="paper-abstract__text">
        We present Orthogonal Ternary Projection (OTP), an encoding paradigm where symbols are represented as high-dimensional vectors with components in {-1, 0, +1}. The central innovation: zeros are not absences of data but <em>informational zeros</em>—markers of transparency and orthogonality that carry structural meaning. This framework bridges classical determinism and observer-dependent information: it is fully deterministic yet observer-conditioned, where different measurement channels observe different projections of the same underlying state. Information is encoded in geometric relationships rather than symbolic identities, enabling progressive revelation analogous to the Monty Hall effect.
      </p>
    </section>

    <section class="paper-section" id="introduction">
      <h2 class="paper-section__title">1. Introduction</h2>

      <p>
        Classical information theory treats information as absolute and objective—a message has definite entropy, and encoding is a deterministic mapping from symbols to bits. Yet this framework treats symbols as atomic, unstructured entities with no internal geometry.
      </p>

      <p>
        Quantum information theory introduces observer dependence and contextuality—a quantum state is described relative to a measurement basis. Information becomes fundamentally relational. But quantum mechanics brings conceptual baggage: superposition, entanglement, probabilistic ontology.
      </p>

      <div class="key-insight">
        <strong>Core Insight</strong>
        Information is not just bits (presence/absence) but geometry (orientation/orthogonality). By utilizing informational zeros—zeros that represent transparency rather than absence—we build systems that adapt automatically to biased data and allow progressive, observer-dependent decoding.
      </div>

      <h3 class="paper-section__subtitle">The Core Concept: DNA is not base-4, it's base-2<sup>2</sup></h3>

      <p>
        Consider encoding the genetic alphabet {A, T, G, C}. Traditional binary encoding:
      </p>

      <pre class="paper-code">Traditional: A = 00, T = 01, G = 10, C = 11
Each nucleotide is an atomic symbol requiring 2 bits</pre>

      <p>
        This encoding is efficient but loses structure. A and T are "distance 1 apart" in bit-space, as are A and G—yet biologically, A-T pair together while A-G are both purines. The encoding doesn't capture these relationships.
      </p>

      <pre class="paper-code">Orthogonal Ternary Projection:
  Dimension 1 (AT vs GC):      A → +1, T → -1, G → 0, C → 0
  Dimension 2 (Purine vs Pyr): A → 0,  T → 0,  G → +1, C → -1

Joint encoding:
  A = (+1, 0)   "AT-positive, GC-transparent"
  T = (-1, 0)   "AT-negative, GC-transparent"
  G = (0, +1)   "AT-transparent, Purine-positive"
  C = (0, -1)   "AT-transparent, Pyrimidine-positive"</pre>

      <p>
        The zeros are not missing information—they encode orthogonality. When the AT dimension returns 0, this tells us definitively: "the nucleotide is not in the AT subspace," equivalent to "the nucleotide is G or C." This is positive information through exclusion.
      </p>
    </section>

    <section class="paper-section" id="informational-zeros">
      <h2 class="paper-section__title">2. Informational Zeros</h2>

      <p>
        In traditional Boolean logic, "0" conflates multiple meanings: additive identity, FALSE, absent, unknown. OTP introduces the <em>informational zero</em>—a zero that denotes a deliberate type of information, not a lack thereof.
      </p>

      <table class="paper-table">
        <thead>
          <tr>
            <th>View</th>
            <th>Binary {0,1}</th>
            <th>Ternary {-1,0,+1} in OTP</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Arithmetic</td>
            <td>Additive identity</td>
            <td>Orthogonality marker</td>
          </tr>
          <tr>
            <td>Logic</td>
            <td>FALSE (opposite of TRUE)</td>
            <td>INAPPLICABLE (orthogonal to question)</td>
          </tr>
          <tr>
            <td>Information</td>
            <td>No signal / unknown</td>
            <td>Confident exclusion / transparency</td>
          </tr>
        </tbody>
      </table>

      <h3 class="paper-section__subtitle">The Filter Analogy</h3>

      <p>
        Consider colored light filters. A red filter passes red light (+1), blocks blue light (-1), and is transparent to green light (0). Having no filter is an active choice that lets light through unchanged. Similarly, a 0 in an OTP vector lets that dimension "pass through" without interaction.
      </p>

      <div class="key-insight">
        <strong>Key Principle</strong>
        In OTP, zero is not the absence of meaning—it is the presence of orthogonality. Two zeros in different coordinates are not identical: each refers to the absence of a particular attribute. Zeros are typed.
      </div>
    </section>

    <section class="paper-section" id="foundations">
      <h2 class="paper-section__title">3. Theoretical Foundations</h2>

      <p>
        An OTP system consists of:
      </p>

      <ol>
        <li>A ternary alphabet {-1, 0, +1} where 0 represents transparency/orthogonality</li>
        <li>Multiple measurement channels (dimensions) that partition the symbol space</li>
        <li>Pairwise orthogonality: different symbols project onto different subspaces</li>
        <li>Selective transparency: each symbol is "visible" to some channels and "transparent" to others</li>
      </ol>

      <p>
        This creates a geometric information space where symbols are points in a high-dimensional space, channels are projection axes, zeros mark orthogonality between symbols and axes, and distance has geometric interpretation.
      </p>

      <h3 class="paper-section__subtitle">Information-Theoretic Properties</h3>

      <p>
        For a 4-symbol OTP example with uniform prior:
      </p>

      <pre class="paper-code">Prior: P(s) = {0.25, 0.25, 0.25, 0.25}
Observe: E1(s) = 0

Posterior: P(s | E1 = 0) = {0, 0, 0.5, 0.5}

Information gained: I = log2(4) - log2(2) = 1 bit</pre>

      <p>
        The zero reveals exactly 1 bit of information. It's not "no signal"—it's a definitive exclusion that eliminates half the possibility space.
      </p>
    </section>

    <section class="paper-section" id="progressive-revelation">
      <h2 class="paper-section__title">4. Progressive Revelation</h2>

      <p>
        OTP enables something impossible with direct binary encoding: progressive information revelation analogous to the Monty Hall problem.
      </p>

      <p>
        With traditional atomic encoding, you either know the symbol or you don't. With OTP:
      </p>

      <ol>
        <li><strong>Measure dimension 1</strong> (AT vs GC): Returns 0 → Rules out A and T, narrows to {G, C}</li>
        <li><strong>Measure dimension 2</strong> (Purine vs Pyr): Returns +1 → Identifies G with certainty</li>
        <li><strong>Combine evidence</strong>: Complete discrimination through sequential, orthogonal measurements</li>
      </ol>

      <div class="key-insight">
        <strong>The Monty Hall Insight</strong>
        Each zero observation is like Monty Hall revealing a goat behind a door—it's a constrained action that eliminates possibilities and increases confidence in what remains. The revealed empty dimension is not "no information"—it's confident exclusion that concentrates probability elsewhere.
      </div>
    </section>

    <section class="paper-section" id="genomics">
      <h2 class="paper-section__title">5. Application: Genomics</h2>

      <p>
        DNA's base-pairing rules (A-T, G-C) create natural orthogonal subspaces. OTP encoding exploits this biological structure:
      </p>

      <ul>
        <li><strong>Weak/Strong hydrogen bonding</strong>: AT pairs (2 H-bonds) vs GC pairs (3 H-bonds)</li>
        <li><strong>Purine/Pyrimidine chemistry</strong>: A,G (larger) vs T,C (smaller)</li>
      </ul>

      <p>
        These aren't arbitrary dimensions—they reflect physical properties that evolution has exploited for error correction. The encoding honors the problem's natural structure.
      </p>

      <h3 class="paper-section__subtitle">Compositional Adaptation</h3>

      <p>
        Under compositional bias, OTP systems exhibit remarkable properties: minority channels provide higher signal-to-noise ratios than majority channels, and at least one channel is always sparse—creating automatic adaptation to data statistics without explicit conditioning.
      </p>
    </section>

    <section class="paper-section" id="implications">
      <h2 class="paper-section__title">6. Philosophical Implications</h2>

      <p>
        OTP reveals a deeper principle about information itself: it is fundamentally relational, emerging from correlations between observers and systems rather than existing as an intrinsic property of symbols.
      </p>

      <p>
        The framework is classical but observer-dependent, deterministic yet contextual. This synthesis unifies concepts from information theory, sparse signal processing, orthogonal matrix theory, and relational logic into a coherent framework.
      </p>

      <div class="key-insight">
        <strong>The Deeper Principle</strong>
        When the representation honors the problem's natural structure, answers emerge from geometry rather than search. Information can be encoded in geometric relationships rather than symbolic identities.
      </div>
    </section>
  </main>

  <script>
    // Active TOC highlighting based on scroll
    const sections = document.querySelectorAll('.paper-section');
    const tocItems = document.querySelectorAll('.toc-item');

    function updateTOC() {
      let current = '';
      sections.forEach(section => {
        const sectionTop = section.offsetTop - 100;
        if (window.scrollY >= sectionTop) {
          current = section.id;
        }
      });

      tocItems.forEach(item => {
        item.classList.remove('active');
        if (item.getAttribute('href') === `#${current}`) {
          item.classList.add('active');
        }
      });
    }

    window.addEventListener('scroll', updateTOC);
    updateTOC();
  </script>
</body>
</html>
