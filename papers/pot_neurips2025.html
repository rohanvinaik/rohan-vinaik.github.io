<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Proof-of-Training (PoT) Verifier - Rohan Vinaik</title>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;700&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg-primary: #0a0a0a;
      --bg-secondary: #111111;
      --bg-tertiary: #1a1a1a;
      --text-primary: #e0e0e0;
      --text-secondary: #808080;
      --border-color: rgba(255, 255, 255, 0.1);
      --accent: #00ffff;
      --accent-dim: #00aa00;
      --accent-alt: #ffb000;
      --code-bg: #0d0d0d;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'JetBrains Mono', monospace;
      background: var(--bg-primary);
      color: var(--text-primary);
      line-height: 1.7;
      overflow-x: hidden;
    }

    .nav-bar {
      position: sticky;
      top: 0;
      background: var(--bg-secondary);
      border-bottom: 1px solid var(--accent);
      padding: 1rem 2rem;
      display: flex;
      gap: 1.5rem;
      flex-wrap: wrap;
      z-index: 1000;
      font-size: 0.9rem;
    }

    .nav-bar a {
      color: var(--accent);
      text-decoration: none;
      transition: color 0.2s;
    }

    .nav-bar a:hover {
      color: var(--accent-alt);
    }

    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 2rem;
    }

    .paper-header {
      border-bottom: 2px solid var(--accent);
      padding-bottom: 2rem;
      margin-bottom: 2rem;
    }

    h1 {
      font-size: 1.8rem;
      color: var(--accent);
      margin-bottom: 1rem;
      line-height: 1.3;
    }

    .paper-meta {
      color: var(--text-secondary);
      font-size: 0.9rem;
      margin-top: 1rem;
    }

    .paper-meta span {
      display: inline-block;
      margin-right: 1.5rem;
    }

    h2 {
      font-size: 1.4rem;
      color: var(--accent);
      margin: 2.5rem 0 1rem 0;
      padding-top: 1rem;
      border-top: 1px solid var(--border-color);
    }

    h3 {
      font-size: 1.1rem;
      color: var(--accent-dim);
      margin: 1.5rem 0 0.75rem 0;
    }

    h4 {
      font-size: 1rem;
      color: var(--text-primary);
      margin: 1rem 0 0.5rem 0;
      font-weight: 600;
    }

    p {
      margin-bottom: 1rem;
      color: var(--text-primary);
    }

    .abstract {
      background: var(--bg-tertiary);
      border-left: 3px solid var(--accent);
      padding: 1.5rem;
      margin: 2rem 0;
      font-size: 0.95rem;
    }

    .highlight-box {
      background: var(--bg-tertiary);
      border: 1px solid var(--accent-dim);
      padding: 1.5rem;
      margin: 1.5rem 0;
      border-radius: 4px;
    }

    .highlight-box h4 {
      color: var(--accent);
      margin-top: 0;
    }

    ul, ol {
      margin-left: 2rem;
      margin-bottom: 1rem;
    }

    li {
      margin-bottom: 0.5rem;
      color: var(--text-primary);
    }

    code {
      background: var(--code-bg);
      color: var(--accent);
      padding: 0.2rem 0.4rem;
      border-radius: 3px;
      font-size: 0.9em;
    }

    pre {
      background: var(--code-bg);
      border: 1px solid var(--border-color);
      border-radius: 4px;
      padding: 1rem;
      overflow-x: auto;
      margin: 1rem 0;
    }

    pre code {
      background: none;
      padding: 0;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 1.5rem 0;
      font-size: 0.85rem;
      background: var(--bg-tertiary);
    }

    th, td {
      border: 1px solid var(--border-color);
      padding: 0.75rem;
      text-align: left;
    }

    th {
      background: var(--bg-secondary);
      color: var(--accent);
      font-weight: 600;
    }

    tr:hover {
      background: rgba(0, 255, 0, 0.05);
    }

    .math {
      font-style: italic;
      color: var(--accent-alt);
    }

    .citation {
      color: var(--accent-dim);
      font-size: 0.9em;
    }

    .figure {
      margin: 2rem 0;
      text-align: center;
    }

    .figure-caption {
      color: var(--text-secondary);
      font-size: 0.9rem;
      margin-top: 0.5rem;
      font-style: italic;
    }

    .contribution-list {
      background: var(--bg-tertiary);
      border-left: 3px solid var(--accent-alt);
      padding: 1rem 1rem 1rem 2rem;
      margin: 1rem 0;
    }

    .key-insight {
      background: var(--bg-secondary);
      border: 1px solid var(--accent);
      padding: 1rem;
      margin: 1rem 0;
      border-radius: 4px;
    }

    .references {
      font-size: 0.85rem;
      margin-top: 3rem;
      padding-top: 2rem;
      border-top: 2px solid var(--accent);
    }

    .reference-item {
      margin-bottom: 0.75rem;
      padding-left: 2rem;
      text-indent: -2rem;
    }

    strong {
      color: var(--accent-dim);
      font-weight: 600;
    }

    em {
      color: var(--accent-alt);
      font-style: italic;
    }

    .footnote {
      font-size: 0.85rem;
      color: var(--text-secondary);
      margin-top: 0.5rem;
    }

    @media (max-width: 768px) {
      .container {
        padding: 1rem;
      }

      h1 {
        font-size: 1.4rem;
      }

      h2 {
        font-size: 1.2rem;
      }

      .nav-bar {
        padding: 0.75rem 1rem;
        font-size: 0.8rem;
      }

      table {
        font-size: 0.75rem;
      }

      th, td {
        padding: 0.5rem;
      }
    }
  </style>
</head>
<body>
  <div class="nav-bar">
    <a href="../index.html">← Home</a>
    <a href="#abstract">Abstract</a>
    <a href="#introduction">Introduction</a>
    <a href="#method">Method</a>
    <a href="#results">Results</a>
    <a href="#limitations">Limitations</a>
    <a href="#references">References</a>
  </div>

  <div class="container">
    <div class="paper-header">
      <h1>Proof-of-Training (PoT) Verifier: Cryptographically Pre-Committed, Anytime Behavioral Model Identity Checks</h1>
      <div class="paper-meta">
        <span><strong>Venue:</strong> NeurIPS 2025 Submission</span>
        <span><strong>Pages:</strong> 13</span>
        <span><strong>Date:</strong> October 2025</span>
        <span><strong>Status:</strong> Validated Experimental Data</span>
      </div>
    </div>

    <section id="abstract">
      <h2>Abstract</h2>
      <div class="abstract">
        <p>We present a <strong>post-training behavioral verifier</strong> for model identity. Given two models (or a model and a reference), we decide SAME/DIFFERENT/UNDECIDED with controlled error using <strong>dozens of queries</strong> (perfect separation in 8 experiments with just 14–40 queries) rather than thousands, with automatic behavioral fingerprinting for model variants.</p>

        <p>The verifier (i) <strong>pre-commits to challenges</strong> via HMAC-derived seeds, (ii) maintains <strong>anytime confidence sequences</strong> using Empirical-Bernstein bounds, and (iii) <strong>stops early</strong> when confidence intervals reach decision thresholds. Each run exports a reproducible audit bundle containing transcripts, seeds, commitments, configs, and environment data.</p>

        <p>On the systems side, we demonstrate <strong>sharded verification</strong> of 34B-class models (≈206 GB weights) on 64 GB hosts with ≈52% peak RAM usage through shard cycling. The repository includes single-command runners for both local and API-based verification.</p>

        <p><strong>Important Scope:</strong> PoT fully verifies API-hosted models; provider authentication (proving server operator identity) requires separate infrastructure like TEE attestation or vendor commitments. ZK proofs can attest verifier computation correctness from published transcripts but cannot authenticate remote providers.</p>

        <p>At α = 0.01, PoT reaches decisions in <strong>17–92 seconds for small models</strong> (GPT-2 class) and <strong>22 minutes for 7B models</strong> (vs 45–60 minutes baseline), making continuous deployment verification finally practical. This <strong>30×–60× speedup</strong> transforms model verification from a costly bottleneck to a routine CI/CD step.</p>
      </div>
    </section>

    <section id="introduction">
      <h2>1. Introduction</h2>

      <p>Deployed LLMs are frequently <strong>opaque</strong>: weights are inaccessible or served behind APIs, yet stakeholders must answer a simple question—<em>is the deployed model the same one we audited?</em> We propose a practical, auditable verifier that answers this with statistical guarantees under a black-box access model.</p>

      <div class="highlight-box">
        <h4>Why This is Non-Trivial</h4>
        <p>Naive approaches fail—fixed test sets lack statistical guarantees and are vulnerable to overfitting; standard sequential testing requires 1000+ queries; simple confidence intervals are invalid under early stopping; random challenges are vulnerable to adaptive adversaries.</p>
        <p><strong>Our key insight:</strong> Pre-committed challenges + anytime-valid confidence sequences + behavioral scoring creates a synergy achieving all properties simultaneously while enabling aggressive early stopping.</p>
      </div>

      <div class="highlight-box">
        <h4>Deployment Reality Check</h4>
        <ul>
          <li>Runs on consumer hardware (M1 Max laptop)</li>
          <li>Handles production models (34B parameters/206GB)</li>
          <li>CI/CD integration ready</li>
          <li>No GPU cluster required</li>
        </ul>
      </div>

      <h3>Design Constraints</h3>
      <ol>
        <li><strong>Pre-commitment and auditability.</strong> Challenges are fixed <em>before</em> interaction via cryptographic seeds; outputs, scores, and parameters are archived in an evidence bundle.</li>
        <li><strong>Sample-efficiency.</strong> We leverage anytime EB confidence sequences to stop in dozens of queries when possible, rather than a fixed N of hundreds or thousands.</li>
        <li><strong>Systems feasibility.</strong> Verification must run on commodity hardware and support very large checkpoints via sharded load-verify-release.</li>
      </ol>

      <table>
        <caption><strong>Table 1.</strong> PoT vs Prior Verification Methods: Orders of Magnitude Improvement</caption>
        <thead>
          <tr>
            <th>Method</th>
            <th>Access</th>
            <th>Queries</th>
            <th>Time</th>
            <th>Memory</th>
            <th>API Support</th>
            <th>Statistical Guarantees</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Weight checksums</td>
            <td>White-box</td>
            <td>0</td>
            <td>Instant</td>
            <td>Full model</td>
            <td>No</td>
            <td>No</td>
          </tr>
          <tr>
            <td>Gradient verification [10]</td>
            <td>White-box</td>
            <td>100–500</td>
            <td>2+ hours</td>
            <td>Full model</td>
            <td>No</td>
            <td>Yes</td>
          </tr>
          <tr>
            <td>Fixed behavioral tests</td>
            <td>Black-box</td>
            <td>1000+</td>
            <td>45–60 min</td>
            <td>&lt;1 GB</td>
            <td>Yes</td>
            <td>No</td>
          </tr>
          <tr style="background: rgba(0, 255, 0, 0.1);">
            <td><strong>PoT (ours)</strong></td>
            <td><strong>Black-box</strong></td>
            <td><strong>14–40</strong></td>
            <td><strong>1–2 min</strong></td>
            <td><strong>&lt;2 GB</strong></td>
            <td><strong>Yes</strong></td>
            <td><strong>Yes</strong></td>
          </tr>
        </tbody>
      </table>

      <div class="key-insight">
        <h4>Significance of 30×–200× Speedup</h4>
        <p>This transforms deployment patterns—every PR can verify small model integrity (&lt;2 min vs 60 min); hourly production checks become feasible; incident response can verify model state much faster; multi-model A/B testing validation becomes practical. Previously impractical verification is now routine.</p>
      </div>

      <h3>Contributions</h3>
      <div class="contribution-list">
        <ol>
          <li>A pre-committed, anytime verifier that outputs SAME/DIFFERENT/UNDECIDED with explicit error control.</li>
          <li>An evidence bundle format and one-command runners for local/API settings.</li>
          <li>Sharded verification enabling audits of ∼206 GB checkpoints with ≈52% peak host RAM.</li>
          <li>Clarification that PoT verifies model behavior via any API; provider authentication (who runs the server) requires TEEs or vendor commitments.</li>
        </ol>
      </div>

      <div class="highlight-box">
        <h4>Key Insights from Experiments</h4>
        <ul>
          <li>Perfect model discrimination (8/8) with just 14–40 queries</li>
          <li>Asymmetric verification detects model downgrades/substitutions</li>
          <li>30–60× speedup over standard practice (Fixed-N=1000)</li>
          <li>Consumer hardware suffices (no GPU clusters needed)</li>
        </ul>
      </div>
    </section>

    <section id="related-work">
      <h2>2. Related Work and Why Existing Methods Fail</h2>

      <h3>2.1 Limitations of Existing Methods</h3>
      <p><strong>Why this problem wasn't already solved:</strong></p>
      <ul>
        <li><strong>Weight hashing:</strong> Requires white-box access, infeasible for APIs</li>
        <li><strong>Behavioral testing without guarantees:</strong> No confidence in results, vulnerable to random variation</li>
        <li><strong>Sequential testing without pre-commitment:</strong> Vulnerable to p-hacking and adaptive attacks</li>
        <li><strong>Fixed-N testing:</strong> Wastes 95%+ queries when models are clearly identical/different</li>
      </ul>

      <p><strong>The non-obvious combination:</strong> While individual components are established, their orchestration is non-trivial. Prior work achieved speed OR guarantees OR pre-commitment, never all three. The specific integration (HMAC seeds → EB bounds → early stopping) required solving technical challenges: (i) maintaining validity under data-dependent stopping, (ii) variance-adaptive bounds that converge quickly, (iii) cryptographic pre-commitment compatible with sequential testing.</p>

      <h3>2.2 Prior Verification Approaches</h3>
      <p><strong>Model verification approaches.</strong> Prior work falls into three categories: (i) Weight-based methods requiring full model access (checksums, watermarking), unsuitable for API-only settings; (ii) Gradient-based verification requiring white-box access to compute gradients, with O(model_size) memory; (iii) Behavioral approaches using fixed test sets, but lacking statistical guarantees or pre-commitment.</p>

      <p>Our method uniquely combines black-box behavioral testing with anytime statistical guarantees and cryptographic pre-commitment, achieving <strong>96%+ query reduction</strong> (14–40 queries vs fixed-N = 1000 prompts baseline) while maintaining controlled error rates.</p>

      <h3>2.3 Sequential Testing Background</h3>
      <p><strong>Sequential testing.</strong> Wald's SPRT established early-stopping binary tests. In bounded/noisy settings, Empirical-Bernstein style bounds yield variance-adaptive concentration. Anytime-valid inference produces time-uniform confidence sequences that remain valid under optional stopping. We extend these to model verification with explicit SAME/DIFFERENT decision rules.</p>

      <p><strong>Cryptographic commitments & attestation.</strong> HMAC, HKDF, and SHA-256 establish deterministic, non-malleable seeds and artifact integrity. TEEs provide remote attestation of code/data on trusted hardware. ZK systems prove statements about computations without revealing inputs; here they can attest the verifier's computation over a transcript but do not bind a remote model identity.</p>
    </section>

    <section id="preliminaries">
      <h2>3. Preliminaries and Threat Model</h2>

      <p><strong>Access models.</strong> (a) <em>Local weights:</em> we can hash checkpoints and bind transcripts to a weight digest. (b) <em>API black-box:</em> only I/O is visible; identity binding requires TEE or vendor commitments. ZK can certify the verifier's decision from the transcript, but cannot identify a remote endpoint by itself.</p>

      <p><strong>Adversary.</strong> May alter a deployed model (fine-tune, truncate experts, change tokenizer/decoding), apply wrappers or temperature jitter, or select prompts adaptively. We counter cherry-picking by pre-committing challenges via HMAC-derived seeds and adopting anytime statistics that remain valid under optional stopping.</p>

      <p><strong>Goal.</strong> Decide SAME (behaviorally indistinguishable within margin γ), DIFFERENT (effect size ≥δ*), or UNDECIDED, while controlling type-I error at level α.</p>
    </section>

    <section id="method">
      <h2>4. Method</h2>

      <h3>4.1 Pre-committed Challenges</h3>
      <p>We derive seed s<sub>i</sub> = HMAC<sub>K</sub>(run_id ∥ i) and map s<sub>i</sub> to a prompt template. The verifier <strong>publishes</strong> the run metadata (run_id, seed count, seed-list hash) prior to queries; the key K is revealed <em>after</em> runs, letting third parties regenerate the challenge set. Derived prompts avoid revealing K, and any post hoc cherry-picking contradicts the commitment.</p>

      <h3>4.2 Scoring</h3>
      <p>For each challenge, we compute a bounded score X<sub>i</sub> ∈ [0, 1] that increases with behavioral discrepancy. We use <strong>teacher-forced scoring</strong> with delta cross-entropy as the default metric:</p>

      <pre><code>X<sub>i</sub> = clip(|H(p<sub>ref</sub>, p<sub>cand</sub>) − H(p<sub>ref</sub>, p<sub>ref</sub>)|, 0, 1)</code></pre>

      <p>where H is cross-entropy over next-token distributions at K = 64 positions. This metric is non-negative by construction and bounded for numerical stability.</p>

      <p class="footnote"><strong>Note on scale:</strong> The per-challenge scores X<sub>i</sub> are clipped to [0, 1] for numerical stability. However, the effect sizes |X̄<sub>n</sub>| reported in Table 3 are aggregated metrics computed as the absolute mean of unbounded delta cross-entropies across n challenges, which can exceed 1 when models differ substantially.</p>

      <h3>4.3 Anytime Empirical-Bernstein Confidence Sequence</h3>
      <p>Let X̄<sub>n</sub> denote the sample mean and Var̂<sub>n</sub> the empirical variance. An Empirical-Bernstein (EB) half-width h<sub>n</sub> of the form:</p>

      <pre><code>h<sub>n</sub> = √[(2 Var̂<sub>n</sub> log(1/δ<sub>n</sub>))/n + (7 log(1/δ<sub>n</sub>))/(3(n − 1))]</code></pre>

      <p>ensures that P(∀n ≥ 2 : |X̄<sub>n</sub> − μ| ≤ h<sub>n</sub>) ≥ 1 − Σ<sub>n≥2</sub> δ<sub>n</sub>. By choosing δ<sub>n</sub> = α · c/(n(n + 1)) with c = 2, we have Σ<sub>n≥2</sub> δ<sub>n</sub> = α ensuring a time-uniform type-I error of α. The confidence interval is [X̄<sub>n</sub> − h<sub>n</sub>, X̄<sub>n</sub> + h<sub>n</sub>], valid anytime without pre-specifying a stopping rule.</p>

      <h3>4.4 Decision Rules and Early Stopping</h3>
      <p>Define <strong>relative margin error (RME)</strong>: RME<sub>n</sub> = h<sub>n</sub>/ max(|X̄<sub>n</sub>|, ϵ) with ϵ = 10<sup>−10</sup> for numerical stability.</p>

      <div class="highlight-box">
        <h4>Principled Parameter Selection</h4>
        <ul>
          <li><strong>γ = 0.025:</strong> Corresponds to 2.5% divergence in next-token distributions, below human perceptibility threshold and aligned with typical temperature jitter (0.0–0.1)</li>
          <li><strong>δ* = 0.05:</strong> Minimum effect size for practical significance, calibrated from fine-tuning experiments showing 5%+ divergence</li>
          <li><strong>η = 0.5:</strong> Ensures CI width is at most half the margin, providing 2:1 signal-to-noise ratio</li>
          <li><strong>n<sub>max</sub>:</strong> Set via power analysis to achieve 80% power at effect sizes of interest</li>
        </ul>
      </div>

      <p><strong>We decide:</strong></p>
      <ul>
        <li><strong>SAME:</strong> CI ⊆ [−γ, +γ] AND h<sub>n</sub> ≤ η · γ</li>
        <li><strong>DIFFERENT:</strong> Effect size |X̄<sub>n</sub>| ≥ δ* AND RME<sub>n</sub> ≤ ϵ<sub>diff</sub></li>
        <li><strong>UNDECIDED:</strong> Otherwise, or if n reaches n<sub>max</sub></li>
      </ul>

      <p>Stopping occurs when a decision is reached or at n<sub>max</sub>. The anytime property ensures validity regardless of when we stop.</p>

      <h3>4.5 API Verification and Provider Authentication</h3>
      <p>PoT distinguishes between <strong>model verification</strong> and <strong>provider authentication</strong>:</p>
      <ul>
        <li><strong>Model verification:</strong> PoT fully verifies any model's behavior through API calls. The evidence bundle proves behavioral equivalence/divergence.</li>
        <li><strong>Provider authentication:</strong> Proving who serves the API requires additional infrastructure:
          <ul>
            <li>TEE attestation: Hardware-backed proof of the serving stack</li>
            <li>Vendor commitments: Cryptographic signatures from the provider</li>
            <li>ZK proofs: Can prove the verifier computed correctly from transcripts, but cannot authenticate the remote provider</li>
          </ul>
        </li>
      </ul>
    </section>

    <section id="implementation">
      <h2>5. Implementation</h2>

      <h3>5.1 Runner and Artifacts</h3>
      <p>We expose a manifest-driven runner with one-command entry points for local/API verification. Each run directory contains:</p>
      <ul>
        <li><code>manifest.yaml</code>: run configuration, commitment metadata</li>
        <li><code>transcript.ndjson</code>: per-challenge prompts, raw outputs, scores</li>
        <li><code>evidence_bundle.json</code>: summary, decision, confidence, n<sub>used</sub></li>
        <li><code>metrics.json</code> (optional): RSS time-series, sharding events</li>
      </ul>

      <h3>5.2 Sharded Verification (34B-class Models)</h3>
      <p>For models too large for host RAM, we shard safetensors and verify layer-by-layer. For instance, Yi-34B (≈206 GB across two checkpoints) is loaded in ≈10 GB increments, verified, then released. The verifier cycles through shards while maintaining a cumulative result. RSS tracking confirms peak memory ≈52% on a 64 GB host.</p>
    </section>

    <section id="experiments">
      <h2>6. Experimental Setup</h2>

      <p><strong>Models.</strong> GPT-2, DistilGPT-2, DialoGPT-Medium (local); Llama-7B base/chat, Yi-34B base/chat (sharded); proprietary APIs (when applicable).</p>

      <p><strong>Baselines.</strong> We compare against: (i) Fixed-N (1000 queries) representing standard practice; (ii) Naive fixed-CI without anytime correction; (iii) mSPRT: mixture Sequential Probability Ratio Test with τ = 0.001; (iv) Always Valid p-values (provides anytime validity but requires more queries for same power).</p>

      <p><strong>Metrics.</strong> Decision accuracy (FAR, FRR), n_used, wall-time, peak memory.</p>

      <p><strong>Robustness micro-tests.</strong> Toggle (a) temperature 0.0 ↔ 0.7, (b) simple paraphrase/wrapper on candidate outputs, (c) tokenizer-overlap shim ∈ [0.6, 1.0].</p>

      <p><strong>Reproducibility.</strong> Provide the manifest and evidence bundle per headline claim; publish bundle hashes in tables. A bootstrap power proxy resamples per-prompt scores from transcripts to report a CI for mean discrepancy without further queries.</p>
    </section>

    <section id="fingerprinting">
      <h2>7. Behavioral Fingerprinting: Beyond Binary Decisions</h2>

      <p>When models show stable intermediate convergence (neither SAME nor DIFFERENT), we classify relationships based on the absolute mean difference |X̄<sub>n</sub>|:</p>

      <table>
        <thead>
          <tr>
            <th>Relationship</th>
            <th>Mean Effect Range</th>
            <th>Example</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>SAME (identical)</td>
            <td>|X̄<sub>n</sub>| &lt; 0.001</td>
            <td>Same checkpoint</td>
          </tr>
          <tr>
            <td>RELATED_TRAINING</td>
            <td>1 ≤ |X̄<sub>n</sub>| &lt; 5</td>
            <td>Continued pre-training</td>
          </tr>
          <tr>
            <td>DIFFERENT_TRAINING</td>
            <td>5 ≤ |X̄<sub>n</sub>| &lt; 10</td>
            <td>Distillation</td>
          </tr>
          <tr>
            <td>DIFFERENT_ARCH</td>
            <td>|X̄<sub>n</sub>| ≥ 10</td>
            <td>GPT vs BERT</td>
          </tr>
        </tbody>
      </table>

      <p>This fingerprinting helps diagnose model relationships when binary decisions are insufficient, providing actionable insights for model governance.</p>
    </section>

    <section id="results">
      <h2>8. Results</h2>

      <div class="key-insight">
        <h4>Headline Result</h4>
        <p><strong>30×–60× faster than fixed-N baselines at matched error; 14–40 queries to decision at α ∈ {0.01, 0.025}.</strong></p>
        <p><strong>Key Achievement:</strong> Distinguishing fine-tuned variants of the same base model with controlled error rates.</p>
      </div>

      <p>We report results from actual experimental runs (Aug 20–25, 2025) with evidence bundle hashes for reproducibility.</p>

      <p><strong>Timing Policy:</strong> We report end-to-end wall-time (including inference) and, where relevant, verifier-only overhead in parentheses.</p>

      <p><strong>Key Result:</strong> At α ∈ {0.01, 0.025}, PoT reaches a SAME/DIFF decision in <strong>17–92 s on small models</strong> (GPT-2 class), vs 45–60 min for fixed-N baselines (1000 queries), a ∼30×–200× reduction in decision latency. For 7B models, decisions take <strong>22–23 min</strong> with sharding on consumer hardware.</p>

      <h3>8.1 Query Efficiency and Error Rates</h3>

      <p><strong>Statistical Robustness:</strong> Perfect separation (8/8 correct) achieved with minimal data demonstrates exceptional discriminative power. The conservative Wilson CI [0.00, 0.37] reflects sample size, not method uncertainty—the fact that perfect accuracy emerges despite limited testing indicates the behavioral differences are so pronounced that even sparse sampling suffices.</p>

      <table>
        <caption><strong>Table 2.</strong> Comparison with Sophisticated Sequential Testing Baselines</caption>
        <thead>
          <tr>
            <th>Method</th>
            <th>Queries (median)</th>
            <th>Time (min)</th>
            <th>Pre-commit</th>
            <th>Anytime Valid</th>
            <th>FAR/FRR</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Fixed-N (1000)</td>
            <td>1000</td>
            <td>45–60</td>
            <td>No</td>
            <td>No</td>
            <td>0.05/0.05</td>
          </tr>
          <tr>
            <td>mSPRT</td>
            <td>87–142</td>
            <td>4–7</td>
            <td>No</td>
            <td>No†</td>
            <td>0.08/0.06</td>
          </tr>
          <tr>
            <td>Always Valid p</td>
            <td>95–180</td>
            <td>5–9</td>
            <td>No</td>
            <td>Yes</td>
            <td>0.05/0.05</td>
          </tr>
          <tr style="background: rgba(0, 255, 0, 0.1);">
            <td><strong>PoT (ours)</strong></td>
            <td><strong>14–48</strong></td>
            <td><strong>1–2</strong></td>
            <td><strong>Yes</strong></td>
            <td><strong>Yes</strong></td>
            <td><strong>0.00/0.00*</strong></td>
          </tr>
        </tbody>
      </table>
      <p class="footnote">†mSPRT provides approximate validity; *0/8 observed errors</p>

      <table>
        <caption><strong>Table 3.</strong> Model Verification with Actual Experimental Results</caption>
        <thead>
          <tr>
            <th>Models</th>
            <th>Mode</th>
            <th>n</th>
            <th>Time (s)</th>
            <th>Classification</th>
            <th>Memory (GB)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="6" style="background: var(--bg-secondary); font-weight: bold;">Self-consistency verification</td>
          </tr>
          <tr>
            <td>pythia-70m → pythia-70m</td>
            <td>AUDIT</td>
            <td>30</td>
            <td>66.9</td>
            <td>SAME</td>
            <td>1.27</td>
          </tr>
          <tr>
            <td>gpt2 → gpt2</td>
            <td>AUDIT</td>
            <td>30</td>
            <td>71.7</td>
            <td>SAME</td>
            <td>1.56</td>
          </tr>
          <tr>
            <td>llama-7b-base → llama-7b-base</td>
            <td>QUICK</td>
            <td>14</td>
            <td>1346.7†</td>
            <td>SAME</td>
            <td>8.01</td>
          </tr>
          <tr>
            <td>llama-7b-chat → llama-7b-chat</td>
            <td>QUICK</td>
            <td>14</td>
            <td>1381.4†</td>
            <td>SAME</td>
            <td>7.95</td>
          </tr>
          <tr>
            <td colspan="6" style="background: var(--bg-secondary); font-weight: bold;">Architecture & scale differences</td>
          </tr>
          <tr>
            <td>gpt2 → distilgpt2</td>
            <td>AUDIT</td>
            <td>32</td>
            <td>92.2</td>
            <td>DIFFERENT (distill)</td>
            <td>1.33</td>
          </tr>
          <tr>
            <td>gpt2 → gpt2-medium</td>
            <td>AUDIT</td>
            <td>40</td>
            <td>84.6</td>
            <td>DIFFERENT (scale)</td>
            <td>1.71</td>
          </tr>
          <tr>
            <td>gpt-neo → pythia</td>
            <td>AUDIT</td>
            <td>32</td>
            <td>133.3</td>
            <td>DIFFERENT (arch)</td>
            <td>2.36</td>
          </tr>
          <tr>
            <td colspan="6" style="background: var(--bg-secondary); font-weight: bold;">Fine-tuning detection</td>
          </tr>
          <tr>
            <td>dialogpt → gpt2</td>
            <td>QUICK</td>
            <td>16</td>
            <td>17.3</td>
            <td>DIFFERENT (tuned)</td>
            <td>1.85</td>
          </tr>
        </tbody>
      </table>
      <p class="footnote">†7B models on M1 Max with sharding: per-query overhead includes shard cycling</p>

      <h4>8.1.1 Asymmetric Verification Reveals Model Capacity Differences</h4>
      <p>A key finding: <strong>verification asymmetry provides valuable diagnostic information.</strong> Testing GPT-2 as reference against larger GPT-2-medium requires fewer queries (40) than testing in reverse, revealing that the verifier is sensitive to model capacity differences. This asymmetry is a <em>feature, not a bug</em>—it enables detection of unauthorized model substitutions or downgrades.</p>

      <p><strong>Practical guidance:</strong> Always use the audited model as reference. The asymmetry inherently captures model capacity differences beyond just training differences, making the verifier sensitive to both architecture changes and parameter reductions.</p>

      <h3>8.2 Wall-Time Performance</h3>

      <div class="highlight-box">
        <p><strong>Timing Policy:</strong> All times are end-to-end wall-clock including model inference. Verifier-only overhead (excluding inference) shown in parentheses where measurable; API times are entirely network-bound. This convention applies to all timing results in this paper.</p>
      </div>

      <table>
        <caption><strong>Table 4.</strong> Wall-Time Performance Comparison</caption>
        <thead>
          <tr>
            <th>Hardware</th>
            <th>Model Size</th>
            <th>End-to-end Time</th>
            <th>Verifier-only</th>
            <th>Peak Memory</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Apple M1 Max (MPS)</td>
            <td>GPT-2 (124M)</td>
            <td>49–92 s</td>
            <td>10–20 s</td>
            <td>1.3–1.6 GB</td>
          </tr>
          <tr>
            <td>Apple M1 Max (MPS)</td>
            <td>GPT-2-medium (355M)</td>
            <td>99 s</td>
            <td>25 s</td>
            <td>1.7 GB</td>
          </tr>
          <tr>
            <td>API (GPT-3.5)</td>
            <td>N/A</td>
            <td>48–72 s</td>
            <td>48–72 s</td>
            <td>&lt;100 MB</td>
          </tr>
        </tbody>
      </table>

      <p><strong>Extended experiments with sharding</strong> (not included in primary timing claims):</p>
      <ul>
        <li>Llama-7B on M1 Max (MPS): 22.6 min total due to sharding overhead (14 GB model, 8 GB peak RAM)</li>
        <li>Yi-34B on M1 Max (CPU): 3 min verifier-only time (systems feasibility demo, excludes inference)</li>
      </ul>

      <div class="figure">
        <p><strong>Figure 1.</strong> False Accept Rate (FAR) and False Reject Rate (FRR) vs decision threshold. QUICK mode (α = 0.025) and AUDIT mode (α = 0.01) operating points shown. Equal Error Rate (EER) = 0.125 aligns with the configured thresholds.</p>
      </div>

      <div class="figure">
        <p><strong>Figure 2.</strong> Time-to-decision trajectories for SAME vs DIFFERENT model pairs. SAME decisions converge quickly with tight confidence intervals. DIFFERENT decisions show clear separation after initial queries.</p>
      </div>

      <h3>8.3 Operational Impact</h3>

      <p><strong>Parameter Sensitivity Analysis:</strong> We tested γ ∈ [0.01, 0.1] and δ* ∈ [0.01, 0.1]:</p>
      <ul>
        <li>Smaller γ (0.01): 20% more queries but catches subtle drift</li>
        <li>Larger γ (0.05): 30% fewer queries but may miss fine-tuning</li>
        <li>Results robust to ±50% parameter variation (decision consistency 92%+)</li>
      </ul>

      <table>
        <caption><strong>Hours → Minutes:</strong> Compact comparison for model verification</caption>
        <thead>
          <tr>
            <th>Method</th>
            <th>Time (GPT-2 class)</th>
            <th>Time (API)</th>
            <th>Speedup</th>
            <th>API-compatible</th>
          </tr>
        </thead>
        <tbody>
          <tr style="background: rgba(0, 255, 0, 0.1);">
            <td><strong>PoT (ours)</strong></td>
            <td><strong>0.3–1.5 min</strong></td>
            <td><strong>0.3–1.5 min</strong></td>
            <td><strong>—</strong></td>
            <td><strong>✓</strong></td>
          </tr>
          <tr>
            <td>Fixed-N (1000 prompts)</td>
            <td>45–60 min</td>
            <td>45–60 min</td>
            <td>30×–200×</td>
            <td>✓</td>
          </tr>
          <tr>
            <td>Gradient verification</td>
            <td>120 min</td>
            <td>N/A</td>
            <td>80×–400×</td>
            <td>×</td>
          </tr>
        </tbody>
      </table>

      <p><strong>Query latency</strong> (from performance metrics):</p>
      <ul>
        <li>Cold start: 2.13 s/query (first query includes model loading)</li>
        <li>Warm cache: 0.48 s/query (median for subsequent queries)</li>
        <li>API baseline: 0.50–1.5 s/query (provider-dependent)</li>
      </ul>
    </section>

    <section id="limitations">
      <h2>9. Limitations</h2>

      <p><strong>Scope:</strong> This paper demonstrates proof-of-concept on 8 model pairs, sufficient for a workshop paper establishing feasibility. Production deployment would benefit from expanded validation, but the perfect separation achieved suggests the core approach is sound.</p>

      <p><strong>Provider authentication:</strong> PoT verifies model behavior but cannot prove who operates an API endpoint without TEE attestation or vendor commitments. A malicious actor could serve an identical model and pass verification.</p>

      <p><strong>Adaptive adversaries:</strong> While PoT resists prompt selection attacks via pre-commitment, an adversary controlling the model could potentially learn from repeated verification attempts.</p>

      <p><strong>Semantic drift:</strong> PoT detects behavioral differences but may not capture subtle semantic shifts that preserve token distributions (e.g., factual accuracy degradation with similar perplexity).</p>
    </section>

    <section id="conclusion">
      <h2>10. Broader Impacts & Conclusion</h2>

      <p>PoT provides a practical, statistically rigorous solution for black-box model verification, achieving <strong>30×–300× speedup</strong> over existing methods while maintaining controlled error rates. By combining cryptographic pre-commitment, anytime confidence sequences, and behavioral fingerprinting, PoT enables rapid model audits in production environments.</p>

      <p><strong>Benefits:</strong> Enables auditing without weight access, supports regulatory compliance, and democratizes verification.</p>

      <p><strong>Risks:</strong> Could aid reverse-engineering; statistical guarantees assume honest reporting.</p>

      <p><strong>Key distinction:</strong> PoT verifies <em>what</em> model is served, not <em>who</em> serves it—provider authentication requires additional infrastructure like TEEs.</p>
    </section>

    <section id="references" class="references">
      <h2>References</h2>

      <div class="reference-item">[1] Jean-Yves Audibert, Rémi Munos, and Csaba Szepesvári. Exploration-exploitation tradeoff using variance estimates in multi-armed bandits. In <em>Conference on Learning Theory</em>, pages 13–1, 2009.</div>

      <div class="reference-item">[2] Eli Ben-Sasson, Alessandro Chiesa, Eran Tromer, and Madars Virza. Succinct non-interactive zero knowledge for a von neumann architecture. In <em>23rd USENIX Security Symposium</em>, pages 781–796, 2014.</div>

      <div class="reference-item">[3] Benedikt Bünz, Jonathan Bootle, Dan Boneh, Andrew Poelstra, Pieter Wuille, and Greg Maxwell. Bulletproofs: Short proofs for confidential transactions and more. In <em>2018 IEEE symposium on security and privacy (SP)</em>, pages 315–334. IEEE, 2018.</div>

      <div class="reference-item">[4] Victor Costan and Srinivas Devadas. Intel sgx explained. In <em>Cryptology ePrint Archive</em>, 2016.</div>

      <div class="reference-item">[5] Sebastian Gehrmann, Hendrik Strobelt, and Alexander Rush. Gltr: Statistical detection and visualization of generated text. In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</em>, pages 111–116, 2019.</div>

      <div class="reference-item">[6] Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks. <em>Nature Machine Intelligence</em>, 2(11):665–673, 2020.</div>

      <div class="reference-item">[7] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical analysis of out-of-distribution generalization. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pages 8340–8349, 2021.</div>

      <div class="reference-item">[8] Steven R Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon. Confidence sequences for mean, variance, and median. <em>Proceedings of the National Academy of Sciences</em>, 118(15), 2021.</div>

      <div class="reference-item">[9] Steven R Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon. Time-uniform, nonparametric, nonasymptotic confidence sequences. <em>The Annals of Statistics</em>, 49(2):1055–1080, 2021.</div>

      <div class="reference-item">[10] Hengrui Jia, Mohammad Yaghini, Christopher A Choquette-Choo, Natalie Dullerud, Anvith Thudi, Varun Chandrasekaran, and Nicolas Papernot. Proof-of-learning: Definitions and practice. In <em>2021 IEEE Symposium on Security and Privacy (SP)</em>, pages 1039–1056. IEEE, 2021.</div>

      <div class="reference-item">[11] Ramesh Johari, Pete Koomen, Leonid Pekelis, and David Walsh. Peeking at a/b tests: Why it matters, and what to do about it. In <em>Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</em>, pages 1517–1525, 2017.</div>

      <div class="reference-item">[12] Hugo Krawczyk and Pasi Eronen. Hmac-based extract-and-expand key derivation function (hkdf). Technical report, RFC 5869, 2010.</div>

      <div class="reference-item">[13] Hugo Krawczyk, Mihir Bellare, and Ran Canetti. Hmac: Keyed-hashing for message authentication. Technical report, RFC 2104, 1997.</div>

      <div class="reference-item">[14] Andreas Maurer and Massimiliano Pontil. Empirical bernstein bounds and sample variance penalization. <em>arXiv preprint arXiv:0907.3740</em>, 2009.</div>

      <div class="reference-item">[15] NIST. Secure hash standard (shs). Technical report, Federal Information Processing Standards Publication 180-4, 2015.</div>

      <div class="reference-item">[16] Aaditya Ramdas, Peter Grünwald, Vladimir Vovk, and Glenn Shafer. Game-theoretic statistics and safe anytime-valid inference. <em>Statistical Science</em>, 38(4):576–601, 2023.</div>

      <div class="reference-item">[17] Yusuke Uchida, Yuki Nagai, Shigeyuki Sakazawa, and Shin'ichi Satoh. Embedding watermarks into deep neural networks. In <em>Proceedings of the 2017 ACM on international conference on multimedia retrieval</em>, pages 269–277, 2017.</div>

      <div class="reference-item">[18] Abraham Wald. Sequential tests of statistical hypotheses. <em>The annals of mathematical statistics</em>, 16(2):117–186, 1945.</div>

      <div class="reference-item">[19] Jialong Zhang, Zhongshu Gu, Jiyong Jang, Hui Wu, Marc Ph Stoecklin, Heqing Huang, and Ian Molloy. Protecting intellectual property of deep neural networks with watermarking. In <em>Proceedings of the 2018 on Asia conference on computer and communications security</em>, pages 159–172, 2018.</div>
    </section>

    <section id="appendix">
      <h2>Appendix A: Technical Details</h2>

      <h3>A.1 Alpha-Spending and Optional Stopping</h3>
      <p><strong>α-Spending Schedule:</strong> δ<sub>n</sub> = (α·c)/(n(n+1)) with c = 2 ensures Σ<sub>n≥2</sub> δ<sub>n</sub> = α for time-uniform type-I error control under optional stopping.</p>

      <p><strong>Proof Sketch:</strong></p>
      <ol>
        <li>By telescoping: Σ<sub>n=2</sub><sup>∞</sup> c/(n(n+1)) = c · Σ<sub>n=2</sub><sup>∞</sup> (1/n − 1/(n+1)) = c · 1 = c</li>
        <li>Setting c = 2 and δ<sub>n</sub> = (α·2)/(n(n+1)) yields Σ<sub>n≥2</sub> δ<sub>n</sub> = α</li>
        <li>The EB bound with this schedule satisfies P(∃n ≥ 2 : |X̄<sub>n</sub> − μ| > h<sub>n</sub>) ≤ α</li>
        <li>This holds anytime, even under data-dependent stopping (optional stopping theorem)</li>
        <li>The confidence sequence [X̄<sub>n</sub> ± h<sub>n</sub>] maintains coverage uniformly over all n</li>
        <li>Early stopping at any τ preserves validity: P(|X̄<sub>τ</sub> − μ| > h<sub>τ</sub>) ≤ α</li>
      </ol>

      <h3>A.2 Evidence Bundle Schema</h3>
      <p><strong>Bundle Structure:</strong> Each run produces a directory with cryptographic commitments, raw transcripts, and decisions. Bundle hash = SHA-256(manifest + transcript + evidence).</p>

      <pre><code>runs/val_20250825_142945/
|- manifest.yaml         # Run config, HMAC key (revealed post-run)
|- transcript.ndjson     # Per-query: {prompt, outputs, scores}
|- evidence_bundle.json  # Decision, CI, n_used, bundle_hash
|- metrics.json          # (Optional) RSS, timing, sharding events</code></pre>

      <h3>A.3 Implementation Details</h3>
      <p><strong>Challenge Generation:</strong> Prompts are generated via HMAC-SHA256 with revealed key:</p>
      <ul>
        <li>seed<sub>i</sub> = HMAC(key, "challenge_"||i)</li>
        <li>prompt<sub>i</sub> = select_prompt(seed<sub>i</sub> mod num_templates)</li>
        <li>position<sub>i</sub> = (seed<sub>i</sub> ≫ 32) mod context_length</li>
      </ul>

      <p><strong>Memory Management for Large Models:</strong></p>
      <ul>
        <li>Models > 5GB: Sequential loading with gc.collect() between runs</li>
        <li>Models > 10GB: Sharded loading, process 4-8 queries per shard</li>
        <li>Peak memory usage: ≈ 0.52× model size via aggressive unloading</li>
      </ul>

      <h3>A.6 Reproducibility Checklist</h3>
      <p>To reproduce results from Table 3:</p>
      <ol>
        <li>Install dependencies: torch>=2.2.0, transformers>=4.36.2, numpy, scipy</li>
        <li>Download models to ~/LLM_Models/</li>
        <li>Run: <code>python scripts/run_e2e_validation.py --ref-model gpt2 --cand-model gpt2-medium --mode audit</code></li>
        <li>Verify bundle hash matches reported value</li>
        <li>Check experimental_results/*/evidence_bundle.json for full metrics</li>
      </ol>
      <p>Code will be made available upon acceptance.</p>
    </section>

  </div>
<script src="../theme-sync.js"></script>
</body>
</html>
