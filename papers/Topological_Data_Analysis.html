<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Topological Data Analysis: Extracting Geometric Structure from Data | Rohan Vinaik</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;700&display=swap" rel="stylesheet">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    :root {
      --bg: #1a1a1a;
      --text: #e0e0e0;
      --text-secondary: #808080;
      --accent: #00ffff;
      --border: rgba(255, 255, 255, 0.1);
      --code-bg: #222222;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'JetBrains Mono', monospace;
      background: var(--bg);
      color: var(--text);
      line-height: 1.6;
      padding: 20px;
      max-width: 900px;
      margin: 0 auto;
    }
    h1 {
      color: var(--accent);
      font-size: 1.5rem;
      margin-bottom: 8px;
      letter-spacing: 0.02em;
    }
    h2 {
      color: var(--accent);
      font-size: 1.1rem;
      margin-top: 32px;
      margin-bottom: 16px;
      padding-bottom: 8px;
      border-bottom: 1px solid var(--border);
    }
    h3 {
      color: var(--accent);
      font-size: 0.95rem;
      margin-top: 24px;
      margin-bottom: 12px;
    }
    h4 {
      color: var(--text);
      font-size: 0.85rem;
      margin-top: 20px;
      margin-bottom: 10px;
      font-weight: 600;
    }
    p { margin-bottom: 16px; font-size: 0.85rem; }
    a {
      color: var(--accent);
      text-decoration: none;
      border-bottom: 1px dotted var(--accent);
    }
    a:hover { border-bottom-style: solid; }
    .back-link {
      display: inline-block;
      margin-bottom: 24px;
      font-size: 0.85rem;
    }
    .paper-meta {
      color: var(--text-secondary);
      font-size: 0.75rem;
      margin-bottom: 24px;
    }
    .abstract {
      background: var(--code-bg);
      padding: 20px;
      border-left: 3px solid var(--accent);
      margin-bottom: 32px;
      font-size: 0.85rem;
    }
    .tags {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 32px;
    }
    .tag {
      background: var(--code-bg);
      padding: 4px 12px;
      border: 1px solid var(--border);
      font-size: 0.7rem;
      color: var(--accent);
      text-decoration: none;
      border-bottom: none;
    }
    .tag:hover {
      background: var(--accent);
      color: var(--bg);
      border-color: var(--accent);
    }
    .quick-nav {
      background: var(--code-bg);
      padding: 16px;
      margin-bottom: 32px;
      border: 1px solid var(--border);
    }
    .quick-nav h3 {
      margin-top: 0;
      font-size: 0.85rem;
    }
    .quick-nav ul {
      list-style: none;
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 8px;
      margin-top: 12px;
    }
    .quick-nav a {
      font-size: 0.75rem;
      border-bottom: none;
      padding: 4px 0;
      display: block;
    }
    .quick-nav a:hover { color: var(--bg); background: var(--accent); padding-left: 8px; }
    .code-block {
      background: var(--code-bg);
      padding: 16px;
      margin: 16px 0;
      border-left: 2px solid var(--accent);
      font-size: 0.75rem;
      white-space: pre-wrap;
      overflow-x: auto;
    }
    ul {
      margin-left: 20px;
      margin-bottom: 16px;
    }
    ul li {
      font-size: 0.85rem;
      margin-bottom: 8px;
    }
    .references {
      font-size: 0.75rem;
      margin-top: 32px;
    }
    .references ol {
      padding-left: 20px;
    }
    .references li {
      margin-bottom: 12px;
      line-height: 1.5;
    }
    @media (max-width: 768px) {
      body { padding: 12px; }
      h1 { font-size: 1.2rem; }
      h2 { font-size: 1rem; }
    }
  </style>
</head>
<body>

<a href="../index.html#reference" class="back-link">← Back to Reference</a>

<h1>Topological Data Analysis: Extracting Geometric Structure from Data</h1>
<div class="paper-meta">January 2025 · Technical Reference</div>

<div class="tags">
  <a href="../index.html?filter=TOPOLOGICAL-DATA-ANALYSIS" class="tag">[TOPOLOGICAL-DATA-ANALYSIS]</a>
  <a href="../index.html?filter=PERSISTENT-HOMOLOGY" class="tag">[PERSISTENT-HOMOLOGY]</a>
  <a href="../index.html?filter=SIMPLICIAL-COMPLEXES" class="tag">[SIMPLICIAL-COMPLEXES]</a>
  <a href="../index.html?filter=COMPUTATIONAL-TOPOLOGY" class="tag">[COMPUTATIONAL-TOPOLOGY]</a>
  <a href="../index.html?filter=GEOMETRIC-DATA-ANALYSIS" class="tag">[GEOMETRIC-DATA-ANALYSIS]</a>
  <a href="../index.html?filter=MAPPER-ALGORITHM" class="tag">[MAPPER-ALGORITHM]</a>
  <a href="../index.html?filter=FILTRATIONS" class="tag">[FILTRATIONS]</a>
  <a href="../index.html?filter=BETTI-NUMBERS" class="tag">[BETTI-NUMBERS]</a>
  <a href="../index.html?filter=MACHINE-LEARNING" class="tag">[MACHINE-LEARNING]</a>
  <a href="../index.html?filter=MATHEMATICAL-FOUNDATIONS" class="tag">[MATHEMATICAL-FOUNDATIONS]</a>
</div>

<div class="abstract">
  <strong>Abstract:</strong> Topological Data Analysis (TDA) provides mathematical frameworks for extracting robust geometric and topological features from high-dimensional data. Through persistent homology, simplicial complex construction, and multi-scale filtrations, TDA identifies structural characteristics—clusters, loops, voids—that persist across scales. This methodology reveals shape-based features that remain stable under noise and coordinate transformations, offering principled approaches to understanding data geometry across scientific domains.
</div>

<div class="quick-nav">
  <h3>Quick Navigation</h3>
  <ul>
    <li><a href="#core-principles">1. Core Principles</a></li>
    <li><a href="#mathematical-foundations">2. Mathematical Foundations</a></li>
    <li><a href="#persistent-homology">3. Persistent Homology</a></li>
    <li><a href="#simplicial-complex-construction">4. Simplicial Complex Construction</a></li>
    <li><a href="#filtrations-and-multi-scale-analysis">5. Filtrations and Multi-Scale Analysis</a></li>
    <li><a href="#computational-methods">6. Computational Methods</a></li>
    <li><a href="#theoretical-connections">7. Theoretical Connections</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</div>

<h2 id="core-principles">1. Core Principles</h2>

<h3>1.1 Shape as Information</h3>

<p><strong>Core Insight:</strong> The "shape" of data—its topological structure—contains robust information that persists under noise and coordinate transformations.</p>

<p><strong>Key Distinction:</strong></p>
<div class="code-block">Traditional methods: Focus on coordinates and distances
TDA: Focus on relationships and connectivity

Example:
  Traditional: Points at (x₁, y₁), (x₂, y₂), ...
  TDA: "Three clusters with two loops between them"</div>

<p><strong>Advantages:</strong></p>
<ul>
  <li><strong>Coordinate-free:</strong> Results independent of coordinate system</li>
  <li><strong>Noise-resistant:</strong> Topological features persist under perturbations</li>
  <li><strong>Multi-scale:</strong> Captures structure at all scales simultaneously</li>
  <li><strong>Interpretable:</strong> Geometric features have clear meaning</li>
</ul>

<h3>1.2 Persistence as Significance</h3>

<p><strong>Definition:</strong> Topological features existing across wide range of scales are "significant"; those appearing briefly are likely noise.</p>

<p><strong>Persistence Diagram:</strong></p>
<div class="code-block">Birth-Death pairs: (bᵢ, dᵢ)
  bᵢ: Scale at which feature appears
  dᵢ: Scale at which feature disappears
  Persistence: pᵢ = dᵢ - bᵢ

Long persistence → True structure
Short persistence → Noise</div>

<h3>1.3 Homology Dimensions</h3>

<p><strong>H₀ (0-dimensional):</strong> Connected components</p>
<ul>
  <li>Interpretation: Clusters, separate groups</li>
  <li>Example: Distinct populations in data</li>
</ul>

<p><strong>H₁ (1-dimensional):</strong> Loops, cycles</p>
<ul>
  <li>Interpretation: Circular structures, feedback loops</li>
  <li>Example: Cyclic processes, periodic patterns</li>
</ul>

<p><strong>H₂ (2-dimensional):</strong> Voids, cavities</p>
<ul>
  <li>Interpretation: 3D holes, missing data regions</li>
  <li>Example: Unfilled parameter space</li>
</ul>

<h2 id="mathematical-foundations">2. Mathematical Foundations</h2>

<h3>2.1 Simplicial Complexes</h3>

<p><strong>Definition:</strong> Collection of simplices (points, edges, triangles, tetrahedra) satisfying closure properties.</p>

<p><strong>Formal Structure:</strong></p>
<div class="code-block">Simplex σ: Convex hull of k+1 affinely independent points
  0-simplex: Vertex (point)
  1-simplex: Edge (line segment)
  2-simplex: Triangle (filled)
  3-simplex: Tetrahedron (filled)

Simplicial complex K:
  - If σ ∈ K, then all faces of σ are in K
  - Intersection of simplices is either empty or shared face</div>

<h3>2.2 Homology Groups</h3>

<p><strong>Definition:</strong> Homology groups \(H_k(K)\) capture k-dimensional holes in complex K.</p>

<p><strong>Intuition:</strong></p>
<div class="code-block">H₀: Number of connected components - 1
H₁: Number of independent loops
H₂: Number of independent voids</div>

<p><strong>Betti Numbers:</strong></p>
<div class="code-block">βₖ = rank(Hₖ) = dimension of k-th homology group

Interpretation:
  β₀ = 3 → 3 connected components
  β₁ = 2 → 2 independent loops
  β₂ = 1 → 1 void</div>

<p><strong>Computation via Boundary Operators:</strong></p>
<div class="code-block">∂ₖ: Cₖ → Cₖ₋₁ (maps k-chains to (k-1)-chains)

Homology:
  Hₖ = ker(∂ₖ) / im(∂ₖ₊₁)
     = k-cycles / k-boundaries</div>

<h3>2.3 Filtrations</h3>

<p><strong>Definition:</strong> Nested sequence of simplicial complexes:</p>
<div class="code-block">∅ = K₀ ⊆ K₁ ⊆ K₂ ⊆ ... ⊆ Kₙ = K</div>

<p><strong>Common Types:</strong></p>

<h4>Rips Filtration</h4>
<div class="code-block">Kᵣ = {σ | diameter(σ) ≤ r}
Add simplex when all pairwise distances ≤ r</div>

<h4>Čech Filtration</h4>
<div class="code-block">Kᵣ = {σ | balls of radius r around vertices intersect}
More accurate but computationally expensive</div>

<h4>Alpha Complex</h4>
<div class="code-block">Kᵣ = {σ | σ face of Delaunay triangulation, circumradius ≤ r}
Optimal for Euclidean data</div>

<h2 id="persistent-homology">3. Persistent Homology</h2>

<h3>3.1 Birth-Death Pairs</h3>

<p><strong>Definition:</strong> Track when each homology class appears (birth) and disappears (death) in filtration.</p>

<p><strong>Conceptual Algorithm:</strong></p>
<div class="code-block">For each dimension:
  1. Compute homology at each filtration level
  2. Track when classes appear (birth)
  3. Track when classes disappear (death)
  4. Record (dimension, birth, death) pairs</div>

<h3>3.2 Persistence Diagrams</h3>

<p><strong>Representation:</strong> Plot (birth, death) pairs in 2D plane.</p>

<p><strong>Properties:</strong></p>
<div class="code-block">1. All points above diagonal (death ≥ birth)
2. Points far from diagonal: High persistence (signal)
3. Points near diagonal: Low persistence (noise)</div>

<p><strong>Interpretation Strategy:</strong></p>
<div class="code-block">Set persistence threshold θ
Features with persistence > θ considered significant
Features with persistence ≤ θ considered noise</div>

<h3>3.3 Barcodes</h3>

<p><strong>Alternative Representation:</strong> Horizontal bars showing feature lifespans.</p>

<p><strong>Format:</strong></p>
<div class="code-block">Feature 1: |=============================| (long bar = signal)
Feature 2: |==|                          (short bar = noise)
Feature 3: |====================|        (medium bar)</div>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Intuitive visual interpretation</li>
  <li>Direct comparison across datasets</li>
  <li>Clear signal-noise separation</li>
</ul>

<h2 id="simplicial-complex-construction">4. Simplicial Complex Construction</h2>

<h3>4.1 Vietoris-Rips Complex</h3>

<p><strong>Definition:</strong> Include k-simplex if all pairwise distances ≤ r.</p>

<p><strong>Properties:</strong></p>
<div class="code-block">Advantages:
  - Simple to implement
  - Captures connectivity well

Disadvantages:
  - Many redundant simplices
  - Computationally expensive: O(n^(d+2))</div>

<h3>4.2 Alpha Complex</h3>

<p><strong>Definition:</strong> Nerve of union of balls around points.</p>

<p><strong>Construction:</strong> Via Delaunay triangulation, filtered by circumradius.</p>

<p><strong>Properties:</strong></p>
<div class="code-block">Advantages:
  - Fewer simplices than Rips
  - Theoretically optimal for Euclidean data

Disadvantages:
  - Requires Euclidean embedding
  - Delaunay computation: O(n^⌈d/2⌉)</div>

<h3>4.3 Witness Complex</h3>

<p><strong>Purpose:</strong> Landmark-based approximation for large datasets.</p>

<p><strong>Approach:</strong></p>
<div class="code-block">1. Select subset of landmarks
2. Each data point "witnesses" nearby landmarks
3. Include simplex if witnessed by some point</div>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Scalable to millions of points</li>
  <li>Preserves topological features</li>
  <li>Reduces computational burden</li>
</ul>

<h2 id="filtrations-and-multi-scale-analysis">5. Filtrations and Multi-Scale Analysis</h2>

<h3>5.1 Distance-to-Measure (DTM)</h3>

<p><strong>Purpose:</strong> Robust filtration resistant to outliers.</p>

<p><strong>Definition:</strong></p>
<div class="code-block">DTM(x, k) = √(1/k ∑ᵢ₌₁ᵏ d(x, xᵢ)²)

where x₁, ..., xₖ are k nearest neighbors</div>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Robust to outliers</li>
  <li>Statistically principled</li>
  <li>Cleaner persistence diagrams</li>
</ul>

<h3>5.2 Adaptive Filtrations</h3>

<p><strong>Concept:</strong> Use data-dependent scales rather than uniform thresholds.</p>

<p><strong>Density-Based Approach:</strong></p>
<div class="code-block">Dense regions: Use smaller scales
Sparse regions: Use larger scales

Result: Uniform topological sensitivity across data</div>

<h2 id="computational-methods">6. Computational Methods</h2>

<h3>6.1 Matrix Reduction Algorithm</h3>

<p><strong>Core Approach:</strong> Reduce boundary matrix to compute persistent homology.</p>

<p><strong>Key Steps:</strong></p>
<div class="code-block">1. Construct boundary matrix
2. Apply column reduction (eliminate pivots)
3. Record birth-death pairs from reduction
4. Output persistence diagram</div>

<p><strong>Optimizations:</strong></p>
<ul>
  <li>Clearing: Skip unnecessary columns</li>
  <li>Compression: Store only non-zero entries</li>
  <li>Cohomology: Dual algorithm (often faster)</li>
</ul>

<h3>6.2 Mapper Algorithm</h3>

<p><strong>Purpose:</strong> Create simplified network representation of data.</p>

<p><strong>Procedure:</strong></p>
<div class="code-block">1. Choose filter function (projection, density, etc.)
2. Partition filter range into overlapping intervals
3. Cluster points in each interval
4. Connect clusters sharing points

Output: Graph where nodes = clusters, edges = overlap</div>

<p><strong>Applications:</strong></p>
<ul>
  <li>Dimensionality reduction with topology preservation</li>
  <li>Visual exploration of high-dimensional data</li>
  <li>Network construction from point clouds</li>
</ul>

<h3>6.3 Common Filter Functions</h3>

<h4>Density Estimation</h4>
<div class="code-block">Filter by local point density
Reveals data manifold structure</div>

<h4>PCA Projection</h4>
<div class="code-block">Project to principal component
Captures main variation direction</div>

<h4>Eccentricity</h4>
<div class="code-block">Average distance to all other points
Identifies data periphery</div>

<h2 id="theoretical-connections">7. Theoretical Connections</h2>

<h3>7.1 Compressed Sensing</h3>

<p><strong>Connection:</strong> Random projections preserve topological structure.</p>

<p><strong>Relevant Results:</strong></p>
<ul>
  <li>Johnson-Lindenstrauss theorem applies to persistence</li>
  <li>Can compute homology from random projections</li>
  <li>Dimensionality reduction preserves topological features</li>
</ul>

<h3>7.2 Information Theory</h3>

<p><strong>Topological Entropy:</strong></p>
<div class="code-block">H_top = -∑ᵢ pᵢ log pᵢ

where pᵢ = persistence of feature i / total persistence</div>

<p><strong>Applications:</strong></p>
<ul>
  <li>Quantify topological complexity</li>
  <li>Compare datasets via topological signatures</li>
  <li>Feature selection based on information content</li>
</ul>

<h3>7.3 Machine Learning Integration</h3>

<p><strong>Feature Extraction:</strong></p>
<div class="code-block">Use persistence diagrams as features:
  - Betti curves: βₖ(r) vs r
  - Persistence landscapes: Functional summaries
  - Persistence images: Vectorized diagrams</div>

<p><strong>Kernel Methods:</strong></p>
<div class="code-block">Define kernels on persistence diagrams
Enable: SVM, kernel PCA on topological features</div>

<div class="references">
  <h2 id="references">References</h2>
  <ol>
    <li><strong>Carlsson, G.</strong> (2009). Topology and data. <em>Bulletin of the American Mathematical Society</em>, 46(2), 255-308.</li>
    <li><strong>Edelsbrunner, H., & Harer, J.</strong> (2008). Persistent homology—a survey. <em>Contemporary Mathematics</em>, 453, 257-282.</li>
    <li><strong>Chazal, F., & Michel, B.</strong> (2021). An introduction to Topological Data Analysis. <em>Frontiers in Artificial Intelligence</em>, 4, 108.</li>
    <li><strong>Singh, G., Mémoli, F., & Carlsson, G.</strong> (2007). Topological Methods for the Analysis of High Dimensional Data Sets. <em>Eurographics Symposium on Point-Based Graphics</em>.</li>
    <li><strong>Wasserman, L.</strong> (2018). Topological data analysis. <em>Annual Review of Statistics and Its Application</em>, 5, 501-532.</li>
    <li><strong>Ghrist, R.</strong> (2008). Barcodes: The persistent topology of data. <em>Bulletin of the AMS</em>, 45(1), 61-75.</li>
  </ol>
</div>

<script src="../theme-sync.js"></script>
</body>
</html>
