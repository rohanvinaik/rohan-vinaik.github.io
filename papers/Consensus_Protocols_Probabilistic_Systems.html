<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Consensus Protocols for Probabilistic Systems | Rohan Vinaik</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;700&display=swap" rel="stylesheet">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    :root {
      --bg: #0a0a0a;
      --text: #e0e0e0;
      --text-secondary: #a0a0a0;
      --accent: #00ff00;
      --border: #333;
      --code-bg: #1a1a1a;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'JetBrains Mono', monospace;
      background: var(--bg);
      color: var(--text);
      line-height: 1.6;
      padding: 20px;
      max-width: 900px;
      margin: 0 auto;
    }
    h1 {
      color: var(--accent);
      font-size: 1.5rem;
      margin-bottom: 8px;
      letter-spacing: 0.02em;
    }
    h2 {
      color: var(--accent);
      font-size: 1.1rem;
      margin-top: 32px;
      margin-bottom: 16px;
      padding-bottom: 8px;
      border-bottom: 1px solid var(--border);
    }
    h3 {
      color: var(--accent);
      font-size: 0.95rem;
      margin-top: 24px;
      margin-bottom: 12px;
    }
    h4 {
      color: var(--text);
      font-size: 0.85rem;
      margin-top: 20px;
      margin-bottom: 10px;
      font-weight: 600;
    }
    p { margin-bottom: 16px; font-size: 0.85rem; }
    ul, ol {
      margin-bottom: 16px;
      margin-left: 24px;
      font-size: 0.85rem;
    }
    li { margin-bottom: 8px; }
    a {
      color: var(--accent);
      text-decoration: none;
      border-bottom: 1px dotted var(--accent);
    }
    a:hover { border-bottom-style: solid; }
    .back-link {
      display: inline-block;
      margin-bottom: 24px;
      font-size: 0.85rem;
    }
    .paper-meta {
      color: var(--text-secondary);
      font-size: 0.75rem;
      margin-bottom: 24px;
    }
    .abstract {
      background: var(--code-bg);
      padding: 20px;
      border-left: 3px solid var(--accent);
      margin-bottom: 32px;
      font-size: 0.85rem;
    }
    .tags {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 32px;
    }
    .tag {
      background: var(--code-bg);
      padding: 4px 12px;
      border: 1px solid var(--border);
      font-size: 0.7rem;
      color: var(--accent);
      text-decoration: none;
      border-bottom: none;
    }
    .tag:hover {
      background: var(--accent);
      color: var(--bg);
      border-color: var(--accent);
    }
    .quick-nav {
      background: var(--code-bg);
      padding: 16px;
      margin-bottom: 32px;
      border: 1px solid var(--border);
    }
    .quick-nav h3 {
      margin-top: 0;
      font-size: 0.85rem;
    }
    .quick-nav ul {
      list-style: none;
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 8px;
      margin-top: 12px;
      margin-left: 0;
    }
    .quick-nav a {
      font-size: 0.75rem;
      border-bottom: none;
      padding: 4px 0;
      display: block;
    }
    .quick-nav a:hover { color: var(--bg); background: var(--accent); padding-left: 8px; }
    .code-block {
      background: var(--code-bg);
      padding: 16px;
      border: 1px solid var(--border);
      margin: 16px 0;
      font-size: 0.75rem;
      overflow-x: auto;
      white-space: pre;
      font-family: 'JetBrains Mono', monospace;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
      font-size: 0.75rem;
    }
    th, td {
      border: 1px solid var(--border);
      padding: 12px;
      text-align: left;
    }
    th {
      background: var(--code-bg);
      color: var(--accent);
      font-weight: 600;
    }
    tr:nth-child(even) {
      background: rgba(26, 26, 26, 0.3);
    }
    .highlight-box {
      background: var(--code-bg);
      border-left: 3px solid var(--accent);
      padding: 16px;
      margin: 20px 0;
      font-size: 0.85rem;
    }
    .references {
      font-size: 0.75rem;
      margin-top: 32px;
    }
    .references ol {
      padding-left: 20px;
    }
    .references li {
      margin-bottom: 12px;
      line-height: 1.5;
    }
    @media (max-width: 768px) {
      body { padding: 12px; }
      h1 { font-size: 1.2rem; }
      h2 { font-size: 1rem; }
      table { font-size: 0.65rem; }
      th, td { padding: 8px; }
    }
  </style>
</head>
<body>

<a href="../index.html#reference" class="back-link">← Back to Reference</a>

<h1>Consensus Protocols for Probabilistic Systems</h1>
<div class="paper-meta">January 2025 · Technical Reference · Version 2.0</div>

<div class="tags">
  <a href="../index.html?filter=CONSENSUS" class="tag">[CONSENSUS]</a>
  <a href="../index.html?filter=PROBABILISTIC-SYSTEMS" class="tag">[PROBABILISTIC-SYSTEMS]</a>
  <a href="../index.html?filter=DISTRIBUTED-COMPUTING" class="tag">[DISTRIBUTED-COMPUTING]</a>
  <a href="../index.html?filter=MAJORITY-VOTING" class="tag">[MAJORITY-VOTING]</a>
  <a href="../index.html?filter=ERROR-PROPAGATION" class="tag">[ERROR-PROPAGATION]</a>
  <a href="../index.html?filter=PRIVACY-PRESERVING-ML" class="tag">[PRIVACY-PRESERVING-ML]</a>
  <a href="../index.html?filter=SECURE-MPC" class="tag">[SECURE-MPC]</a>
  <a href="../index.html?filter=STATISTICAL-INFERENCE" class="tag">[STATISTICAL-INFERENCE]</a>
  <a href="../index.html?filter=CONFIDENCE-SEQUENCES" class="tag">[CONFIDENCE-SEQUENCES]</a>
  <a href="../index.html?filter=OPTIMIZATION" class="tag">[OPTIMIZATION]</a>
</div>

<div class="abstract">
  <strong>Abstract:</strong> This reference establishes a comprehensive framework for consensus protocols in probabilistic systems, transforming intentional uncertainty into tunable precision guarantees. We present mathematical foundations including majority voting theory, concentration inequalities, error propagation analysis, and confidence sequence construction. The framework applies broadly across privacy-preserving machine learning, secure multi-party computation, distributed sensor networks, Byzantine fault tolerance, and genomic analysis. We provide systematic parameter tuning methodologies mapping accuracy requirements to run counts, time budgets to parallelization strategies, and cost constraints to consensus thresholds. Trade-off analysis quantifies accuracy-latency-cost relationships with optimization algorithms for adaptive stopping, variance reduction, and resource allocation. Implementation patterns cover asynchronous consensus, quorum-based aggregation, and weighted voting schemes with concrete performance metrics.
</div>

<div class="quick-nav">
  <h3>Quick Navigation</h3>
  <ul>
    <li><a href="#general-framework">1. General Framework</a></li>
    <li><a href="#mathematical-tools">2. Mathematical Tools</a></li>
    <li><a href="#applications">3. Applications Beyond Genomics</a></li>
    <li><a href="#parameter-tuning">4. Parameter Tuning</a></li>
    <li><a href="#tradeoffs">5. Trade-offs</a></li>
    <li><a href="#implementation">6. Implementation Patterns</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</div>

<h2 id="general-framework">1. General Framework</h2>

<h3>1.1 Converting Intentional Uncertainty to Tunable Precision</h3>

<p>Probabilistic algorithms intentionally sacrifice deterministic guarantees for computational efficiency, privacy preservation, or fault tolerance. Consensus protocols reverse this trade-off: by running multiple independent trials and aggregating results, we recover precision guarantees while maintaining the computational advantages of the probabilistic approach.</p>

<div class="highlight-box">
<strong>Core Transformation:</strong><br>
Single probabilistic trial: Fast, uncertain output (error rate p)<br>
↓ [Consensus protocol with n trials]<br>
Aggregated result: Controlled precision (error rate exp(-Θ(n)))
</div>

<h4>Fundamental Properties</h4>

<ul>
  <li><strong>Tunability:</strong> Precision scales predictably with trial count via concentration inequalities</li>
  <li><strong>Parallelizability:</strong> Independent trials enable embarrassingly parallel execution</li>
  <li><strong>Anytime Validity:</strong> Partial results available at any stopping time with valid confidence bounds</li>
  <li><strong>Graceful Degradation:</strong> More resources monotonically improve precision</li>
</ul>

<h3>1.2 Consensus Fundamentals</h3>

<h4>Generic Protocol Structure</h4>

<div class="code-block">CONSENSUS-PROTOCOL(input, accuracy_target, confidence_level):
  // 1. Parameter determination
  n ← compute_trial_count(accuracy_target, confidence_level, p_error)

  // 2. Parallel execution
  results ← []
  parallel for i = 1 to n:
    results[i] ← PROBABILISTIC-ALGORITHM(input)

  // 3. Aggregation
  if discrete_output:
    consensus ← MAJORITY-VOTE(results)
  else:
    consensus ← WEIGHTED-MEAN(results, weights)

  // 4. Confidence bounds
  (lower_bound, upper_bound) ← CONFIDENCE-INTERVAL(results, confidence_level)

  return consensus, lower_bound, upper_bound
</div>

<h4>Aggregation Strategies</h4>

<table>
  <thead>
    <tr>
      <th>Strategy</th>
      <th>Output Type</th>
      <th>Advantage</th>
      <th>Typical Use Case</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Majority Vote</td>
      <td>Discrete</td>
      <td>Robust to outliers</td>
      <td>Classification, decision problems</td>
    </tr>
    <tr>
      <td>Mean</td>
      <td>Continuous</td>
      <td>Statistically efficient</td>
      <td>Numerical estimation</td>
    </tr>
    <tr>
      <td>Median</td>
      <td>Continuous</td>
      <td>Robust to heavy tails</td>
      <td>Noisy sensors, Byzantine settings</td>
    </tr>
    <tr>
      <td>Trimmed Mean</td>
      <td>Continuous</td>
      <td>Balance efficiency/robustness</td>
      <td>Distributed consensus with faults</td>
    </tr>
    <tr>
      <td>Weighted Mean</td>
      <td>Continuous</td>
      <td>Incorporates quality signals</td>
      <td>Heterogeneous sources</td>
    </tr>
  </tbody>
</table>

<h3>1.3 Precision Guarantees</h3>

<p>For binary outcomes with per-trial success probability \( p > 0.5 \), majority vote succeeds with probability approaching 1 exponentially fast:</p>

<div class="code-block">P(consensus correct) ≥ 1 - exp(-2n(p - 0.5)²)  [Hoeffding bound]

Examples (p = 0.7, target confidence 99%):
  n = 10:  P(correct) ≥ 92.8%
  n = 25:  P(correct) ≥ 99.3%
  n = 50:  P(correct) ≥ 99.98%
  n = 100: P(correct) ≥ 99.9999%
</div>

<p>For continuous estimation, error decreases as \( \sigma/\sqrt{n} \) (central limit theorem):</p>

<div class="code-block">Mean squared error: MSE(consensus) = σ²/n

Error reduction factor vs single trial:
  n = 10:  √10 ≈ 3.16× reduction
  n = 100: 10× reduction
  n = 1000: 31.6× reduction
</div>

<h2 id="mathematical-tools">2. Mathematical Tools</h2>

<h3>2.1 Majority Voting Theory</h3>

<h4>Exact Binomial Distribution</h4>

<p>For \( n \) independent Bernoulli trials with success probability \( p \), the probability that majority (at least \( k = \lceil n/2 \rceil \) trials) succeed is:</p>

<p>\[
P(\text{majority correct}) = \sum_{i=k}^{n} \binom{n}{i} p^i (1-p)^{n-i}
\]</p>

<div class="code-block">Python implementation:
from scipy.stats import binom

def majority_success_prob(n, p):
    k = (n + 1) // 2  # Majority threshold
    return 1 - binom.cdf(k - 1, n, p)

# Example: n=21 trials, p=0.6 per-trial accuracy
# P(majority correct) = 0.9801
</div>

<h4>Normal Approximation (Large n)</h4>

<p>For \( n \geq 30 \), the binomial distribution is well-approximated by a normal distribution:</p>

<p>\[
P(\text{majority correct}) \approx \Phi\left( \frac{(p - 0.5)\sqrt{n}}{\sqrt{p(1-p)}} \right)
\]</p>

<p>where \( \Phi \) is the standard normal cumulative distribution function.</p>

<table>
  <thead>
    <tr>
      <th>p (per-trial)</th>
      <th>n = 10</th>
      <th>n = 25</th>
      <th>n = 50</th>
      <th>n = 100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.55</td>
      <td>0.623</td>
      <td>0.734</td>
      <td>0.852</td>
      <td>0.956</td>
    </tr>
    <tr>
      <td>0.60</td>
      <td>0.754</td>
      <td>0.885</td>
      <td>0.971</td>
      <td>0.9987</td>
    </tr>
    <tr>
      <td>0.70</td>
      <td>0.945</td>
      <td>0.9936</td>
      <td>0.99998</td>
      <td>≈ 1</td>
    </tr>
    <tr>
      <td>0.80</td>
      <td>0.9936</td>
      <td>0.99998</td>
      <td>≈ 1</td>
      <td>≈ 1</td>
    </tr>
    <tr>
      <td>0.90</td>
      <td>0.99999</td>
      <td>≈ 1</td>
      <td>≈ 1</td>
      <td>≈ 1</td>
    </tr>
  </tbody>
</table>

<h4>Required Trials for Target Confidence</h4>

<p>To achieve confidence \( 1 - \delta \) (e.g., \( \delta = 0.01 \) for 99% confidence), solve for \( n \):</p>

<p>\[
n \geq \frac{\left(\Phi^{-1}(1-\delta)\right)^2 \cdot p(1-p)}{(p - 0.5)^2}
\]</p>

<table>
  <thead>
    <tr>
      <th>Confidence</th>
      <th>p = 0.6</th>
      <th>p = 0.7</th>
      <th>p = 0.8</th>
      <th>p = 0.9</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>95%</td>
      <td>165</td>
      <td>41</td>
      <td>17</td>
      <td>7</td>
    </tr>
    <tr>
      <td>99%</td>
      <td>266</td>
      <td>66</td>
      <td>27</td>
      <td>11</td>
    </tr>
    <tr>
      <td>99.9%</td>
      <td>414</td>
      <td>103</td>
      <td>42</td>
      <td>17</td>
    </tr>
    <tr>
      <td>99.99%</td>
      <td>577</td>
      <td>144</td>
      <td>58</td>
      <td>24</td>
    </tr>
  </tbody>
</table>

<h3>2.2 Concentration Inequalities</h3>

<h4>Hoeffding's Inequality</h4>

<p>For independent random variables \( X_1, \ldots, X_n \) bounded in \([0, 1]\) with sample mean \( \bar{X} = \frac{1}{n}\sum X_i \) and true mean \( \mu = E[\bar{X}] \):</p>

<p>\[
P(|\bar{X} - \mu| \geq \epsilon) \leq 2 \exp(-2n\epsilon^2)
\]</p>

<p><strong>Required samples for \( (\epsilon, \delta) \) guarantee:</strong></p>

<p>\[
n \geq \frac{1}{2\epsilon^2} \ln\left(\frac{2}{\delta}\right)
\]</p>

<div class="code-block">Example: 95% confidence (δ=0.05), 5% tolerance (ε=0.05)
  n ≥ (1/(2·0.0025)) · ln(40) ≈ 738 samples

Example: 99% confidence (δ=0.01), 1% tolerance (ε=0.01)
  n ≥ (1/(2·0.0001)) · ln(200) ≈ 26,492 samples
</div>

<h4>Chernoff Bounds</h4>

<p>Tighter bounds for sums of Bernoulli variables. Let \( X = \sum_{i=1}^n X_i \) where \( X_i \sim \text{Bernoulli}(p) \), and \( \mu = E[X] = np \).</p>

<p><strong>Lower tail (multiplicative):</strong></p>
<p>\[
P(X \leq (1-\delta)\mu) \leq \exp\left(-\frac{\delta^2 \mu}{2}\right)
\]</p>

<p><strong>Upper tail (multiplicative):</strong></p>
<p>\[
P(X \geq (1+\delta)\mu) \leq \exp\left(-\frac{\delta^2 \mu}{3}\right) \quad \text{for } 0 < \delta \leq 1
\]</p>

<div class="code-block">Application: Estimate mean with relative error δ, failure probability ε

Lower tail: n ≥ (2/δ²) · ln(1/ε)
Upper tail: n ≥ (3/δ²) · ln(1/ε)

Example: 10% relative error (δ=0.1), 1% failure (ε=0.01)
  Upper tail: n ≥ (3/0.01) · ln(100) ≈ 1,382 samples
</div>

<h4>Bennett's Inequality</h4>

<p>Variance-adaptive bound. For bounded variables \( X_i \in [0, b] \) with variance \( \sigma^2 \):</p>

<p>\[
P(|\bar{X} - \mu| \geq \epsilon) \leq 2 \exp\left(-\frac{n\epsilon^2}{2\sigma^2 + \frac{2b\epsilon}{3}}\right)
\]</p>

<p>Tighter than Hoeffding when \( \sigma^2 \ll b^2 \) (low-variance data).</p>

<h3>2.3 Error Propagation Analysis</h3>

<h4>Independent Errors</h4>

<p>For function \( f(x_1, \ldots, x_k) \) with independent inputs having errors \( \sigma_i \):</p>

<p>\[
\sigma_f^2 = \sum_{i=1}^k \left(\frac{\partial f}{\partial x_i}\right)^2 \sigma_i^2
\]</p>

<div class="code-block">Examples:

Sum: f = x₁ + x₂ + ... + x_k
  σ_f² = σ₁² + σ₂² + ... + σ_k²

Weighted sum: f = Σ aᵢxᵢ
  σ_f² = Σ aᵢ² σᵢ²

Product: f = x₁ · x₂
  (σ_f/f)² = (σ₁/x₁)² + (σ₂/x₂)²

Power law: f = x^α
  σ_f/f = |α| · σ/x
</div>

<h4>Correlated Errors</h4>

<p>Full covariance matrix \( \Sigma \) with elements \( \Sigma_{ij} = \text{Cov}(x_i, x_j) \):</p>

<p>\[
\sigma_f^2 = \nabla f^T \Sigma \nabla f = \sum_{i,j} \frac{\partial f}{\partial x_i} \frac{\partial f}{\partial x_j} \Sigma_{ij}
\]</p>

<div class="code-block">Example: Linear combination f = Σ wᵢxᵢ

σ_f² = Σᵢ Σⱼ wᵢ wⱼ Cov(xᵢ, xⱼ)

Special case: All pairwise correlation ρ, equal variances σ²
  σ_f² = σ² [Σ wᵢ² + ρ Σᵢ≠ⱼ wᵢwⱼ]
</div>

<h3>2.4 Confidence Intervals</h3>

<h4>Normal-Based Interval (Large n)</h4>

<p>For sample mean \( \bar{X} \) with sample standard deviation \( s \):</p>

<p>\[
\bar{X} \pm z_{\alpha/2} \frac{s}{\sqrt{n}}
\]</p>

<p>where \( z_{\alpha/2} \) is the critical value (e.g., 1.96 for 95% confidence).</p>

<h4>t-Distribution Interval (Small n)</h4>

<p>When \( n < 30 \) or population variance unknown:</p>

<p>\[
\bar{X} \pm t_{\alpha/2, n-1} \frac{s}{\sqrt{n}}
\]</p>

<p>where \( t_{\alpha/2, n-1} \) is the t critical value with \( n-1 \) degrees of freedom.</p>

<h4>Bootstrap Confidence Interval</h4>

<p>Non-parametric approach for complex statistics:</p>

<div class="code-block">BOOTSTRAP-CI(data, statistic, B=1000, α=0.05):
  bootstrap_stats ← []
  for b = 1 to B:
    resample ← sample(data, size=len(data), replace=True)
    bootstrap_stats[b] ← statistic(resample)

  lower ← percentile(bootstrap_stats, α/2)
  upper ← percentile(bootstrap_stats, 1 - α/2)

  return (lower, upper)
</div>

<h3>2.5 Confidence Sequences</h3>

<p>Time-uniform bounds valid at all sample sizes simultaneously, enabling valid inference at arbitrary stopping times without inflation of Type I error.</p>

<h4>Ville's Inequality</h4>

<p>Foundation for confidence sequences. For non-negative martingale \( M_t \) with \( M_0 = 1 \):</p>

<p>\[
P\left(\exists t \geq 1: M_t \geq \frac{1}{\alpha}\right) \leq \alpha
\]</p>

<h4>Empirical Bernstein Confidence Sequence</h4>

<p>For bounded variables \( X_i \in [0, 1] \) with sample mean \( \bar{X}_n \) and sample variance \( V_n \):</p>

<p>\[
P\left(\forall n \geq 1: \mu \in \left[\bar{X}_n \pm r_n\right]\right) \geq 1 - \delta
\]</p>

<p>where the radius is:</p>

<p>\[
r_n = \sqrt{\frac{2V_n \log(c/\delta)}{n}} + \frac{3\log(c/\delta)}{n}
\]</p>

<p>with universal constant \( c \approx 1.7 \).</p>

<div class="code-block">Advantages over fixed-n intervals:
1. Valid at any stopping time (adaptive experiments)
2. No multiple testing correction needed
3. Tighter bounds when variance is low (data-adaptive)
4. Enables anytime-valid inference

Typical application: Sequential A/B testing, online learning
</div>

<h4>Predictable Mixture Bound</h4>

<p>For sub-Gaussian variables with adaptive variance estimation:</p>

<p>\[
r_n = \sqrt{\frac{2\hat{\sigma}_n^2 \log(1/\delta)}{n}} + \frac{3 \log(1/\delta)}{n}
\]</p>

<h3>2.6 Statistical Power Analysis</h3>

<p>Power is the probability of correctly rejecting a false null hypothesis.</p>

<h4>Power for Proportion Test</h4>

<p>Testing \( H_0: p = p_0 \) vs \( H_1: p = p_1 \) with significance level \( \alpha \):</p>

<p>\[
n = \left( \frac{z_{\alpha/2}\sqrt{p_0(1-p_0)} + z_{\beta}\sqrt{p_1(1-p_1)}}{p_1 - p_0} \right)^2
\]</p>

<p>where \( \beta \) is the Type II error rate (power = \( 1 - \beta \)).</p>

<table>
  <thead>
    <tr>
      <th>Effect Size (p₁ - p₀)</th>
      <th>Power 80%</th>
      <th>Power 90%</th>
      <th>Power 95%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.05</td>
      <td>1571</td>
      <td>2102</td>
      <td>2600</td>
    </tr>
    <tr>
      <td>0.10</td>
      <td>393</td>
      <td>526</td>
      <td>651</td>
    </tr>
    <tr>
      <td>0.15</td>
      <td>175</td>
      <td>234</td>
      <td>290</td>
    </tr>
    <tr>
      <td>0.20</td>
      <td>99</td>
      <td>132</td>
      <td>164</td>
    </tr>
  </tbody>
</table>

<h2 id="applications">3. Applications Beyond Genomics</h2>

<h3>3.1 Privacy-Preserving Machine Learning Inference</h3>

<h4>Differentially Private Query Answering</h4>

<p>Problem: Answer statistical queries on sensitive datasets while preserving \( (\epsilon, \delta) \)-differential privacy.</p>

<div class="highlight-box">
<strong>Setting:</strong> Database with n records, query function f with sensitivity Δf<br>
<strong>Mechanism:</strong> Add Laplace noise Lap(Δf/ε) to true answer<br>
<strong>Challenge:</strong> Single noisy answer has high variance<br>
<strong>Solution:</strong> Consensus over multiple independent noise additions
</div>

<div class="code-block">PRIVATE-COUNT-CONSENSUS(database, query, ε, target_accuracy):
  // 1. Compute noise scale
  sensitivity = 1  // Count queries have sensitivity 1
  scale = sensitivity / ε

  // 2. Determine number of runs for target accuracy
  // Target: P(|answer - truth| ≤ target_accuracy) ≥ 0.95
  // Laplace variance: 2·scale²
  variance = 2 * scale²
  n_runs = ceil((1.96² · variance) / target_accuracy²)

  // 3. Multiple noisy answers
  true_count = COUNT(database, query)
  noisy_counts = []
  for i = 1 to n_runs:
    noise = sample_laplace(0, scale)
    noisy_counts[i] = true_count + noise

  // 4. Aggregate
  consensus = median(noisy_counts)
  CI = empirical_percentile_interval(noisy_counts, α=0.05)

  return consensus, CI

// Privacy cost: n_runs × ε via basic composition
// Or: O(ε√(n_runs log(1/δ))) via advanced composition
</div>

<p><strong>Example:</strong> Count query with \( \epsilon = 1.0 \), target accuracy ± 5 within 95% confidence.</p>

<div class="code-block">Scale = 1/1.0 = 1.0
Variance = 2·1² = 2
n_runs = (1.96² · 2) / 25 ≈ 31 runs

Privacy cost (basic composition): 31ε = 31.0
Privacy cost (advanced composition): ε√(2·31·ln(1/δ)) ≈ 5.5ε (for δ=10⁻⁶)
</div>

<h4>Federated Learning with Gradient Consensus</h4>

<p>Problem: Train model on decentralized data without sharing raw data. Each client adds noise for local differential privacy.</p>

<div class="code-block">FEDERATED-CONSENSUS-TRAINING(clients, model, ε_local, rounds):
  initialize model θ₀

  for t = 1 to rounds:
    // Local computation at each client
    for each client k:
      g_k = compute_gradient(client_k.data, θₜ)
      noisy_g_k = g_k + Gaussian(0, σ²I)  // σ from privacy budget
      send noisy_g_k to server

    // Server-side consensus (R repetitions per round)
    consensus_gradients = []
    for r = 1 to R:
      // Collect independent noisy gradients
      batch_gradients = collect_from_clients()
      mean_gradient = (1/K) Σ batch_gradients
      consensus_gradients[r] = mean_gradient

    // Aggregate with outlier rejection
    final_gradient = trimmed_mean(consensus_gradients, trim=0.1)

    // Update model
    θₜ₊₁ = θₜ - η · final_gradient

  return θ_final
</div>

<p><strong>Parameters:</strong></p>
<ul>
  <li>R = 5-20 consensus rounds per training round (empirically)</li>
  <li>Trim top/bottom 10% to handle Byzantine clients</li>
  <li>Noise scale \( \sigma = O(\sqrt{T}/\epsilon) \) for T total iterations</li>
</ul>

<h3>3.2 Secure Multi-Party Computation</h3>

<h4>Garbled Circuit Majority Voting</h4>

<p>Problem: Garbled circuits may have residual information leakage or implementation errors. Running a single circuit provides security but no robustness.</p>

<div class="highlight-box">
<strong>Protocol:</strong> Generate R independent garbled circuits for same function<br>
<strong>Execution:</strong> Evaluate all R circuits<br>
<strong>Output:</strong> Majority vote on each output bit<br>
<strong>Security:</strong> Adversary must compromise majority of circuits
</div>

<div class="code-block">Parameters for security level λ (bits):
  Per-circuit security: λ₀ (e.g., 40 bits, fail prob 2⁻⁴⁰)
  Target security: λ (e.g., 128 bits, fail prob 2⁻¹²⁸)

Required circuits for majority voting security:
  R ≥ 2·(λ - λ₀) + 1

Example: λ₀ = 40, λ = 128
  R ≥ 2·(128-40) + 1 = 177 circuits

Cost analysis:
  Single circuit: 1× communication, 1× computation, 2⁻⁴⁰ failure
  177 circuits: 177× communication, 177× parallel computation, 2⁻¹²⁸ failure
  Parallel speedup: near-linear with processors
</div>

<h4>Secret Sharing with Byzantine Nodes</h4>

<p>Problem: Shamir secret sharing assumes honest nodes. Malicious nodes may provide incorrect shares.</p>

<div class="code-block">ROBUST-SECRET-RECONSTRUCTION(shares, threshold_t, num_shares_n):
  // Collect more than threshold shares
  collected = n shares (where n > t)

  // Try multiple t-subsets
  candidates = []
  for each subset S of size t from collected:
    secret_candidate = lagrange_interpolate(S)
    candidates.append(secret_candidate)

  // Consensus via mode
  secret = mode(candidates)

  // Confidence: fraction of subsets agreeing
  agreement_rate = count(candidates == secret) / len(candidates)

  return secret, agreement_rate

Robustness guarantee:
  If at most f shares are corrupted, and we collect n ≥ t+2f shares:
  - (n choose t) total subsets
  - Corrupted subsets: at most (f choose 1)·(n-f choose t-1) + ...
  - Majority of subsets contain all-honest shares → correct reconstruction

Example: t=5, n=11, f=3 Byzantine shares
  Total subsets: C(11,5) = 462
  All-honest subsets: C(8,5) = 56
  Success probability: 56/462 ≈ 12% per subset
  With 20 random subsets: P(majority correct) > 99%
</div>

<h3>3.3 Distributed Sensor Networks</h3>

<h4>Environmental Monitoring with Noisy Sensors</h4>

<p>Scenario: N spatially distributed sensors measuring temperature, each with independent Gaussian noise \( \mathcal{N}(0, \sigma_i^2) \).</p>

<div class="code-block">WEIGHTED-CONSENSUS-ESTIMATION(sensor_readings, sensor_variances):
  // Optimal weights: inverse variance weighting
  weights = [1/σᵢ² for σᵢ² in sensor_variances]

  // Weighted mean
  μ̂ = Σ(wᵢ · xᵢ) / Σ wᵢ

  // Consensus variance (Cramér-Rao bound)
  σ̂² = 1 / Σ wᵢ

  // Confidence interval (normal approximation)
  margin = 1.96 · √σ̂²
  CI = [μ̂ - margin, μ̂ + margin]

  return μ̂, CI

Variance reduction factor vs single sensor:
  Single best sensor (variance σ_min²): σ_min²
  Consensus (N sensors, equal variance σ²): σ²/N
  Consensus (heterogeneous): 1 / Σ(1/σᵢ²)

Example: 10 sensors, σ = [1, 1, 1, 2, 2, 3, 3, 4, 5, 10]
  Single best: σ² = 1
  Simple mean: σ² = Σσᵢ²/N² = 1.84
  Weighted consensus: 1/Σ(1/σᵢ²) ≈ 0.48  (2× better than single sensor)
</div>

<h4>Byzantine Fault Tolerance in Sensor Fusion</h4>

<p>Problem: Some sensors may be compromised and send arbitrary (adversarial) values.</p>

<div class="code-block">BYZANTINE-ROBUST-CONSENSUS(readings, f_max_byzantine):
  N = len(readings)

  // Trim outliers (assumption: f < N/3)
  sorted_readings = sort(readings)
  trimmed = sorted_readings[f_max_byzantine : N - f_max_byzantine]

  // Robust estimators
  consensus = median(trimmed)  // or trimmed_mean(trimmed)

  // Confidence via bootstrap (non-parametric)
  CI = bootstrap_percentile_interval(trimmed, α=0.05)

  return consensus, CI

Guarantees:
  - If f ≤ f_max_byzantine < N/3: consensus within ε of true value
  - Convergence rate: O(1/√(N - 2f))

Example: N=30 sensors, f=8 Byzantine
  Untrimmed mean: arbitrarily bad
  Trimmed mean (remove 8 on each side):
    - Uses middle 14 readings
    - Variance reduction: 14× vs single sensor
    - Robust to up to 8 Byzantine nodes
</div>

<h3>3.4 Byzantine Agreement Protocols</h3>

<h4>Consensus in Distributed Systems</h4>

<p>Classic problem: N nodes must agree on a single value despite f Byzantine (malicious) nodes.</p>

<div class="highlight-box">
<strong>Requirements:</strong><br>
1. Agreement: All honest nodes decide on same value<br>
2. Validity: If all honest nodes start with v, they decide v<br>
3. Termination: All honest nodes eventually decide<br>
<br>
<strong>Lower bound:</strong> Requires N ≥ 3f + 1 nodes for f Byzantine faults
</div>

<div class="code-block">BYZANTINE-AGREEMENT-VOTING(initial_value, N, f):
  value = initial_value

  for round = 1 to f+1:
    // Phase 1: Broadcast
    broadcast(value)

    // Phase 2: Collect
    values_received = collect_from_all_nodes()

    // Phase 3: Vote
    vote_counts = count_occurrences(values_received)
    majority_value, majority_count = max(vote_counts)

    if majority_count > (N + f) / 2:
      value = majority_value
      if round > 1 and value == previous_value:
        decide(value)
        return value
    else:
      value = default_value

  // After f+1 rounds, consensus guaranteed
  decide(value)
  return value

Communication complexity:
  Rounds: O(f)
  Messages per round: O(N²)
  Total messages: O(f·N²)

Practical systems (e.g., PBFT):
  - Use cryptographic signatures for authentication
  - Optimize to O(N²) messages per consensus decision
  - Typical: f=1 (tolerating 1 failure with N=4 nodes)
</div>

<h3>3.5 Probabilistic Data Structures</h3>

<h4>Bloom Filter Consensus</h4>

<p>Problem: Bloom filters have false positive rate p. Critical queries require higher precision.</p>

<div class="code-block">CONSENSUS-BLOOM-FILTER-QUERY(element, bloom_filters, target_fpr):
  // Multiple independent Bloom filters
  R = len(bloom_filters)

  // Query all filters
  results = [bf.contains(element) for bf in bloom_filters]
  positive_count = sum(results)

  // Majority vote
  consensus = (positive_count > R/2)

  // Estimate false positive rate
  if consensus == True and element not in ground_truth:
    // This is a false positive
    empirical_fpr = p^(R/2)  // Majority must be false positives

  return consensus

False positive rate reduction:
  Single Bloom filter: p (e.g., 0.01)
  Majority of R=5 filters: ≈ p^3 (e.g., 10⁻⁶)
  Majority of R=11 filters: ≈ p^6 (e.g., 10⁻¹²)

Trade-off:
  Space: R× larger (R independent filters)
  Time: R× query cost
  FPR: Exponential reduction
</div>

<h4>Count-Min Sketch Consensus</h4>

<p>Problem: Count-Min Sketch overestimates frequencies due to hash collisions. Consensus reduces error.</p>

<div class="code-block">CONSENSUS-COUNT-MIN-SKETCH(element, sketches):
  // Query R independent sketches
  estimates = [sketch.query(element) for sketch in sketches]

  // Consensus: median (robust to outliers)
  consensus_count = median(estimates)

  // Confidence interval via bootstrap
  CI = percentile_interval(estimates, [0.025, 0.975])

  return consensus_count, CI

Error reduction:
  Single sketch: E[estimate] = true_count + ε·stream_size
  Median of R sketches: Tighter concentration around true value

Typical: R = 5-10 independent sketches
  Error reduction: ~√R for median estimator
</div>

<h2 id="parameter-tuning">4. Parameter Tuning</h2>

<h3>4.1 Accuracy Requirements → Run Count Mapping</h3>

<h4>Decision Framework</h4>

<div class="code-block">COMPUTE-RUN-COUNT(accuracy_target, confidence_level, per_trial_error):
  // Step 1: Identify output type
  if discrete_output:
    // Use majority voting formulas
    p_correct = 1 - per_trial_error
    z = inverse_normal_cdf(confidence_level)
    n = ceil((z² · p_correct · (1 - p_correct)) / (p_correct - 0.5)²)

  else:  // continuous_output
    // Use concentration inequalities
    δ = 1 - confidence_level
    ε = accuracy_target

    if variance_known:
      // Use normal approximation
      z = inverse_normal_cdf(1 - δ/2)
      n = ceil((z · σ / ε)²)
    else:
      // Use Hoeffding (conservative)
      n = ceil((1/(2·ε²)) · log(2/δ))

  // Step 2: Add safety margin (finite-sample correction)
  n = ceil(n · 1.15)

  return n
</div>

<h4>Lookup Table: Discrete Outcomes</h4>

<table>
  <thead>
    <tr>
      <th>Per-trial Accuracy</th>
      <th>Target Confidence</th>
      <th>Required Trials</th>
      <th>Expected Cost (vs 1 trial)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>60%</td>
      <td>95%</td>
      <td>165</td>
      <td>165×</td>
    </tr>
    <tr>
      <td>60%</td>
      <td>99%</td>
      <td>266</td>
      <td>266×</td>
    </tr>
    <tr>
      <td>70%</td>
      <td>95%</td>
      <td>41</td>
      <td>41×</td>
    </tr>
    <tr>
      <td>70%</td>
      <td>99%</td>
      <td>66</td>
      <td>66×</td>
    </tr>
    <tr>
      <td>80%</td>
      <td>95%</td>
      <td>17</td>
      <td>17×</td>
    </tr>
    <tr>
      <td>80%</td>
      <td>99%</td>
      <td>27</td>
      <td>27×</td>
    </tr>
    <tr>
      <td>90%</td>
      <td>95%</td>
      <td>7</td>
      <td>7×</td>
    </tr>
    <tr>
      <td>90%</td>
      <td>99%</td>
      <td>11</td>
      <td>11×</td>
    </tr>
  </tbody>
</table>

<h4>Lookup Table: Continuous Estimation</h4>

<table>
  <thead>
    <tr>
      <th>Tolerance (ε)</th>
      <th>Confidence</th>
      <th>Required Trials (Hoeffding)</th>
      <th>With Known σ=0.1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.01</td>
      <td>95%</td>
      <td>18,445</td>
      <td>385</td>
    </tr>
    <tr>
      <td>0.01</td>
      <td>99%</td>
      <td>26,492</td>
      <td>664</td>
    </tr>
    <tr>
      <td>0.05</td>
      <td>95%</td>
      <td>738</td>
      <td>16</td>
    </tr>
    <tr>
      <td>0.05</td>
      <td>99%</td>
      <td>1,060</td>
      <td>27</td>
    </tr>
    <tr>
      <td>0.10</td>
      <td>95%</td>
      <td>185</td>
      <td>4</td>
    </tr>
    <tr>
      <td>0.10</td>
      <td>99%</td>
      <td>265</td>
      <td>7</td>
    </tr>
  </tbody>
</table>

<h3>4.2 Time Budgets → Parallelization Strategy</h3>

<h4>Resource Allocation Model</h4>

<div class="code-block">ALLOCATE-RESOURCES(time_budget, per_trial_time, processors, target_confidence):
  // Sequential baseline
  sequential_trials = floor(time_budget / per_trial_time)

  // Parallel execution
  parallel_trials = processors · floor(time_budget / per_trial_time)

  // Determine achievable confidence
  if discrete_output:
    conf_sequential = majority_vote_confidence(sequential_trials, p_correct)
    conf_parallel = majority_vote_confidence(parallel_trials, p_correct)
  else:
    conf_sequential = compute_confidence(sequential_trials, σ, ε)
    conf_parallel = compute_confidence(parallel_trials, σ, ε)

  // Adaptive scheduling
  if conf_parallel < target_confidence:
    print("Insufficient resources for target confidence")
    print(f"Achievable: {conf_parallel} with {processors} processors")
  else:
    // Can achieve target; find optimal trial count
    min_trials = binary_search_trials(target_confidence)
    optimal_processors = ceil(min_trials / (time_budget / per_trial_time))
    print(f"Achievable with {optimal_processors} processors")

  return optimal_processors, parallel_trials
</div>

<h4>Example Scenarios</h4>

<table>
  <thead>
    <tr>
      <th>Time Budget</th>
      <th>Per-trial Time</th>
      <th>Processors</th>
      <th>Sequential Max</th>
      <th>Parallel Max</th>
      <th>Speedup</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>60 sec</td>
      <td>1 sec</td>
      <td>1</td>
      <td>60</td>
      <td>60</td>
      <td>1×</td>
    </tr>
    <tr>
      <td>60 sec</td>
      <td>1 sec</td>
      <td>10</td>
      <td>60</td>
      <td>600</td>
      <td>10×</td>
    </tr>
    <tr>
      <td>60 sec</td>
      <td>1 sec</td>
      <td>100</td>
      <td>60</td>
      <td>6,000</td>
      <td>100×</td>
    </tr>
    <tr>
      <td>600 sec</td>
      <td>10 sec</td>
      <td>50</td>
      <td>60</td>
      <td>3,000</td>
      <td>50×</td>
    </tr>
  </tbody>
</table>

<h4>Adaptive Batch Scheduling</h4>

<div class="code-block">ADAPTIVE-CONSENSUS(target_confidence, max_time, processors):
  batch_size = processors
  results = []
  elapsed = 0

  while elapsed < max_time:
    // Run batch
    batch_results = parallel_execute(batch_size)
    results.extend(batch_results)
    elapsed += per_trial_time

    // Check confidence
    current_confidence = compute_confidence(results)

    if current_confidence >= target_confidence:
      print(f"Target achieved with {len(results)} trials in {elapsed} sec")
      return aggregate(results), current_confidence

    // Estimate remaining trials needed
    remaining_trials = estimate_remaining(current_confidence, target_confidence)

    // Adjust batch size for next iteration
    time_remaining = max_time - elapsed
    max_next_batch = processors · floor(time_remaining / per_trial_time)
    batch_size = min(remaining_trials, max_next_batch)

  print(f"Time budget exhausted. Confidence: {current_confidence}")
  return aggregate(results), current_confidence

Benefits:
  1. Early stopping: saves up to 30-50% computation
  2. Anytime valid: results valid at any stopping point
  3. Resource efficient: adapts to actual variance
</div>

<h3>4.3 Cost Constraints → Consensus Threshold</h3>

<h4>Cost-Accuracy Trade-off</h4>

<div class="code-block">OPTIMIZE-COST-ACCURACY(cost_per_trial, cost_budget, value_of_accuracy):
  // Define objective: value - cost
  objective(n) = value_of_accuracy(confidence(n)) - n · cost_per_trial

  // Find optimal n within budget
  max_trials = floor(cost_budget / cost_per_trial)

  optimal_n = argmax_{n ≤ max_trials} objective(n)
  optimal_confidence = confidence(optimal_n)
  total_cost = optimal_n · cost_per_trial
  net_value = objective(optimal_n)

  return optimal_n, optimal_confidence, net_value

Example: Privacy-preserving query
  Cost per query: $0.01 (API call)
  Budget: $10
  Value function: $100 if confidence > 99%, else $0

  Required trials for 99%: 266 (from p=0.6 table)
  Cost for 266 trials: $2.66
  Net value: $100 - $2.66 = $97.34

  Decision: Run 266 trials (well within budget)
</div>

<h4>Marginal Utility Analysis</h4>

<table>
  <thead>
    <tr>
      <th>Trials (n)</th>
      <th>Confidence</th>
      <th>Marginal Confidence Gain</th>
      <th>Cost</th>
      <th>Marginal Cost</th>
      <th>ROI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td>75.4%</td>
      <td>-</td>
      <td>$1.00</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td>25</td>
      <td>88.5%</td>
      <td>+13.1%</td>
      <td>$2.50</td>
      <td>$1.50</td>
      <td>8.7% / $</td>
    </tr>
    <tr>
      <td>50</td>
      <td>97.1%</td>
      <td>+8.6%</td>
      <td>$5.00</td>
      <td>$2.50</td>
      <td>3.4% / $</td>
    </tr>
    <tr>
      <td>100</td>
      <td>99.87%</td>
      <td>+2.77%</td>
      <td>$10.00</td>
      <td>$5.00</td>
      <td>0.55% / $</td>
    </tr>
    <tr>
      <td>200</td>
      <td>99.9999%</td>
      <td>+0.13%</td>
      <td>$20.00</td>
      <td>$10.00</td>
      <td>0.013% / $</td>
    </tr>
  </tbody>
</table>

<p>Observation: Diminishing returns after ~50 trials. Optimal point depends on value function.</p>

<h2 id="tradeoffs">5. Trade-offs</h2>

<h3>5.1 Accuracy vs Latency vs Cost</h3>

<h4>Fundamental Trade-off Curves</h4>

<p>For target accuracy \( \epsilon \) and confidence \( 1 - \delta \):</p>

<div class="code-block">Accuracy-Cost:
  n ∝ 1/ε²  (quadratic)
  Doubling accuracy requires 4× more trials

Accuracy-Latency (sequential):
  T = n · t_trial ∝ 1/ε²
  Doubling accuracy requires 4× more time

Accuracy-Latency (parallel with P processors):
  T = (n/P) · t_trial ∝ 1/(ε² · P)
  Parallelism provides linear speedup

Confidence-Cost:
  n ∝ log(1/δ)  (logarithmic)
  10× higher confidence requires ~2.3× more trials
</div>

<table>
  <thead>
    <tr>
      <th>Configuration</th>
      <th>Accuracy (ε)</th>
      <th>Confidence</th>
      <th>Trials</th>
      <th>Time (1 proc)</th>
      <th>Time (10 proc)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Low precision</td>
      <td>0.10</td>
      <td>95%</td>
      <td>185</td>
      <td>185 sec</td>
      <td>19 sec</td>
    </tr>
    <tr>
      <td>Medium precision</td>
      <td>0.05</td>
      <td>95%</td>
      <td>738</td>
      <td>738 sec</td>
      <td>74 sec</td>
    </tr>
    <tr>
      <td>High precision</td>
      <td>0.01</td>
      <td>95%</td>
      <td>18,445</td>
      <td>5.1 hours</td>
      <td>31 min</td>
    </tr>
    <tr>
      <td>High confidence</td>
      <td>0.05</td>
      <td>99.9%</td>
      <td>1,842</td>
      <td>31 min</td>
      <td>3.1 min</td>
    </tr>
  </tbody>
</table>

<h3>5.2 Optimization Strategies</h3>

<h4>Multi-Objective Optimization</h4>

<div class="code-block">PARETO-OPTIMAL-CONSENSUS(objectives, constraints):
  // Objectives: minimize cost, minimize latency, maximize accuracy
  // Constraints: budget, time_budget, min_accuracy

  pareto_frontier = []

  for n in range(min_trials, max_trials):
    cost = n · cost_per_trial
    latency_seq = n · trial_time
    latency_par = (n / processors) · trial_time
    accuracy = compute_accuracy(n)

    if cost <= budget and latency_par <= time_budget and accuracy >= min_accuracy:
      point = {
        'trials': n,
        'cost': cost,
        'latency': latency_par,
        'accuracy': accuracy
      }

      // Check if dominated by existing point
      if not dominated_by(point, pareto_frontier):
        pareto_frontier.append(point)

  return pareto_frontier

Output: Set of non-dominated configurations
  - Cannot improve one objective without hurting another
  - User selects based on preferences
</div>

<h4>Adaptive Variance Reduction</h4>

<p>Use variance reduction techniques to decrease required trials:</p>

<div class="code-block">1. Control Variates
   Theoretical reduction: 1 - ρ² (ρ = correlation with control)
   Typical: 40-60% fewer trials for ρ ≈ 0.7

2. Stratified Sampling
   Theoretical reduction: varies by stratum variance
   Typical: 30-50% fewer trials

3. Importance Sampling
   Theoretical reduction: variance of optimal IS estimator
   Typical: 5-10× fewer trials for rare event estimation

Combined approach:
  Baseline: 1000 trials
  With control variates (ρ=0.7): 510 trials
  With stratification: 300 trials
  Combined: 250 trials (75% reduction)
</div>

<h4>Sequential Stopping Rules</h4>

<div class="code-block">SEQUENTIAL-PROBABILITY-RATIO-TEST(H0, H1, α, β):
  // Test H0: p = p0 vs H1: p = p1
  // α = Type I error, β = Type II error

  A = (1 - β) / α  // Upper threshold
  B = β / (1 - α)  // Lower threshold

  LR = 1  // Likelihood ratio
  n = 0

  while B < LR < A:
    n += 1
    x_n = observe_trial()

    LR *= (p1/p0)^x_n · ((1-p1)/(1-p0))^(1-x_n)

    if LR >= A:
      reject H0
      return "H1", n
    elif LR <= B:
      accept H0
      return "H0", n

Average sample number (ASN):
  If true p = p0: ASN ≈ (β·log(B) + (1-β)·log(A)) / D(p0||p1)
  If true p = p1: ASN ≈ (α·log(A) + (1-α)·log(B)) / D(p1||p0)

  where D(p||q) = p·log(p/q) + (1-p)·log((1-p)/(1-q))

Savings vs fixed sample size:
  Typical: 30-50% fewer samples on average
</div>

<h3>5.3 Cost-Performance Curves</h3>

<h4>Empirical Analysis: Privacy-Preserving Query</h4>

<table>
  <thead>
    <tr>
      <th>Trials</th>
      <th>Accuracy (MAE)</th>
      <th>95% CI Width</th>
      <th>Cost ($)</th>
      <th>Cost per 1% Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>5</td>
      <td>±12.3</td>
      <td>24.6</td>
      <td>0.50</td>
      <td>$0.041</td>
    </tr>
    <tr>
      <td>10</td>
      <td>±8.7</td>
      <td>17.4</td>
      <td>1.00</td>
      <td>$0.115</td>
    </tr>
    <tr>
      <td>25</td>
      <td>±5.5</td>
      <td>11.0</td>
      <td>2.50</td>
      <td>$0.455</td>
    </tr>
    <tr>
      <td>50</td>
      <td>±3.9</td>
      <td>7.8</td>
      <td>5.00</td>
      <td>$1.28</td>
    </tr>
    <tr>
      <td>100</td>
      <td>±2.8</td>
      <td>5.6</td>
      <td>10.00</td>
      <td>$3.57</td>
    </tr>
    <tr>
      <td>500</td>
      <td>±1.2</td>
      <td>2.4</td>
      <td>50.00</td>
      <td>$41.67</td>
    </tr>
  </tbody>
</table>

<p>Observation: Cost per marginal accuracy improvement increases super-linearly. Optimal point around 50-100 trials for most applications.</p>

<h2 id="implementation">6. Implementation Patterns</h2>

<h3>6.1 Asynchronous Consensus</h3>

<h4>Non-Blocking Aggregation</h4>

<div class="code-block">ASYNC-CONSENSUS(tasks, target_confidence, timeout):
  // Launch all tasks asynchronously
  futures = [async_execute(task) for task in tasks]

  results = []
  start_time = now()

  while len(results) < len(tasks) and (now() - start_time) < timeout:
    // Non-blocking check for completed tasks
    completed = [f for f in futures if f.done()]

    for future in completed:
      results.append(future.result())
      futures.remove(future)

    // Early stopping: check if sufficient confidence achieved
    if len(results) >= min_trials:
      current_confidence = compute_confidence(results)
      if current_confidence >= target_confidence:
        // Cancel remaining tasks
        for future in futures:
          future.cancel()

        return aggregate(results), current_confidence, len(results)

  // Timeout or all tasks completed
  return aggregate(results), compute_confidence(results), len(results)

Benefits:
  - Tolerates variable task latency
  - Early stopping when possible
  - Graceful handling of failures (missing results)

Typical speedup: 1.5-3× over synchronous when latencies vary
</div>

<h4>Streaming Aggregation</h4>

<div class="code-block">STREAMING-CONSENSUS():
  // Online statistics (Welford's algorithm)
  n = 0
  mean = 0
  M2 = 0  // Sum of squared deviations

  for result in result_stream:
    n += 1
    delta = result - mean
    mean += delta / n
    delta2 = result - mean
    M2 += delta * delta2

    // Online confidence bound
    if n >= 2:
      variance = M2 / (n - 1)
      sem = sqrt(variance / n)
      margin = 1.96 * sem  // 95% CI

      if margin < tolerance:
        return mean, margin, n

  return mean, margin, n

Memory: O(1) vs O(n) for batch storage
Enables: Infinite streams, real-time updates
</div>

<h3>6.2 Quorum-Based Aggregation</h3>

<h4>k-out-of-n Consensus</h4>

<div class="code-block">QUORUM-CONSENSUS(n_total, k_quorum, timeout):
  // Launch n_total tasks
  futures = [async_execute(task_i) for i in range(n_total)]

  results = []
  start = now()

  while len(results) < k_quorum and (now() - start) < timeout:
    // Wait for next completion
    newly_completed = wait_any(futures)
    results.extend(newly_completed)

  if len(results) >= k_quorum:
    // Sufficient quorum achieved
    consensus = aggregate(results[:k_quorum])
    return consensus, "QUORUM_REACHED"
  else:
    // Timeout with partial results
    consensus = aggregate(results)
    return consensus, "PARTIAL_QUORUM"

Latency optimization:
  - Only wait for k fastest tasks (out of n)
  - Tail latency tolerance
  - Trade-off: k=n (highest confidence) vs k≈n/2 (lowest latency)

Example: n=100, k=60, task latency varies 50-500ms
  Wait for all: 500ms (p99)
  Wait for 60: ~200ms (median of top 60)
  Latency improvement: 2.5×
</div>

<h4>Read Repair for Consistency</h4>

<div class="code-block">QUORUM-READ-REPAIR(key, replicas, quorum_size):
  // Read from quorum of replicas
  responses = read_from_quorum(key, replicas, quorum_size)

  // Detect inconsistencies
  values = [r.value for r in responses]
  timestamps = [r.timestamp for r in responses]

  if all_equal(values):
    return values[0]  // Consistent
  else:
    // Inconsistent: resolve via timestamp (last-write-wins)
    latest_value = values[argmax(timestamps)]

    // Background repair: propagate latest to stale replicas
    stale_replicas = [r for r, v in zip(replicas, values) if v != latest_value]
    async_repair(stale_replicas, key, latest_value)

    return latest_value

Consistency guarantee:
  - With quorum reads (k > n/2) and writes (k > n/2): linearizable
  - Read + repair: eventual consistency with bounded staleness
</div>

<h3>6.3 Weighted Voting Schemes</h3>

<h4>Quality-Weighted Consensus</h4>

<div class="code-block">WEIGHTED-CONSENSUS(trials, quality_scores):
  // Trials have associated quality scores (e.g., confidence, precision)
  // Higher quality → higher weight

  weights = normalize(quality_scores)

  // Weighted mean
  consensus = sum(w * x for w, x in zip(weights, trials)) / sum(weights)

  // Weighted variance
  weighted_var = sum(w * (x - consensus)² for w, x in zip(weights, trials)) / sum(weights)

  // Effective sample size
  n_eff = (sum(weights))² / sum(w² for w in weights)

  // Confidence interval using effective sample size
  sem = sqrt(weighted_var / n_eff)
  CI = [consensus - 1.96*sem, consensus + 1.96*sem]

  return consensus, CI

Applications:
  - Heterogeneous sensors (different precision)
  - Federated learning (variable data size)
  - Multi-source data fusion

Example: 5 sources with quality [0.9, 0.8, 0.5, 0.3, 0.2]
  Normalized weights: [0.37, 0.33, 0.21, 0.12, 0.08]
  Effective sample size: 3.2 (vs 5 for equal weights)
  Variance reduction: ~35% better than simple mean
</div>

<h4>Stake-Weighted Byzantine Consensus</h4>

<div class="code-block">STAKE-WEIGHTED-BFT(proposals, stakes, f_max):
  // Validators propose values weighted by stake
  // Tolerates f_max Byzantine validators by stake

  total_stake = sum(stakes)
  byzantine_threshold = f_max * total_stake

  // Round 1: Propose
  proposals_with_stakes = zip(proposals, stakes)

  // Round 2: Vote on proposals (weighted by stake)
  vote_weights = {}
  for proposal, stake in proposals_with_stakes:
    if proposal not in vote_weights:
      vote_weights[proposal] = 0
    vote_weights[proposal] += stake

  // Consensus: Proposal with >2/3 stake
  consensus_threshold = (2/3) * total_stake

  for proposal, weight in vote_weights.items():
    if weight > consensus_threshold:
      return proposal, "CONSENSUS"

  // No consensus (≥1/3 stake Byzantine)
  return None, "NO_CONSENSUS"

Safety guarantee:
  - If <1/3 stake is Byzantine: safety preserved (no conflicting commits)
  - Liveness: requires ≥2/3 honest stake

Example: 100 validators, stakes = [10, 8, 5, 5, 3, ...] (Pareto distributed)
  Top 10 validators: 67% stake → Can form consensus
  Byzantine resilience: Up to 33% malicious stake by value
</div>

<h3>6.4 Performance Metrics</h3>

<h4>Throughput vs Latency</h4>

<table>
  <thead>
    <tr>
      <th>Pattern</th>
      <th>Throughput (trials/sec)</th>
      <th>Latency (time to consensus)</th>
      <th>Resource Efficiency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Sequential</td>
      <td>1 / t_trial</td>
      <td>n · t_trial</td>
      <td>100% utilization</td>
    </tr>
    <tr>
      <td>Parallel (P procs)</td>
      <td>P / t_trial</td>
      <td>(n/P) · t_trial</td>
      <td>~100% (if n >> P)</td>
    </tr>
    <tr>
      <td>Async (variable latency)</td>
      <td>P / E[t_trial]</td>
      <td>Median(n fastest)</td>
      <td>60-80% (tail cancellation)</td>
    </tr>
    <tr>
      <td>Quorum (k < n)</td>
      <td>P / E[t_trial]</td>
      <td>(k/P) · t_median</td>
      <td>k/n (wasteful if k << n)</td>
    </tr>
    <tr>
      <td>Streaming</td>
      <td>1 / t_trial</td>
      <td>Variable (early stop)</td>
      <td>~100% (online stats)</td>
    </tr>
  </tbody>
</table>

<h4>Scalability Analysis</h4>

<div class="code-block">Parallel efficiency as function of processors P:

Ideal (embarrassingly parallel):
  Speedup(P) = P
  Efficiency(P) = 1

Realistic (with overhead):
  Speedup(P) = P / (1 + overhead_fraction)

Amdahl's Law (with sequential fraction s):
  Speedup(P) = 1 / (s + (1-s)/P)

Example: 5% aggregation overhead (sequential)
  P=10: Speedup = 9.5× (95% efficient)
  P=100: Speedup = 95× (95% efficient)
  P=1000: Speedup = 952× (95% efficient)

Communication-bound regime:
  When communication_time > computation_time / P
  Optimal batch size: balance communication vs parallelism
</div>

<div class="highlight-box">
<strong>Implementation Recommendations:</strong><br><br>
<strong>Low-latency applications:</strong> Async + quorum (k=⌈n/2⌉+1)<br>
<strong>High-throughput batch:</strong> Parallel execution with full n trials<br>
<strong>Resource-constrained:</strong> Streaming + adaptive stopping<br>
<strong>Byzantine environments:</strong> Weighted voting with 2/3 threshold<br>
<strong>Heterogeneous quality:</strong> Quality-weighted consensus
</div>

<div class="references">
  <h2 id="references">References</h2>
  <ol>
    <li><strong>Chernoff, H.</strong> (1952). A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations. <em>Annals of Mathematical Statistics</em>, 23(4), 493-507.</li>
    <li><strong>Hoeffding, W.</strong> (1963). Probability inequalities for sums of bounded random variables. <em>Journal of the American Statistical Association</em>, 58(301), 13-30.</li>
    <li><strong>Howard, S. R., Ramdas, A., McAuliffe, J., & Sekhon, J.</strong> (2021). Time-uniform, nonparametric, nonasymptotic confidence sequences. <em>Annals of Statistics</em>, 49(2), 1055-1080.</li>
    <li><strong>Dwork, C., & Roth, A.</strong> (2014). The algorithmic foundations of differential privacy. <em>Foundations and Trends in Theoretical Computer Science</em>, 9(3-4), 211-407.</li>
    <li><strong>McMahan, B., Moore, E., Ramage, D., Hampson, S., & Arcas, B. A.</strong> (2017). Communication-efficient learning of deep networks from decentralized data. <em>AISTATS</em>.</li>
    <li><strong>Castro, M., & Liskov, B.</strong> (1999). Practical Byzantine fault tolerance. <em>OSDI</em>, 99, 173-186.</li>
    <li><strong>Lynch, N. A.</strong> (1996). <em>Distributed Algorithms</em>. Morgan Kaufmann Publishers.</li>
    <li><strong>Robert, C. P., & Casella, G.</strong> (2004). <em>Monte Carlo Statistical Methods</em> (2nd ed.). Springer.</li>
    <li><strong>Wald, A.</strong> (1945). Sequential tests of statistical hypotheses. <em>Annals of Mathematical Statistics</em>, 16(2), 117-186.</li>
    <li><strong>Welford, B. P.</strong> (1962). Note on a method for calculating corrected sums of squares and products. <em>Technometrics</em>, 4(3), 419-420.</li>
    <li><strong>Kairouz, P., McMahan, H. B., et al.</strong> (2021). Advances and open problems in federated learning. <em>Foundations and Trends in Machine Learning</em>, 14(1-2), 1-210.</li>
    <li><strong>Gilad, Y., Hemo, R., Micali, S., Vlachos, G., & Zeldovich, N.</strong> (2017). Algorand: Scaling Byzantine agreements for cryptocurrencies. <em>SOSP</em>, 51-68.</li>
  </ol>
</div>

<script src="../theme-sync.js"></script>
</body>
</html>
