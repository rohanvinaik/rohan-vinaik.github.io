<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Enhanced Genomic Marketplace Tokenomics | Rohan Vinaik</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;700&display=swap" rel="stylesheet">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    :root {
      --bg: #1a1a1a;
      --text: #e0e0e0;
      --text-secondary: #808080;
      --accent: #00ffff;
      --border: rgba(255, 255, 255, 0.1);
      --code-bg: #222222;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'JetBrains Mono', monospace;
      background: var(--bg);
      color: var(--text);
      line-height: 1.6;
      padding: 20px;
      max-width: 900px;
      margin: 0 auto;
    }
    h1 {
      color: var(--accent);
      font-size: 1.5rem;
      margin-bottom: 8px;
      letter-spacing: 0.02em;
    }
    h2 {
      color: var(--accent);
      font-size: 1.1rem;
      margin-top: 32px;
      margin-bottom: 16px;
      padding-bottom: 8px;
      border-bottom: 1px solid var(--border);
    }
    h3 {
      color: var(--accent);
      font-size: 0.95rem;
      margin-top: 24px;
      margin-bottom: 12px;
    }
    h4 {
      color: var(--text);
      font-size: 0.85rem;
      margin-top: 16px;
      margin-bottom: 8px;
    }
    p { margin-bottom: 16px; font-size: 0.85rem; }
    a {
      color: var(--accent);
      text-decoration: none;
      border-bottom: 1px dotted var(--accent);
    }
    a:hover { border-bottom-style: solid; }
    .back-link {
      display: inline-block;
      margin-bottom: 24px;
      font-size: 0.85rem;
    }
    .paper-meta {
      color: var(--text-secondary);
      font-size: 0.75rem;
      margin-bottom: 24px;
    }
    .abstract {
      background: var(--code-bg);
      padding: 20px;
      border-left: 3px solid var(--accent);
      margin-bottom: 32px;
      font-size: 0.85rem;
    }
    .tags {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 32px;
    }
    .tag {
      background: var(--code-bg);
      padding: 4px 12px;
      border: 1px solid var(--border);
      font-size: 0.7rem;
      color: var(--accent);
      text-decoration: none;
      border-bottom: none;
    }
    .tag:hover {
      background: var(--accent);
      color: var(--bg);
      border-color: var(--accent);
    }
    .quick-nav {
      background: var(--code-bg);
      padding: 16px;
      margin-bottom: 32px;
      border: 1px solid var(--border);
    }
    .quick-nav h3 {
      margin-top: 0;
      font-size: 0.85rem;
    }
    .quick-nav ul {
      list-style: none;
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 8px;
      margin-top: 12px;
    }
    .quick-nav a {
      font-size: 0.75rem;
      border-bottom: none;
      padding: 4px 0;
      display: block;
    }
    .quick-nav a:hover { color: var(--bg); background: var(--accent); padding-left: 8px; }
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
      font-size: 0.75rem;
    }
    th, td {
      border: 1px solid var(--border);
      padding: 12px;
      text-align: left;
    }
    th {
      background: var(--code-bg);
      color: var(--accent);
      font-weight: 600;
    }
    ul, ol {
      margin-bottom: 16px;
      padding-left: 24px;
    }
    li {
      margin-bottom: 8px;
      font-size: 0.85rem;
    }
    .equation-block {
      background: var(--code-bg);
      padding: 16px;
      margin: 20px 0;
      border-left: 3px solid var(--accent);
      overflow-x: auto;
    }
    code {
      background: var(--code-bg);
      padding: 2px 6px;
      font-size: 0.8rem;
      color: var(--accent);
    }
    .attack-box {
      background: var(--code-bg);
      padding: 16px;
      margin: 20px 0;
      border-left: 3px solid #ff6b6b;
    }
    .attack-box h4 {
      color: #ff6b6b;
      margin-top: 0;
    }
    @media (max-width: 768px) {
      body { padding: 12px; }
      h1 { font-size: 1.2rem; }
      h2 { font-size: 1rem; }
      table { font-size: 0.65rem; }
      th, td { padding: 8px; }
    }
  </style>
</head>
<body>

<a href="../index.html#papers" class="back-link">← Back to Papers</a>

<h1>Enhanced Genomic Marketplace Tokenomics</h1>
<div class="paper-meta">2025 · TECHNICAL REFERENCE</div>

<div class="tags">
  <a href="../index.html?filter=GENOMICS" class="tag">GENOMICS</a>
  <a href="../index.html?filter=CRYPTOGRAPHY" class="tag">CRYPTOGRAPHY</a>
  <a href="../index.html?filter=MECHANISM-DESIGN" class="tag">MECHANISM-DESIGN</a>
  <a href="../index.html?filter=GAME-THEORY" class="tag">GAME-THEORY</a>
  <a href="../index.html?filter=TOKENOMICS" class="tag">TOKENOMICS</a>
  <a href="../index.html?filter=DISTRIBUTED" class="tag">DISTRIBUTED</a>
  <a href="../index.html?filter=PRIVACY" class="tag">PRIVACY</a>
  <a href="../index.html?filter=INCENTIVE-SYSTEMS" class="tag">INCENTIVE-SYSTEMS</a>
</div>

<div class="abstract">
  <strong>Abstract:</strong> This technical reference presents a comprehensive game-theoretic and economic framework for decentralized genomic data marketplaces. We formalize market structure with four participant classes, design utility tokens with deflationary mechanisms and velocity economics, establish incentive-compatible reward functions for quality and diversity, analyze economic security against Sybil attacks and collusion, model market equilibrium dynamics, and apply mechanism design theory (VCG mechanisms, proper scoring rules, peer prediction) to ensure truthful reporting. The framework addresses the fundamental challenge of aligning economic incentives with data quality, privacy preservation, and long-term sustainability in privacy-preserving genomic data exchange.
</div>

<div class="quick-nav">
  <h3>Quick Navigation</h3>
  <ul>
    <li><a href="#market-structure">Market Structure</a></li>
    <li><a href="#token-design">Token Design</a></li>
    <li><a href="#incentive-mechanisms">Incentive Mechanisms</a></li>
    <li><a href="#economic-security">Economic Security</a></li>
    <li><a href="#equilibrium">Market Equilibrium</a></li>
    <li><a href="#mechanism-design">Mechanism Design</a></li>
  </ul>
</div>

<h2 id="market-structure">1. Market Structure</h2>

<p>The genomic data marketplace operates as a multi-sided platform with four distinct participant classes. We model this as a directed graph \(G = (V, E)\) where \(V\) represents participant nodes and \(E\) represents economic flows (token transfers, data access, validation services).</p>

<h3>1.1 Participant Roles and Utility Functions</h3>

<table>
  <thead>
    <tr>
      <th>Role</th>
      <th>Cardinality</th>
      <th>Primary Function</th>
      <th>Utility Function</th>
      <th>Strategic Space</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Data Providers (P)</td>
      <td>\(n_P \sim 10^4\)-\(10^6\)</td>
      <td>Contribute genomic data and metadata</td>
      <td>\(U_P = R_P - C_P - \text{Privacy Risk}\)</td>
      <td>Quality level, privacy budget, staking amount</td>
    </tr>
    <tr>
      <td>Data Consumers (C)</td>
      <td>\(n_C \sim 10^3\)-\(10^5\)</td>
      <td>Query genomic datasets for research</td>
      <td>\(U_C = V_C - P_C - \text{Access Fees}\)</td>
      <td>Query frequency, dataset selection, payment</td>
    </tr>
    <tr>
      <td>Platform Operators (O)</td>
      <td>\(n_O \sim 10\)-\(10^2\)</td>
      <td>Infrastructure, storage, computation</td>
      <td>\(U_O = \text{Fees} + \text{Stake Rewards} - \text{Costs}\)</td>
      <td>Fee structure, infrastructure investment</td>
    </tr>
    <tr>
      <td>Validators (V)</td>
      <td>\(n_V \sim 10^2\)-\(10^3\)</td>
      <td>Verify data quality and provenance</td>
      <td>\(U_V = \text{Validation Rewards} - \text{Stake Risk}\)</td>
      <td>Validation accuracy, stake amount</td>
    </tr>
  </tbody>
</table>

<h3>1.2 Economic Flow Network</h3>

<p>We define four primary flow types in the marketplace graph:</p>

<div class="equation-block">
\[
\begin{aligned}
\mathcal{F}_{\text{data}} &: P \rightarrow O \rightarrow C \quad \text{(privacy-preserving queries)} \\
\mathcal{F}_{\text{payment}} &: C \rightarrow O \rightarrow P \quad \text{(token transfers)} \\
\mathcal{F}_{\text{validation}} &: V \leftrightarrow O \quad \text{(stake and rewards)} \\
\mathcal{F}_{\text{governance}} &: \{P, C, V, O\} \rightarrow \text{Protocol} \quad \text{(voting)}
\end{aligned}
\]
</div>

<h3>1.3 Data Provider Incentive Structure</h3>

<p>Providers maximize expected utility over time horizon \(T\):</p>

<div class="equation-block">
\[
\max_{q_i, \epsilon_i, s_i} \mathbb{E}\left[\sum_{t=0}^T \beta^t \left(R_{i,t}(q_i, \epsilon_i) - C_{i,t}(s_i) - \rho \cdot \text{Risk}_{i,t}(\epsilon_i)\right)\right]
\]
</div>

<p>Where:</p>
<ul>
  <li>\(q_i \in [0,1]\) = Quality level choice (coverage, metadata richness)</li>
  <li>\(\epsilon_i > 0\) = Privacy budget (smaller = stronger privacy)</li>
  <li>\(s_i \geq 0\) = Staking amount</li>
  <li>\(\beta \in (0,1)\) = Temporal discount factor (typically 0.95-0.99)</li>
  <li>\(\rho > 0\) = Risk aversion parameter</li>
  <li>\(R_{i,t}\) = Rewards from data contribution (detailed in Section 3)</li>
  <li>\(C_{i,t}\) = Costs (sequencing, storage, opportunity cost of staked capital)</li>
</ul>

<h3>1.4 Data Consumer Demand Function</h3>

<p>Consumers derive value from dataset access and quality:</p>

<div class="equation-block">
\[
V_C(D, Q) = \sum_{d \in D} \left[\alpha_d \cdot Q_d^{\gamma} \cdot \log(1 + n_d) - \tau \cdot \mathbb{I}[\text{Privacy}(d) < \epsilon_{\min}]\right]
\]
</div>

<p>Where:</p>
<ul>
  <li>\(D\) = Set of datasets accessed</li>
  <li>\(Q_d\) = Quality score of dataset \(d\)</li>
  <li>\(\gamma > 1\) = Quality elasticity (superlinear value from quality)</li>
  <li>\(n_d\) = Sample size in dataset \(d\)</li>
  <li>\(\alpha_d\) = Domain-specific value coefficient</li>
  <li>\(\tau\) = Penalty for insufficient privacy (compliance risk)</li>
  <li>\(\epsilon_{\min}\) = Minimum acceptable privacy budget</li>
</ul>

<h3>1.5 Platform Operator Optimization</h3>

<p>Operators balance fee extraction with platform growth:</p>

<div class="equation-block">
\[
\max_{f_P, f_C, f_O} \Pi_O = \underbrace{f_C \cdot n_C \cdot q_C}_{\text{consumer fees}} + \underbrace{f_P \cdot n_P \cdot q_P}_{\text{provider fees}} + \underbrace{f_O \cdot \sum_V s_V}_{\text{operator fees}} - \text{Infrastructure Costs}
\]
</div>

<p>Subject to participation constraints:</p>

<div class="equation-block">
\[
\begin{aligned}
U_P(f_P) &\geq \bar{U}_P \quad \text{(provider retention)} \\
U_C(f_C) &\geq \bar{U}_C \quad \text{(consumer retention)} \\
\sum_i f_i &\leq f_{\max} \quad \text{(competitiveness constraint)}
\end{aligned}
\]
</div>

<h3>1.6 Validator Game</h3>

<p>Validators engage in a repeated signaling game where honest validation is enforced through stake-at-risk:</p>

<div class="equation-block">
\[
U_V(a_V, a_{-V}) = \begin{cases}
r_V \cdot s_V & \text{if } a_V = \text{honest} \\
r_V \cdot s_V + \Delta - \mathbb{P}(\text{caught}) \cdot (s_V + \text{penalty}) & \text{if } a_V = \text{dishonest}
\end{cases}
\]
</div>

<p>Where \(\Delta\) is potential gain from collusion and \(\mathbb{P}(\text{caught})\) increases with number of honest validators.</p>

<h2 id="token-design">2. Token Design</h2>

<h3>2.1 Token Utility Matrix</h3>

<table>
  <thead>
    <tr>
      <th>Utility Function</th>
      <th>Mechanism</th>
      <th>Velocity Impact</th>
      <th>Value Accrual</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Medium of Exchange</td>
      <td>Required for all data queries and access</td>
      <td>High (+)</td>
      <td>Transaction volume</td>
    </tr>
    <tr>
      <td>Staking Collateral</td>
      <td>Validators and providers lock tokens</td>
      <td>Low (−)</td>
      <td>Security premium</td>
    </tr>
    <tr>
      <td>Governance Rights</td>
      <td>Token-weighted voting on protocol parameters</td>
      <td>Low (−)</td>
      <td>Control premium</td>
    </tr>
    <tr>
      <td>Reward Distribution</td>
      <td>Emissions to providers and validators</td>
      <td>Medium</td>
      <td>Network growth</td>
    </tr>
    <tr>
      <td>Fee Burning</td>
      <td>Deflationary sink for transaction fees</td>
      <td>N/A (−)</td>
      <td>Scarcity value</td>
    </tr>
  </tbody>
</table>

<h3>2.2 Dynamic Token Supply Model</h3>

<p>The total token supply evolves according to a stochastic differential equation incorporating emissions, burns, and staking:</p>

<div class="equation-block">
\[
dS(t) = \left[E(t) - B(t) - \lambda_S \cdot S_{\text{staked}}(t)\right]dt + \sigma_S \cdot dW_t
\]
</div>

<p>Where:</p>
<ul>
  <li>\(S(t)\) = Total token supply at time \(t\)</li>
  <li>\(E(t)\) = Emission rate (rewards to providers and validators)</li>
  <li>\(B(t)\) = Burn rate (fees and penalties destroyed)</li>
  <li>\(\lambda_S\) = Staking removal rate (tokens locked, effectively reducing circulation)</li>
  <li>\(S_{\text{staked}}(t)\) = Amount of staked tokens</li>
  <li>\(\sigma_S\) = Volatility parameter</li>
  <li>\(dW_t\) = Wiener process (market noise)</li>
</ul>

<h3>2.3 Adaptive Emission Schedule</h3>

<p>Emissions adapt to network growth and security requirements:</p>

<div class="equation-block">
\[
E(t) = E_0 \cdot e^{-\lambda t} \cdot \left(1 + \kappa \cdot \frac{TVL(t)}{TVL_{\text{target}}}\right) + E_{\infty}
\]
</div>

<p>Parameters:</p>
<ul>
  <li>\(E_0 = 5 \times 10^6\) tokens/year (initial bootstrap emission)</li>
  <li>\(\lambda = 0.15\) year\(^{-1}\) (decay rate, \(t_{1/2} \approx 4.6\) years)</li>
  <li>\(\kappa = 0.3\) (TVL sensitivity coefficient)</li>
  <li>\(TVL(t)\) = Total Value Locked (in USD equivalent)</li>
  <li>\(TVL_{\text{target}} = 10^8\) USD (target network security)</li>
  <li>\(E_{\infty} = 2 \times 10^4\) tokens/year (terminal minimum inflation \(\approx 0.2\%\))</li>
</ul>

<h3>2.4 Multi-Channel Burn Mechanisms</h3>

<p>Burn rate aggregates multiple deflationary channels:</p>

<div class="equation-block">
\[
B(t) = \underbrace{f_{\text{tx}} \cdot V_{\text{tx}}(t)}_{\text{transaction burns}} + \underbrace{\sum_{i \in \text{Slash}} S_i}_{\text{slashing}} + \underbrace{b_q \cdot \sum_{j \in \text{LowQ}} \Delta Q_j}_{\text{quality penalties}} + \underbrace{b_p \cdot \sum_{k \in \text{Privacy}} \Delta P_k}_{\text{privacy breaches}}
\]
</div>

<table>
  <thead>
    <tr>
      <th>Burn Channel</th>
      <th>Rate Parameter</th>
      <th>Trigger Condition</th>
      <th>Annual Volume Est.</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Transaction Fees</td>
      <td>\(f_{\text{tx}} = 0.005\) (0.5%)</td>
      <td>Every query/access</td>
      <td>\(10^6\) tokens/year</td>
    </tr>
    <tr>
      <td>Validator Slashing</td>
      <td>100% of stake</td>
      <td>Provable dishonesty</td>
      <td>\(10^4\) tokens/year</td>
    </tr>
    <tr>
      <td>Provider Quality Violations</td>
      <td>\(b_q = 100\) tokens per \(\Delta Q\)</td>
      <td>\(Q_{\text{actual}} < Q_{\text{claimed}} - \theta\)</td>
      <td>\(5 \times 10^3\) tokens/year</td>
    </tr>
    <tr>
      <td>Privacy Breaches</td>
      <td>Complete stake forfeiture</td>
      <td>Differential privacy violation</td>
      <td>\(10^3\) tokens/year</td>
    </tr>
    <tr>
      <td>Governance Proposals</td>
      <td>\(b_g = 500\) tokens per failed proposal</td>
      <td>Proposal spam prevention</td>
      <td>\(10^3\) tokens/year</td>
    </tr>
  </tbody>
</table>

<h3>2.5 Staking Economics</h3>

<p>Staking requirements scale with participant role and risk exposure:</p>

<div class="equation-block">
\[
S_{\text{required}}(r, V_{\text{data}}) = \begin{cases}
k_P \cdot V_{\text{data}}^{\alpha_P} & \text{if role } r = \text{Provider} \\
k_V \cdot (n_V)^{-\beta_V} \cdot \text{TVL}^{\alpha_V} & \text{if role } r = \text{Validator} \\
k_O \cdot \text{Infrastructure}_{\text{cost}} & \text{if role } r = \text{Operator}
\end{cases}
\]
</div>

<p>Parameters:</p>
<ul>
  <li>\(k_P = 10^3\), \(\alpha_P = 0.6\) (provider stake scales sublinearly with data value)</li>
  <li>\(k_V = 10^6\), \(\beta_V = 0.3\), \(\alpha_V = 0.4\) (validator stake decreases with validator count to encourage decentralization)</li>
  <li>\(k_O = 1.5\) (operator stake is 1.5x infrastructure investment)</li>
</ul>

<h3>2.6 Token Velocity Control</h3>

<p>Velocity is modulated through lockup incentives and utility design:</p>

<div class="equation-block">
\[
v(t) = \frac{V_{\text{tx}}(t)}{S_{\text{circulating}}(t)} = v_{\text{base}} \cdot \left(1 - \frac{S_{\text{staked}}(t)}{S_{\text{total}}(t)}\right) \cdot \left(1 + \eta \cdot \text{Governance}_{\text{activity}}(t)\right)
\]
</div>

<p>Where:</p>
<ul>
  <li>\(v_{\text{base}} = 12\) (baseline: token changes hands 12 times per year)</li>
  <li>Staking fraction reduces velocity by removing tokens from circulation</li>
  <li>\(\eta = 0.2\) (governance activity moderately increases velocity)</li>
</ul>

<p>Target velocity: \(v_{\text{target}} = 6\) (achieved with \(\approx 50\%\) staking ratio)</p>

<h3>2.7 Token Valuation Model</h3>

<p>Fundamental token value derives from discounted future transaction volume:</p>

<div class="equation-block">
\[
V_{\text{token}} = \frac{1}{v_{\text{target}}} \cdot \sum_{t=1}^{\infty} \frac{V_{\text{tx}}(t) \cdot (1 - f_{\text{burn}})}{(1 + r)^t \cdot S_{\text{circulating}}(t)}
\]
</div>

<p>With expected growth:</p>

<div class="equation-block">
\[
V_{\text{tx}}(t) = V_0 \cdot (1 + g)^t
\]
</div>

<p>Where:</p>
<ul>
  <li>\(V_0 = 10^7\) USD/year (initial transaction volume)</li>
  <li>\(g = 0.3\) (30% annual growth in early years, declining over time)</li>
  <li>\(r = 0.1\) (10% discount rate for crypto assets)</li>
  <li>\(f_{\text{burn}} = 0.005\) (burn fraction)</li>
</ul>

<h2 id="incentive-mechanisms">3. Incentive Mechanisms</h2>

<h3>3.1 Comprehensive Reward Function</h3>

<p>Provider rewards aggregate multiple incentive channels:</p>

<div class="equation-block">
\[
R_i(t) = \underbrace{R_{\text{base}}(Q_i, U_i)}_{\text{quality-usage}} \cdot \underbrace{D_i(a_i, N)}_{\text{diversity}} \cdot \underbrace{P_i(\epsilon_i)}_{\text{privacy}} \cdot \underbrace{L_i(t)}_{\text{longevity}} + \underbrace{B_i(r_i)}_{\text{rarity bonus}}
\]
</div>

<h3>3.2 Base Quality-Weighted Rewards</h3>

<div class="equation-block">
\[
R_{\text{base}}(Q_i, U_i) = \alpha \cdot \left(\frac{Q_i}{\bar{Q}}\right)^{\beta} \cdot \left(\frac{U_i}{\bar{U}}\right)^{\gamma} \cdot T_{\text{epoch}}
\]
</div>

<p>Where:</p>
<ul>
  <li>\(\alpha\) = Normalization constant such that \(\sum_i R_i = T_{\text{epoch}}\) (total reward pool)</li>
  <li>\(Q_i \in [0,1]\) = Composite quality score (detailed below)</li>
  <li>\(\bar{Q}\) = Mean quality across all providers (dynamic baseline)</li>
  <li>\(\beta = 1.8\) = Quality elasticity (strongly superlinear to incentivize high quality)</li>
  <li>\(U_i\) = Usage count (number of queries accessing provider \(i\)'s data)</li>
  <li>\(\bar{U}\) = Mean usage</li>
  <li>\(\gamma = 1.2\) = Usage elasticity (superlinear to reward valuable data)</li>
  <li>\(T_{\text{epoch}} = 10^5\) tokens per epoch (e.g., monthly reward pool)</li>
</ul>

<h3>3.3 Multi-Dimensional Quality Score</h3>

<p>Quality aggregates six weighted components:</p>

<div class="equation-block">
\[
Q_i = \sum_{j=1}^{6} w_j \cdot q_{i,j} \quad \text{where} \quad \sum_{j=1}^{6} w_j = 1
\]
</div>

<table>
  <thead>
    <tr>
      <th>Component \(q_{i,j}\)</th>
      <th>Weight \(w_j\)</th>
      <th>Measurement</th>
      <th>Verification Method</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Coverage Completeness</td>
      <td>0.25</td>
      <td>\(\frac{\text{bases sequenced}}{\text{genome length}}\)</td>
      <td>Cryptographic commitment to coverage</td>
    </tr>
    <tr>
      <td>Sequencing Depth</td>
      <td>0.15</td>
      <td>\(\min(1, \frac{\text{depth}}{30})\)</td>
      <td>Zero-knowledge proof of depth distribution</td>
    </tr>
    <tr>
      <td>Metadata Richness</td>
      <td>0.20</td>
      <td>\(\frac{\text{fields provided}}{\text{total schema fields}}\)</td>
      <td>Schema validation</td>
    </tr>
    <tr>
      <td>Phenotype Data</td>
      <td>0.15</td>
      <td>Completeness of clinical phenotypes</td>
      <td>Ontology-based verification</td>
    </tr>
    <tr>
      <td>Validation Score</td>
      <td>0.15</td>
      <td>Independent re-sequencing match rate</td>
      <td>Random audit sampling</td>
    </tr>
    <tr>
      <td>Privacy Compliance</td>
      <td>0.10</td>
      <td>\(1 - \frac{\epsilon_i}{\epsilon_{\max}}\)</td>
      <td>Differential privacy proof verification</td>
    </tr>
  </tbody>
</table>

<h3>3.4 Diversity Incentive Function</h3>

<p>Diversity multiplier prevents dataset homogeneity and rewards underrepresented populations:</p>

<div class="equation-block">
\[
D_i(a_i, N) = 1 + \gamma_D \cdot \left[\underbrace{\left(1 - \frac{n_{a_i}}{N}\right)}_{\text{ancestry rarity}} + \underbrace{\zeta \cdot \mathbb{I}[a_i \in \mathcal{A}_{\text{under}}]}_{\text{underrepresented bonus}} + \underbrace{\phi \cdot H(a_i)}_{\text{admixture bonus}}\right]
\]
</div>

<p>Where:</p>
<ul>
  <li>\(a_i\) = Ancestry group of provider \(i\)</li>
  <li>\(n_{a_i}\) = Number of samples from ancestry \(a_i\) in marketplace</li>
  <li>\(N\) = Total samples</li>
  <li>\(\gamma_D = 0.5\) = Overall diversity bonus coefficient</li>
  <li>\(\mathcal{A}_{\text{under}} = \{\text{African}, \text{Indigenous}, \text{Oceanian}, \ldots\}\) = Historically underrepresented groups</li>
  <li>\(\zeta = 0.3\) = Additional bonus for underrepresented populations</li>
  <li>\(H(a_i)\) = Admixture entropy (Shannon entropy of ancestry proportions)</li>
  <li>\(\phi = 0.2\) = Admixture bonus coefficient</li>
</ul>

<p>Example: European ancestry at 60% of marketplace receives \(D = 1 + 0.5 \cdot (1 - 0.6) = 1.2\); African ancestry at 5% receives \(D = 1 + 0.5 \cdot [(1 - 0.05) + 0.3] = 2.025\)</p>

<h3>3.5 Privacy Contribution Multiplier</h3>

<p>Providers enabling stronger privacy guarantees receive exponential rewards:</p>

<div class="equation-block">
\[
P_i(\epsilon_i) = \exp\left(\delta_P \cdot \log\left(\frac{\epsilon_{\max}}{\epsilon_i}\right)\right) = \left(\frac{\epsilon_{\max}}{\epsilon_i}\right)^{\delta_P}
\]
</div>

<p>Where:</p>
<ul>
  <li>\(\epsilon_i\) = Differential privacy budget consumed per query (smaller = stronger privacy)</li>
  <li>\(\epsilon_{\max} = 1.0\) = Maximum allowed privacy budget</li>
  <li>\(\delta_P = 0.3\) = Privacy bonus exponent</li>
</ul>

<p>Example: \(\epsilon_i = 0.1\) gives \(P_i = 10^{0.3} \approx 2.0\); \(\epsilon_i = 0.01\) gives \(P_i = 100^{0.3} \approx 3.98\)</p>

<h3>3.6 Longevity Multiplier</h3>

<p>Long-term data availability is rewarded through time-weighted bonuses:</p>

<div class="equation-block">
\[
L_i(t) = 1 + \eta_L \cdot \left(1 - e^{-\mu t}\right) + \nu_L \cdot \min\left(1, \frac{t}{t_{\text{vest}}}\right)
\]
</div>

<p>Where:</p>
<ul>
  <li>\(\eta_L = 0.4\) = Maximum exponential bonus (approaches asymptotically)</li>
  <li>\(\mu = 0.08\) month\(^{-1}\) = Time constant (\(t_{1/2} \approx 8.7\) months)</li>
  <li>\(\nu_L = 0.2\) = Linear vesting bonus</li>
  <li>\(t_{\text{vest}} = 24\) months = Full vesting period</li>
  <li>\(t\) = Months of continuous data availability</li>
</ul>

<p>At \(t = 12\) months: \(L_i = 1 + 0.4 \cdot (1 - e^{-0.96}) + 0.2 \cdot 0.5 \approx 1.42\)</p>

<h3>3.7 Rarity Bonus for Rare Variants</h3>

<p>Providers contributing rare variants (MAF \(< 0.01\)) receive discrete bonuses:</p>

<div class="equation-block">
\[
B_i(r_i) = \sum_{v \in \mathcal{V}_i} b(v) \quad \text{where} \quad b(v) = \begin{cases}
1000 & \text{if } \text{MAF}(v) < 10^{-4} \text{ (ultra-rare)} \\
100 & \text{if } 10^{-4} \leq \text{MAF}(v) < 10^{-3} \\
10 & \text{if } 10^{-3} \leq \text{MAF}(v) < 10^{-2} \\
0 & \text{otherwise}
\end{cases}
\]
</div>

<p>Where \(\mathcal{V}_i\) is the set of novel or rare variants contributed by provider \(i\).</p>

<h3>3.8 Consumer Reputation System</h3>

<p>Consumers build reputation through quality queries and data attribution:</p>

<div class="equation-block">
\[
\text{Rep}_C(t+1) = \lambda_C \cdot \text{Rep}_C(t) + (1 - \lambda_C) \cdot \left[w_1 \cdot \text{QueryQuality}(t) + w_2 \cdot \text{Attribution}(t) + w_3 \cdot \text{Publication}(t)\right]
\]
</div>

<p>High-reputation consumers receive:</p>
<ul>
  <li>Priority access to new datasets (queue jumping)</li>
  <li>Reduced query fees (\(5\%-20\%\) discount)</li>
  <li>Early access to rare variants</li>
  <li>Governance voting weight multiplier (\(1.5 \times\) at max reputation)</li>
</ul>

<h2 id="economic-security">4. Economic Security</h2>

<h3>4.1 Sybil Attack Analysis</h3>

<p>A Sybil attacker attempts to create \(n_S\) fake identities to extract disproportionate rewards. We model the attacker's optimization problem:</p>

<div class="equation-block">
\[
\max_{n_S, q_S, s_S} \pi_{\text{Sybil}} = n_S \cdot R(q_S) - n_S \cdot s_{\text{min}} - C_{\text{fake}}(n_S, q_S)
\]
</div>

<p>Subject to detection probability:</p>

<div class="equation-block">
\[
\mathbb{P}(\text{detected} \mid n_S, q_S) = 1 - \exp\left(-\lambda_{\text{detect}} \cdot n_S \cdot \text{Similarity}(q_S)\right)
\]
</div>

<div class="attack-box">
<h4>Attack Scenario 1: Low-Quality Sybils</h4>

<p><strong>Strategy:</strong> Attacker creates 100 fake identities with minimal quality (\(q_S = 0.1\)) to extract base rewards.</p>

<p><strong>Economics:</strong></p>
<ul>
  <li>Cost: \(100 \times s_{\min} = 100 \times 10^3 = 10^5\) tokens (stake)</li>
  <li>Rewards per identity: \(R_{\text{base}} \cdot (0.1/\bar{Q})^{1.8} \cdot L \cdot D \cdot P \approx R_{\text{base}} \times 0.01\) (superlinear penalty)</li>
  <li>Total expected reward: \(100 \times 0.01 \times R_{\text{base}} = R_{\text{base}}\)</li>
  <li>Legitimate single high-quality provider (\(q = 0.9\)): \(R_{\text{base}} \cdot (0.9/\bar{Q})^{1.8} \approx 8 \times R_{\text{base}}\)</li>
</ul>

<p><strong>Defense:</strong> Superlinear quality rewards (\(\beta = 1.8\)) make low-quality Sybil attacks economically dominated by honest high-quality participation.</p>
</div>

<div class="attack-box">
<h4>Attack Scenario 2: High-Quality Duplicate Sybils</h4>

<p><strong>Strategy:</strong> Attacker submits same high-quality genome \(n_S = 10\) times with minor perturbations.</p>

<p><strong>Detection:</strong></p>
<div class="equation-block">
\[
\text{Similarity}(i, j) = \frac{\sum_{k} \mathbb{I}[\text{Genotype}_i(k) = \text{Genotype}_j(k)]}{\text{Total SNPs}}
\]
</div>

<ul>
  <li>Identical twins: Similarity \(\approx 0.9995\)</li>
  <li>Perturbed duplicates: Similarity \(\approx 0.9990\)</li>
  <li>Unrelated individuals: Similarity \(\approx 0.9985\)</li>
</ul>

<p><strong>Defense:</strong> Graph-based clustering flags identities with similarity \(> 0.999\). Stake slashing for duplicates: \(\text{Penalty} = n_S \times s_{\min}\).</p>
</div>

<h3>4.2 Identity Verification and Trust Tiers</h3>

<p>Optional identity verification provides Sybil resistance without compromising privacy:</p>

<table>
  <thead>
    <tr>
      <th>Trust Tier</th>
      <th>Verification Method</th>
      <th>Reward Multiplier</th>
      <th>Sybil Resistance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Anonymous (Tier 0)</td>
      <td>Stake only</td>
      <td>\(1.0 \times\)</td>
      <td>Economic (stake)</td>
    </tr>
    <tr>
      <td>Verified Individual (Tier 1)</td>
      <td>Zero-knowledge KYC proof</td>
      <td>\(1.3 \times\)</td>
      <td>Strong (unique government ID)</td>
    </tr>
    <tr>
      <td>Institutional (Tier 2)</td>
      <td>Institution credential + audit</td>
      <td>\(1.5 \times\)</td>
      <td>Very strong (org accountability)</td>
    </tr>
    <tr>
      <td>Research Partner (Tier 3)</td>
      <td>Multi-sig from recognized institutions</td>
      <td>\(2.0 \times\)</td>
      <td>Absolute (reputation stake)</td>
    </tr>
  </tbody>
</table>

<h3>4.3 51% Validator Attack</h3>

<p>An attacker controlling fraction \(f_A\) of validators attempts to certify false data quality:</p>

<div class="equation-block">
\[
\text{Attack Success} = \begin{cases}
0 & \text{if } f_A < f_{\text{threshold}} \\
\left(\frac{f_A - f_{\text{threshold}}}{1 - f_{\text{threshold}}}\right)^{\kappa} & \text{otherwise}
\end{cases}
\]
</div>

<p>Where \(f_{\text{threshold}} = 0.67\) (2/3 consensus) and \(\kappa = 2\) (quadratic difficulty).</p>

<p><strong>Economic Cost of Attack:</strong></p>

<div class="equation-block">
\[
C_{\text{attack}} = f_A \cdot \text{TVL}_{\text{validators}} + \mathbb{E}[\text{Penalty} \mid \text{caught}] \cdot \mathbb{P}(\text{caught})
\]
</div>

<p>With quadratic voting, stake required for 51% voting power:</p>

<div class="equation-block">
\[
S_{\text{required}}^{\text{attack}} = \left(\frac{0.51}{\sum_{i \neq A} \sqrt{S_i}}\right)^2 \cdot S_{\text{total}}
\]
</div>

<div class="attack-box">
<h4>Attack Scenario 3: Validator Cartel (67% Attack)</h4>

<p><strong>Objective:</strong> Colluding validators certify low-quality data as high-quality to extract rewards for co-conspirator providers.</p>

<p><strong>Requirements:</strong></p>
<ul>
  <li>Control \(f_A = 0.67\) of validator voting power</li>
  <li>With 200 validators and quadratic voting: need to control \(\approx 90\) top validators</li>
  <li>Estimated stake: \(0.67 \times \text{TVL}_V \approx 6.7 \times 10^7\) USD (assuming \(\text{TVL}_V = 10^8\) USD)</li>
</ul>

<p><strong>Expected Gain:</strong> Certify data worth \(V_{\text{false}} = 10^6\) USD as legitimate.</p>

<p><strong>Detection Probability:</strong></p>
<div class="equation-block">
\[
\mathbb{P}(\text{caught}) = 1 - \left(1 - f_{\text{audit}}\right)^{n_{\text{audits}}} = 1 - (0.9)^{10} \approx 0.65
\]
</div>

<p><strong>Expected Loss if Caught:</strong> \(0.67 \times \text{TVL}_V + \theta \times \text{TVL}_V = 0.77 \times 10^8 = 7.7 \times 10^7\) USD</p>

<p><strong>Expected Value of Attack:</strong></p>
<div class="equation-block">
\[
\mathbb{E}[V_{\text{attack}}] = (1 - 0.65) \times 10^6 - 0.65 \times 7.7 \times 10^7 = -5 \times 10^7 \text{ USD (negative)}
\]
</div>

<p><strong>Conclusion:</strong> Attack is economically irrational due to high stake requirements, slashing penalties, and audit detection.</p>
</div>

<h3>4.4 Collusion-Resistant Mechanism Design</h3>

<p>Prevent provider-consumer collusion (fake queries to inflate usage rewards):</p>

<p><strong>Commit-Reveal for Usage Statistics:</strong></p>

<div class="equation-block">
\[
\begin{aligned}
\text{Commit Phase:} &\quad C_i = H(U_i, r_i) \\
\text{Reveal Phase:} &\quad \text{Verify } H(U_i', r_i') = C_i \\
\text{Reward Calculation:} &\quad R_i \propto U_i' \text{ (only after reveal)}
\end{aligned}
\]
</div>

<p><strong>Query Cost with Stake-at-Risk:</strong> Consumers must stake tokens proportional to query complexity:</p>

<div class="equation-block">
\[
s_{\text{query}} = c_q \cdot \left(\text{Complexity} + \text{DataSize}\right) \quad \text{where } c_q = 10 \text{ tokens per unit}
\]
</div>

<p>Stake is slashed if query is flagged as fake (e.g., no downstream computational usage).</p>

<h3>4.5 Data Poisoning Defense</h3>

<p>Malicious providers may contribute corrupted genomic data to degrade dataset quality:</p>

<p><strong>Multi-Validator Cross-Validation:</strong></p>

<div class="equation-block">
\[
Q_i^{\text{consensus}} = \text{Median}\{Q_i^{(v_1)}, Q_i^{(v_2)}, \ldots, Q_i^{(v_m)}\} \quad \text{where } m \geq 5
\]
</div>

<p><strong>Statistical Outlier Detection:</strong> Flag samples with allele frequencies deviating from population expectations:</p>

<div class="equation-block">
\[
z_i(v) = \frac{\text{MAF}_i(v) - \mu_{\text{pop}}(v)}{\sigma_{\text{pop}}(v)}
\]
</div>

<p>Samples with \(|z_i(v)| > 5\) for multiple variants \(v\) are flagged for review.</p>

<p><strong>Provenance Proofs:</strong> Cryptographic commitments to sequencing provenance:</p>

<div class="equation-block">
\[
\text{Proof}_i = \text{SNARK}\{\exists \text{ (reads, alignment, variant calls)}: \text{Variants}_i = f(\text{reads}, \text{ref genome})\}
\]
</div>

<p><strong>Proportional Slashing:</strong></p>

<div class="equation-block">
\[
\text{Slash}_{\text{poison}}(i) = s_i \cdot \min\left(1, \left(\frac{N_{\text{poisoned}}^{(i)}}{N_{\text{total}}^{(i)}}\right)^{0.5} + \alpha_{\text{severity}}\right)
\]
</div>

<p>Where \(\alpha_{\text{severity}} \in [0, 1]\) increases with intentionality evidence.</p>

<h3>4.6 Eclipse Attack on Providers</h3>

<p>An attacker isolates a provider's network view to feed false quality scores:</p>

<div class="attack-box">
<h4>Attack Scenario 4: Provider Eclipse</h4>

<p><strong>Strategy:</strong> Attacker controls provider's network connections to present artificially high quality assessments, encouraging provider to lower actual quality while maintaining stake.</p>

<p><strong>Defense Mechanisms:</strong></p>
<ul>
  <li><strong>Diverse Validator Sampling:</strong> Providers query \(k = 10\) randomly selected validators, attacker must control \(> 0.5k\) to succeed</li>
  <li><strong>Verifiable Random Functions (VRF):</strong> Validator selection unpredictable and verifiable</li>
  <li><strong>Reputation Weighting:</strong> High-reputation validators weighted more heavily in consensus</li>
</ul>

<p><strong>Attack Success Probability:</strong> With \(f_A = 0.3\) of validators compromised:</p>
<div class="equation-block">
\[
\mathbb{P}(\text{eclipse}) = \sum_{i=6}^{10} \binom{10}{i} (0.3)^i (0.7)^{10-i} \approx 0.047 \text{ (4.7%)}
\]
</div>

<p>Expected loss from attack (including detection and slashing) exceeds expected gain.</p>
</div>

<h3>4.7 Long-Range Attack</h3>

<p>Attacker acquires old private keys with no remaining stake to rewrite history:</p>

<p><strong>Defense: Checkpointing and Social Consensus</strong></p>
<ul>
  <li>Periodic checkpoints signed by majority of current validators</li>
  <li>New nodes reject chains forking before latest checkpoint</li>
  <li>Validators sign commitment: "I will not sign conflicting histories"</li>
</ul>

<div class="equation-block">
\[
\text{Checkpoint}_t = \text{Sign}_{\text{Validators}}(\text{StateRoot}_t, t)
\]
</div>

<h2 id="equilibrium">5. Market Equilibrium</h2>

<h3>5.1 Supply-Demand Equilibrium Model</h3>

<p>The marketplace operates as a continuous double auction with price discovery. Provider supply function:</p>

<div class="equation-block">
\[
S(P, \mathbf{X}) = S_0 + \alpha_S \cdot P^{\beta_S} \cdot \prod_{i} X_i^{\gamma_i}
\]
</div>

<p>Where \(\mathbf{X} = (X_{\text{privacy}}, X_{\text{security}}, X_{\text{tech}})\) are exogenous factors:</p>
<ul>
  <li>\(X_{\text{privacy}}\) = Privacy regulation strength (e.g., GDPR compliance cost)</li>
  <li>\(X_{\text{security}}\) = Network security (stake-to-TVL ratio)</li>
  <li>\(X_{\text{tech}}\) = Sequencing cost reduction over time</li>
</ul>

<p>Parameters:</p>
<ul>
  <li>\(S_0 = 10^4\) (inelastic base supply from altruistic contributors)</li>
  <li>\(\alpha_S = 10^3\) (supply sensitivity)</li>
  <li>\(\beta_S = 1.5\) (supply elasticity, superlinear response to price)</li>
  <li>\(\gamma = [-0.3, 0.5, 0.8]\) (negative for privacy cost, positive for security and tech improvement)</li>
</ul>

<p>Consumer demand function:</p>

<div class="equation-block">
\[
D(P, V_{\text{research}}) = D_0 \cdot \left(\frac{P_0}{P}\right)^{\beta_D} \cdot \left(1 + \kappa_D \cdot V_{\text{research}}\right)
\]
</div>

<p>Where:</p>
<ul>
  <li>\(D_0 = 5 \times 10^4\) (base research demand)</li>
  <li>\(P_0 = 100\) tokens (reference price)</li>
  <li>\(\beta_D = 0.8\) (demand elasticity, sublinear due to inelastic research needs)</li>
  <li>\(V_{\text{research}}\) = Research value created (e.g., drug discovery breakthroughs)</li>
  <li>\(\kappa_D = 0.01\) (demand shift from value creation)</li>
</ul>

<p><strong>Equilibrium Condition:</strong></p>

<div class="equation-block">
\[
S(P^*, \mathbf{X}) = D(P^*, V_{\text{research}})
\]
</div>

<p>Solving numerically for baseline parameters yields \(P^* \approx 120\) tokens per genome-query.</p>

<h3>5.2 Multi-Sided Platform Pricing</h3>

<p>Platform operators face a two-sided pricing problem: set \(f_P\) (provider fee) and \(f_C\) (consumer fee) to maximize platform value:</p>

<div class="equation-block">
\[
\max_{f_P, f_C} \Pi(f_P, f_C) = (f_P + f_C) \cdot N_P(f_P) \cdot N_C(f_C) \cdot Q(f_P, f_C)
\]
</div>

<p>Where:</p>
<ul>
  <li>\(N_P(f_P) = N_P^0 \cdot e^{-\lambda_P f_P}\) (providers decrease exponentially with fees)</li>
  <li>\(N_C(f_C) = N_C^0 \cdot e^{-\lambda_C f_C}\) (consumers decrease exponentially with fees)</li>
  <li>\(Q(f_P, f_C) = Q_0 \cdot (1 - \omega_P f_P) \cdot (1 - \omega_C f_C)\) (quality decreases with fees)</li>
</ul>

<p><strong>First-Order Conditions:</strong></p>

<div class="equation-block">
\[
\begin{aligned}
\frac{\partial \Pi}{\partial f_P} &= N_C \cdot Q \cdot \left[N_P - (f_P + f_C) \lambda_P N_P - (f_P + f_C) \omega_P N_P\right] = 0 \\
\frac{\partial \Pi}{\partial f_C} &= N_P \cdot Q \cdot \left[N_C - (f_P + f_C) \lambda_C N_C - (f_P + f_C) \omega_C N_C\right] = 0
\end{aligned}
\]
</div>

<p><strong>Optimal Fee Structure:</strong></p>

<div class="equation-block">
\[
f_P^* = \frac{1}{2(\lambda_P + \omega_P)}, \quad f_C^* = \frac{1}{2(\lambda_C + \omega_C)}
\]
</div>

<p>With \(\lambda_P = 0.02\), \(\omega_P = 0.01\), \(\lambda_C = 0.015\), \(\omega_C = 0.008\):</p>
<ul>
  <li>\(f_P^* \approx 16.7\) tokens per contribution</li>
  <li>\(f_C^* \approx 21.7\) tokens per query</li>
</ul>

<p>Asymmetric pricing subsidizes providers (lower fee) to bootstrap supply.</p>

<h3>5.3 Token Value and Velocity Equilibrium</h3>

<p>Token value derives from Quantity Theory of Money applied to utility tokens:</p>

<div class="equation-block">
\[
V_{\text{token}} = \frac{PQ}{M \cdot v} = \frac{P^* \cdot \text{Transactions}_{\text{annual}}}{S_{\text{circulating}} \cdot v}
\]
</div>

<p>Where:</p>
<ul>
  <li>\(P^*\) = Equilibrium price per transaction (in fiat)</li>
  <li>\(\text{Transactions}_{\text{annual}} = N_P \cdot N_C \cdot q_{\text{avg}}\) (total annual queries)</li>
  <li>\(S_{\text{circulating}}\) = Circulating token supply</li>
  <li>\(v\) = Velocity (how many times token changes hands per year)</li>
</ul>

<p><strong>Velocity Equilibrium:</strong> Staking incentives create equilibrium between locked and circulating supply:</p>

<div class="equation-block">
\[
\frac{S_{\text{staked}}}{S_{\text{total}}} = \frac{r_{\text{stake}}}{r_{\text{stake}} + v \cdot r_{\text{tx}}}
\]
</div>

<p>Where:</p>
<ul>
  <li>\(r_{\text{stake}} = 0.15\) (15% annual staking rewards)</li>
  <li>\(r_{\text{tx}} = 0.05\) (5% annual return from transaction fee capture)</li>
  <li>\(v\) = Velocity (endogenous)</li>
</ul>

<p>Solving: with \(v = 6\), staking ratio \(\approx 0.33\) (33% of tokens staked).</p>

<h3>5.4 Nash Equilibrium in Provider Quality Game</h3>

<p>Providers engage in a non-cooperative game choosing quality levels \(q_i \in [0, 1]\). Provider \(i\)'s payoff:</p>

<div class="equation-block">
\[
u_i(q_i, q_{-i}) = R_i(q_i, q_{-i}) - C_i(q_i)
\]
</div>

<p>Where \(R_i(q_i, q_{-i})\) depends on relative quality (rewards are \(\propto (q_i/\bar{q})^{\beta}\)) and \(C_i(q_i) = c \cdot q_i^2\) (quadratic cost).</p>

<p><strong>Best Response Function:</strong></p>

<div class="equation-block">
\[
q_i^{\text{BR}}(q_{-i}) = \arg\max_{q_i} \left\{\alpha \cdot \left(\frac{q_i}{\bar{q}(q_i, q_{-i})}\right)^{\beta} \cdot T - c \cdot q_i^2\right\}
\]
</div>

<p>First-order condition:</p>

<div class="equation-block">
\[
\frac{\partial u_i}{\partial q_i} = \alpha \beta \cdot \frac{q_i^{\beta - 1}}{\bar{q}^{\beta}} - 2cq_i = 0
\]
</div>

<p><strong>Symmetric Nash Equilibrium:</strong> All providers choose \(q^* = q_i = \bar{q}\):</p>

<div class="equation-block">
\[
q^* = \left(\frac{\alpha \beta}{2c}\right)^{1/(3 - \beta)}
\]
</div>

<p>With \(\alpha = 10^4\), \(\beta = 1.8\), \(c = 10^3\):</p>

<div class="equation-block">
\[
q^* = \left(\frac{10^4 \cdot 1.8}{2 \cdot 10^3}\right)^{1/1.2} \approx 0.73
\]
</div>

<p>Equilibrium quality level is 0.73, balancing reward incentives against quadratic costs.</p>

<h3>5.5 Stackelberg Equilibrium: Platform as Leader</h3>

<p>Platform operators move first, setting fee structure; providers and consumers respond. This is a Stackelberg game:</p>

<div class="equation-block">
\[
\begin{aligned}
&\text{Stage 1 (Platform):} \quad \max_{f_P, f_C} \Pi(f_P, f_C) \\
&\text{Stage 2 (Providers):} \quad \max_{q_i} u_i(q_i, q_{-i}, f_P) \\
&\text{Stage 3 (Consumers):} \quad \max_{n_{\text{queries}}} V_C(n_{\text{queries}}, f_C)
\end{aligned}
\]
</div>

<p>Platform anticipates provider/consumer responses and incorporates into optimization:</p>

<div class="equation-block">
\[
\max_{f_P, f_C} \Pi(f_P, f_C, q^*(f_P), n^*(f_C))
\]
</div>

<p>Stackelberg equilibrium typically yields higher platform profits than Nash equilibrium but requires commitment to fee structure.</p>

<h3>5.6 Liquidity Pool Dynamics</h3>

<p>Automated market makers (AMMs) provide token-fiat liquidity. Constant product market maker:</p>

<div class="equation-block">
\[
x \cdot y = k \quad \text{where } x = \text{Token reserves}, \, y = \text{Fiat reserves}, \, k = \text{constant}
\]
</div>

<p>Price impact of trade of size \(\Delta x\):</p>

<div class="equation-block">
\[
P(\Delta x) = \frac{y - y'}{x' - x} = \frac{y - k/(x + \Delta x)}{(x + \Delta x) - x} = \frac{y \cdot \Delta x}{x(x + \Delta x)}
\]
</div>

<p>Liquidity providers earn fees \(f_{\text{LP}} = 0.003\) (0.3%) per trade:</p>

<div class="equation-block">
\[
\text{LP Reward}_{\text{annual}} = f_{\text{LP}} \cdot V_{\text{trades}} \cdot \frac{L_i}{\sum_j L_j}
\]
</div>

<p>Where \(L_i\) is liquidity provided by LP \(i\).</p>

<h2 id="mechanism-design">6. Mechanism Design</h2>

<h3>6.1 Incentive Compatibility and Truthfulness</h3>

<p>A mechanism is <em>incentive-compatible</em> (IC) if truth-telling is a dominant strategy. For data quality reporting:</p>

<div class="equation-block">
\[
\forall i, \forall q_i^{\text{false}}, \forall q_{-i}: \quad u_i(q_i^{\text{true}}, q_{-i}) \geq u_i(q_i^{\text{false}}, q_{-i})
\]
</div>

<p>We achieve IC through <em>proper scoring rules</em> that maximize expected utility under truthful reporting.</p>

<h3>6.2 Vickrey-Clarke-Groves (VCG) Mechanism</h3>

<p>For allocating scarce resources (e.g., priority access to rare variant datasets), VCG ensures truthful bidding and efficient allocation.</p>

<p><strong>Setup:</strong></p>
<ul>
  <li>\(n\) consumers bid for access to \(m < n\) rare datasets</li>
  <li>Consumer \(i\) submits valuation \(v_i\) (private information)</li>
  <li>Social planner allocates datasets to maximize total welfare</li>
</ul>

<p><strong>Allocation Rule:</strong></p>

<div class="equation-block">
\[
x^* = \arg\max_{x \in \mathcal{X}} \sum_{i=1}^n v_i \cdot x_i \quad \text{where } x_i \in \{0,1\} \text{ (allocation to consumer } i)
\]
</div>

<p><strong>VCG Payment Rule:</strong> Consumer \(i\) pays the externality imposed on others:</p>

<div class="equation-block">
\[
p_i = \underbrace{\max_{x_{-i}} \sum_{j \neq i} v_j \cdot x_j}_{\text{welfare without } i} - \underbrace{\sum_{j \neq i} v_j \cdot x_j^*}_{\text{welfare of others with } i}
\]
</div>

<p><strong>Theorem (VCG Truthfulness):</strong> Reporting \(v_i^{\text{report}} = v_i^{\text{true}}\) is a dominant strategy.</p>

<p><strong>Proof Sketch:</strong> Consumer \(i\)'s utility is:</p>

<div class="equation-block">
\[
u_i = x_i^* \cdot v_i - p_i = x_i^* \cdot v_i - \left[\max_{x_{-i}} \sum_{j \neq i} v_j \cdot x_j - \sum_{j \neq i} v_j \cdot x_j^*\right]
\]
</div>

<p>The payment \(p_i\) is independent of \(v_i^{\text{report}}\), so maximizing \(u_i\) reduces to ensuring \(x_i^*\) is allocated when \(v_i\) is high, achieved by reporting \(v_i^{\text{true}}\).</p>

<h3>6.3 Proper Scoring Rules for Quality Prediction</h3>

<p>Validators predict data quality before actual usage reveals true quality. We use the <em>Brier score</em> as a proper scoring rule:</p>

<div class="equation-block">
\[
S_{\text{Brier}}(p, o) = 1 - \frac{1}{K} \sum_{k=1}^K (p_k - o_k)^2
\]
</div>

<p>Where:</p>
<ul>
  <li>\(p = (p_1, \ldots, p_K)\) = Predicted probability distribution over \(K\) quality levels</li>
  <li>\(o = (o_1, \ldots, o_K)\) = Actual outcome (one-hot encoded)</li>
</ul>

<p><strong>Theorem (Brier Properness):</strong> Expected Brier score is maximized when \(p = p_{\text{true}}\) (validator's true beliefs).</p>

<p><strong>Proof:</strong> Expected score given true distribution \(q\):</p>

<div class="equation-block">
\[
\mathbb{E}_q[S_{\text{Brier}}(p, o)] = 1 - \sum_{k=1}^K q_k \cdot (p_k - 1)^2 - \sum_{k \neq k'} q_k \cdot p_{k'}^2
\]
</div>

<p>Taking derivative with respect to \(p_k\) and setting to zero:</p>

<div class="equation-block">
\[
\frac{\partial}{\partial p_k} \mathbb{E}[S] = 2q_k(p_k - 1) - 2p_k \sum_{j \neq k} q_j = 0 \implies p_k = q_k
\]
</div>

<p>Alternative proper scoring rules:</p>

<table>
  <thead>
    <tr>
      <th>Scoring Rule</th>
      <th>Formula</th>
      <th>Properties</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Logarithmic</td>
      <td>\(S(p, o) = \sum_k o_k \log p_k\)</td>
      <td>Strictly proper, sensitive to extreme predictions</td>
    </tr>
    <tr>
      <td>Spherical</td>
      <td>\(S(p, o) = \frac{\sum_k p_k o_k}{\sqrt{\sum_k p_k^2}}\)</td>
      <td>Bounded, less extreme penalties</td>
    </tr>
    <tr>
      <td>Brier</td>
      <td>\(S(p, o) = 1 - \sum_k (p_k - o_k)^2\)</td>
      <td>Quadratic, balanced sensitivity</td>
    </tr>
  </tbody>
</table>

<h3>6.4 Peer Prediction Mechanisms</h3>

<p>When ground truth is unavailable (e.g., subjective metadata quality), <em>peer prediction</em> elicits truthful reports by rewarding agreement with other informed agents.</p>

<p><strong>Bayesian Truth Serum (BTS):</strong> Agents report both their answer and their prediction of others' answers.</p>

<div class="equation-block">
\[
\text{Score}_i = \underbrace{\log \frac{p_i(x_i)}{q(x_i)}}_{\text{information score}} + \underbrace{\log p_i(x_i)}_{\text{prediction score}}
\]
</div>

<p>Where:</p>
<ul>
  <li>\(x_i\) = Agent \(i\)'s reported answer</li>
  <li>\(p_i(x)\) = Agent \(i\)'s prediction of fraction reporting \(x\)</li>
  <li>\(q(x)\) = Actual empirical frequency of report \(x\)</li>
</ul>

<p><strong>Correlated Agreement (CA):</strong> Reward consistency with a randomly selected peer:</p>

<div class="equation-block">
\[
R_i = \alpha \cdot I(r_i; r_j \mid s) - \beta \cdot H(r_i \mid s)
\]
</div>

<p>Where:</p>
<ul>
  <li>\(I(X; Y \mid Z)\) = Conditional mutual information between reports given signal</li>
  <li>\(r_i, r_j\) = Reports from agents \(i\) and \(j\)</li>
  <li>\(s\) = Common signal (data sample)</li>
  <li>\(H(X \mid Y)\) = Conditional entropy</li>
</ul>

<p>Truthful reporting maximizes mutual information with other truthful reporters.</p>

<h3>6.5 Mechanism Implementation: Commit-Reveal Protocols</h3>

<p>Prevent strategic manipulation by separating commitment from revelation:</p>

<p><strong>Phase 1 (Commit):</strong> Each participant \(i\) submits:</p>

<div class="equation-block">
\[
C_i = H(m_i, r_i)
\]
</div>

<p>Where \(m_i\) is their private message (e.g., quality assessment), \(r_i\) is random nonce, and \(H\) is a cryptographic hash (e.g., SHA-256).</p>

<p><strong>Phase 2 (Reveal):</strong> After all commitments are submitted, participants reveal \((m_i, r_i)\). Verify:</p>

<div class="equation-block">
\[
H(m_i, r_i) \stackrel{?}{=} C_i
\]
</div>

<p>If verification fails, participant \(i\) is penalized (stake slashed).</p>

<p><strong>Security:</strong> Commitments are binding (cannot change \(m_i\) after seeing others' commitments) and hiding (others cannot infer \(m_i\) from \(C_i\)).</p>

<h3>6.6 Automated Mechanism Enforcement via Smart Contracts</h3>

<p>Mechanism rules are encoded in smart contracts for trustless enforcement:</p>

<table>
  <thead>
    <tr>
      <th>Mechanism Component</th>
      <th>Smart Contract Function</th>
      <th>Inputs</th>
      <th>Outputs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Commit-Reveal</td>
      <td><code>commitQuality(hash)</code></td>
      <td>Hash of quality report</td>
      <td>Commitment recorded on-chain</td>
    </tr>
    <tr>
      <td>Reveal</td>
      <td><code>revealQuality(quality, nonce)</code></td>
      <td>Quality score, nonce</td>
      <td>Verification, update state</td>
    </tr>
    <tr>
      <td>Reward Distribution</td>
      <td><code>calculateRewards()</code></td>
      <td>All revealed qualities, usage stats</td>
      <td>Token transfers to providers</td>
    </tr>
    <tr>
      <td>Slashing</td>
      <td><code>slash(validator, evidence)</code></td>
      <td>Validator ID, cryptographic proof</td>
      <td>Stake confiscation, burn</td>
    </tr>
    <tr>
      <td>Dispute Resolution</td>
      <td><code>initiateDispute(claimant, evidence)</code></td>
      <td>Claimant, evidence of violation</td>
      <td>Multi-sig arbitration process</td>
    </tr>
  </tbody>
</table>

<h3>6.7 Budget Balance and Individual Rationality</h3>

<p>Mechanisms must satisfy two constraints:</p>

<p><strong>Weak Budget Balance:</strong> Platform does not run at a loss:</p>

<div class="equation-block">
\[
\sum_{i} p_i \geq 0
\]
</div>

<p>Where \(p_i\) is net payment from participant \(i\) (negative if they receive rewards).</p>

<p><strong>Individual Rationality (IR):</strong> Participation is voluntary and beneficial:</p>

<div class="equation-block">
\[
u_i(s_i^*, s_{-i}^*) \geq u_i(\text{outside option})
\]
</div>

<p>For providers: \(R_i - C_i - \text{Privacy Risk} \geq 0\)</p>

<p>For consumers: \(V_C - P_C - \text{Fees} \geq \text{Alternative data sources}\)</p>

<p><strong>Theorem:</strong> VCG mechanisms satisfy IR in expectation (participants earn non-negative expected utility).</p>

<h3>6.8 Auction Mechanisms for Priority Access</h3>

<p>High-value consumers (e.g., pharmaceutical companies) may require priority access. We implement a <em>descending clock auction</em>:</p>

<p><strong>Mechanism:</strong></p>
<ol>
  <li>Clock starts at high price \(P_{\max}\)</li>
  <li>Price descends at rate \(\delta\) (e.g., 1% per minute)</li>
  <li>Consumers indicate willingness to purchase at current price</li>
  <li>Auction ends when demand \(\leq\) supply</li>
  <li>All winners pay final clock price (uniform pricing)</li>
</ol>

<p><strong>Properties:</strong></p>
<ul>
  <li><strong>Incentive Compatibility:</strong> Truthful revelation of valuation is weakly dominant</li>
  <li><strong>Efficiency:</strong> Allocates to highest-value consumers</li>
  <li><strong>Revenue:</strong> Extracts close to maximum welfare (near-optimal revenue)</li>
</ul>

<h3>6.9 Sybil-Resistant Reputation Aggregation</h3>

<p>Aggregate validator reputation scores using <em>PageRank-style</em> trust propagation:</p>

<div class="equation-block">
\[
\text{Trust}_i = (1 - d) + d \cdot \sum_{j \in \text{Endorsers}(i)} \frac{\text{Trust}_j}{|\text{Endorsed}(j)|}
\]
</div>

<p>Where:</p>
<ul>
  <li>\(d = 0.85\) = Damping factor (probability of following endorsement graph)</li>
  <li>\(\text{Endorsers}(i)\) = Set of validators endorsing \(i\)</li>
  <li>\(|\text{Endorsed}(j)|\) = Number of validators endorsed by \(j\)</li>
</ul>

<p>Trust-weighted voting reduces Sybil impact: creating fake identities doesn't gain trust without endorsements from established validators.</p>

<h2 id="conclusion">7. Conclusion</h2>

<p>This comprehensive tokenomics framework establishes a rigorous game-theoretic and economic foundation for decentralized genomic data marketplaces. Key contributions include:</p>

<ul>
  <li><strong>Multi-Sided Market Structure:</strong> Formalized four participant classes (providers, consumers, operators, validators) with explicit utility functions and strategic spaces, enabling equilibrium analysis.</li>
  <li><strong>Dynamic Token Economics:</strong> Adaptive emission schedules, multi-channel burn mechanisms, and staking economics that align token value with network security and transaction volume, targeting 50% staking ratio and \(v = 6\) velocity.</li>
  <li><strong>Incentive-Compatible Rewards:</strong> Quality-weighted rewards (\(\beta = 1.8\) superlinear exponent), diversity bonuses (up to 2\(\times\) for underrepresented populations), privacy multipliers (up to 4\(\times\) for strong privacy), and longevity incentives create dominant strategy for high-quality, diverse, privacy-preserving contributions.</li>
  <li><strong>Robust Economic Security:</strong> Analyzed four attack scenarios (low-quality Sybils, duplicate Sybils, 67% validator cartel, eclipse attacks) demonstrating economic irrationality of attacks through stake requirements, slashing penalties, and detection mechanisms.</li>
  <li><strong>Market Equilibrium Theory:</strong> Solved for Nash equilibrium in provider quality game (\(q^* \approx 0.73\)), Stackelberg equilibrium in platform pricing, and token value equilibrium (\(P^* \approx 120\) tokens/query at baseline parameters).</li>
  <li><strong>Mechanism Design Toolkit:</strong> Implemented VCG mechanisms for efficient allocation, proper scoring rules (Brier, logarithmic, spherical) for truthful quality reporting, peer prediction for subjective assessments, and commit-reveal protocols for manipulation resistance.</li>
</ul>

<p>The framework demonstrates that carefully designed tokenomics can simultaneously achieve:</p>
<ul>
  <li>Economic sustainability (balanced emissions and burns)</li>
  <li>Security (stake-at-risk exceeds attack gains)</li>
  <li>Quality (superlinear rewards dominate low-quality strategies)</li>
  <li>Diversity (ancestry-based bonuses align with social good)</li>
  <li>Privacy (differential privacy incentivized through multipliers)</li>
  <li>Truthfulness (mechanism design ensures dominant strategies)</li>
</ul>

<p>Future work includes empirical calibration of parameters through simulation, integration with privacy-preserving query protocols (secure multi-party computation, homomorphic encryption), and extensions to federated learning marketplaces where model updates (rather than raw genomic data) are exchanged.</p>

</body>
</html>
